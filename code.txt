The following is a digest of the repository "job-platform".
This digest is designed to be easily parsed by Large Language Models.

--- SUMMARY ---
Repository: job-platform
Files Analyzed: 161
Total Text Size: 254.4 KB
Estimated Tokens (text only): ~60,816

--- DIRECTORY STRUCTURE ---
job-platform/
├── backend/
│   ├── analytics-service/
│   │   ├── analytics/
│   │   │   ├── __init__.py
│   │   │   ├── admin.py
│   │   │   ├── apps.py
│   │   │   ├── models.py
│   │   │   ├── serializers.py
│   │   │   ├── signals.py
│   │   │   ├── urls.py
│   │   │   └── views.py
│   │   ├── analytics_service/
│   │   │   ├── __init__.py
│   │   │   ├── asgi.py
│   │   │   ├── settings.py
│   │   │   ├── urls.py
│   │   │   └── wsgi.py
│   │   ├── .gitkeep
│   │   ├── manage.py
│   │   └── requirements.txt
│   ├── api-gateway/
│   │   └── .gitkeep
│   ├── application-service/
│   │   ├── application_service/
│   │   │   ├── __init__.py
│   │   │   ├── asgi.py
│   │   │   ├── settings.py
│   │   │   ├── urls.py
│   │   │   └── wsgi.py
│   │   ├── applications/
│   │   │   ├── __init__.py
│   │   │   ├── admin.py
│   │   │   ├── apps.py
│   │   │   ├── models.py
│   │   │   ├── serializers.py
│   │   │   ├── signals.py
│   │   │   ├── urls.py
│   │   │   └── views.py
│   │   ├── .gitkeep
│   │   ├── manage.py
│   │   └── requirements.txt
│   ├── job-service/
│   │   ├── job_service/
│   │   │   ├── __init__.py
│   │   │   ├── asgi.py
│   │   │   ├── settings.py
│   │   │   ├── urls.py
│   │   │   └── wsgi.py
│   │   ├── jobs/
│   │   │   ├── __init__.py
│   │   │   ├── admin.py
│   │   │   ├── apps.py
│   │   │   ├── models.py
│   │   │   ├── serializers.py
│   │   │   ├── signals.py
│   │   │   ├── tests.py
│   │   │   ├── urls.py
│   │   │   └── views.py
│   │   ├── .gitkeep
│   │   ├── events.py
│   │   ├── manage.py
│   │   └── requirements.txt
│   ├── notification-service/
│   │   ├── notification_service/
│   │   │   ├── __init__.py
│   │   │   ├── asgi.py
│   │   │   ├── settings.py
│   │   │   ├── urls.py
│   │   │   └── wsgi.py
│   │   ├── notifications/
│   │   │   ├── __init__.py
│   │   │   ├── admin.py
│   │   │   ├── apps.py
│   │   │   ├── models.py
│   │   │   ├── serializers.py
│   │   │   ├── signals.py
│   │   │   ├── urls.py
│   │   │   └── views.py
│   │   ├── .gitkeep
│   │   ├── manage.py
│   │   └── requirements.txt
│   ├── search-service/
│   │   ├── search/
│   │   │   ├── __init__.py
│   │   │   ├── admin.py
│   │   │   ├── apps.py
│   │   │   ├── models.py
│   │   │   ├── signals.py
│   │   │   ├── urls.py
│   │   │   └── views.py
│   │   ├── search_service/
│   │   │   ├── __init__.py
│   │   │   ├── asgi.py
│   │   │   ├── settings.py
│   │   │   ├── urls.py
│   │   │   └── wsgi.py
│   │   ├── .gitkeep
│   │   ├── manage.py
│   │   └── requirements.txt
│   ├── shared/
│   │   ├── __init__.py
│   │   ├── .gitkeep
│   │   ├── events.py
│   │   ├── kafka_utils.py
│   │   ├── service_registry.py
│   │   └── settings.py
│   └── user-service/
│       ├── user_service/
│       │   ├── __init__.py
│       │   ├── asgi.py
│       │   ├── settings.py
│       │   ├── urls.py
│       │   └── wsgi.py
│       ├── users/
│       │   ├── migrations/
│       │   │   ├── __init__.py
│       │   │   └── 0001_initial.py
│       │   ├── __init__.py
│       │   ├── admin.py
│       │   ├── apps.py
│       │   ├── consumers.py
│       │   ├── events.py
│       │   ├── models.py
│       │   ├── serializers.py
│       │   ├── signals.py
│       │   ├── tests.py
│       │   ├── urls.py
│       │   └── views.py
│       ├── .gitkeep
│       ├── manage.py
│       └── requirements.txt
├── docs/
│   ├── .gitkeep
│   ├── database-design.md
│   ├── database-migration-strategy.md
│   ├── documentation.md
│   ├── microservice-database-summary.md
│   └── PROJECT_SUMMARY.md
├── frontend/
│   ├── flutter-app/
│   │   ├── android/
│   │   │   ├── app/
│   │   │   │   ├── src/
│   │   │   │   │   ├── debug/
│   │   │   │   │   │   └── AndroidManifest.xml
│   │   │   │   │   ├── main/
│   │   │   │   │   │   ├── java/
│   │   │   │   │   │   │   └── io/
│   │   │   │   │   │   │       └── flutter/
│   │   │   │   │   │   │           └── plugins/
│   │   │   │   │   │   │               └── GeneratedPluginRegistrant.java
│   │   │   │   │   │   ├── kotlin/
│   │   │   │   │   │   │   └── com/
│   │   │   │   │   │   │       └── example/
│   │   │   │   │   │   │           └── job_seeker_app/
│   │   │   │   │   │   │               └── MainActivity.kt
│   │   │   │   │   │   ├── res/
│   │   │   │   │   │   │   ├── drawable/
│   │   │   │   │   │   │   │   └── launch_background.xml
│   │   │   │   │   │   │   ├── drawable-v21/
│   │   │   │   │   │   │   │   └── launch_background.xml
│   │   │   │   │   │   │   ├── mipmap-hdpi/
│   │   │   │   │   │   │   │   └── ic_launcher.png [binary]
│   │   │   │   │   │   │   ├── mipmap-mdpi/
│   │   │   │   │   │   │   │   └── ic_launcher.png [binary]
│   │   │   │   │   │   │   ├── mipmap-xhdpi/
│   │   │   │   │   │   │   │   └── ic_launcher.png [binary]
│   │   │   │   │   │   │   ├── mipmap-xxhdpi/
│   │   │   │   │   │   │   │   └── ic_launcher.png [binary]
│   │   │   │   │   │   │   ├── mipmap-xxxhdpi/
│   │   │   │   │   │   │   │   └── ic_launcher.png [binary]
│   │   │   │   │   │   │   ├── values/
│   │   │   │   │   │   │   │   └── styles.xml
│   │   │   │   │   │   │   └── values-night/
│   │   │   │   │   │   │       └── styles.xml
│   │   │   │   │   │   └── AndroidManifest.xml
│   │   │   │   │   └── profile/
│   │   │   │   │       └── AndroidManifest.xml
│   │   │   │   └── build.gradle.kts
│   │   │   ├── gradle/
│   │   │   │   └── wrapper/
│   │   │   │       └── gradle-wrapper.properties
│   │   │   ├── build.gradle.kts
│   │   │   ├── gradle.properties
│   │   │   ├── gradlew
│   │   │   ├── gradlew.bat [binary]
│   │   │   └── settings.gradle.kts
│   │   ├── assets/
│   │   │   └── fonts/
│   │   │       └── README.md
│   │   ├── test/
│   │   │   └── widget_test.dart
│   │   ├── web/
│   │   │   ├── icons/
│   │   │   │   ├── Icon-192.png [binary]
│   │   │   │   ├── Icon-512.png [binary]
│   │   │   │   ├── Icon-maskable-192.png [binary]
│   │   │   │   └── Icon-maskable-512.png [binary]
│   │   │   ├── favicon.png [binary]
│   │   │   └── manifest.json
│   │   ├── .gitkeep
│   │   ├── .metadata
│   │   ├── analysis_options.yaml
│   │   ├── pubspec.yaml
│   │   └── README.md
│   ├── shared/
│   │   ├── constants/
│   │   │   └── api.ts [binary]
│   │   └── types/
│   │       └── api.ts [binary]
│   └── README.md
├── infrastructure/
│   ├── docker/
│   │   ├── api-gateway/
│   │   │   └── nginx.conf
│   │   └── .gitkeep
│   ├── kubernetes/
│   │   └── .gitkeep
│   └── scripts/
│       ├── .gitkeep
│       └── setup.sh
├── scripts/
│   └── setup.sh
├── build.yaml
├── pubspec.yaml
└── README.md


--- FILE CONTENTS ---
============================================================
FILE: backend/analytics-service/analytics/__init__.py
============================================================
 

============================================================
FILE: backend/analytics-service/analytics/admin.py
============================================================
from django.contrib import admin
from .models import AnalyticsEvent, UserAnalytics, JobAnalytics, PlatformAnalytics


@admin.register(AnalyticsEvent)
class AnalyticsEventAdmin(admin.ModelAdmin):
    list_display = ('event_type', 'user_id', 'session_id', 'timestamp')
    list_filter = ('event_type', 'timestamp')
    search_fields = ('event_type', 'user_id', 'session_id')
    ordering = ('-timestamp',)


@admin.register(UserAnalytics)
class UserAnalyticsAdmin(admin.ModelAdmin):
    list_display = ('user_id', 'metric_name', 'metric_value', 'metric_date', 'created_at')
    list_filter = ('metric_name', 'metric_date', 'created_at')
    search_fields = ('user_id', 'metric_name')
    ordering = ('-metric_date', 'metric_name')


@admin.register(JobAnalytics)
class JobAnalyticsAdmin(admin.ModelAdmin):
    list_display = ('job_id', 'metric_name', 'metric_value', 'metric_date', 'created_at')
    list_filter = ('metric_name', 'metric_date', 'created_at')
    search_fields = ('job_id', 'metric_name')
    ordering = ('-metric_date', 'metric_name')


@admin.register(PlatformAnalytics)
class PlatformAnalyticsAdmin(admin.ModelAdmin):
    list_display = ('metric_name', 'metric_value', 'metric_date', 'created_at')
    list_filter = ('metric_name', 'metric_date', 'created_at')
    search_fields = ('metric_name',)
    ordering = ('-metric_date', 'metric_name') 

============================================================
FILE: backend/analytics-service/analytics/apps.py
============================================================
from django.apps import AppConfig
from django.utils.translation import gettext_lazy as _


class AnalyticsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'analytics'
    verbose_name = _('Analytics')
    
    def ready(self):
        """Import signals when the app is ready."""
        import analytics.signals 

============================================================
FILE: backend/analytics-service/analytics/models.py
============================================================
from django.db import models
from django.utils.translation import gettext_lazy as _


class AnalyticsEvent(models.Model):
    """
    Analytics events for tracking user behavior and system events.
    """
    
    event_type = models.CharField(max_length=100, help_text=_("Type of event"))
    user_id = models.BigIntegerField(blank=True, null=True, help_text=_("User ID from user-service (nullable for anonymous events)"))
    session_id = models.CharField(max_length=255, blank=True, help_text=_("Session identifier"))
    properties = models.JSONField(default=dict, blank=True, help_text=_("Event properties and metadata"))
    timestamp = models.DateTimeField(auto_now_add=True, help_text=_("Event timestamp"))
    
    class Meta:
        verbose_name = _('Analytics Event')
        verbose_name_plural = _('Analytics Events')
        db_table = 'analytics_events'
        ordering = ['-timestamp']
        indexes = [
            models.Index(fields=['event_type', 'timestamp']),
            models.Index(fields=['user_id', 'timestamp']),
            models.Index(fields=['session_id', 'timestamp']),
        ]
    
    def __str__(self):
        return f"{self.event_type} - User {self.user_id or 'Anonymous'} at {self.timestamp}"


class UserAnalytics(models.Model):
    """
    User-specific analytics and metrics.
    """
    
    user_id = models.BigIntegerField(help_text=_("User ID from user-service"))
    metric_name = models.CharField(max_length=100, help_text=_("Name of the metric"))
    metric_value = models.DecimalField(max_digits=15, decimal_places=2, blank=True, null=True, help_text=_("Metric value"))
    metric_date = models.DateField(help_text=_("Date for the metric"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('User Analytics')
        verbose_name_plural = _('User Analytics')
        db_table = 'user_analytics'
        unique_together = ('user_id', 'metric_name', 'metric_date')
        ordering = ['-metric_date', 'metric_name']
        indexes = [
            models.Index(fields=['user_id', 'metric_date']),
            models.Index(fields=['metric_name', 'metric_date']),
        ]
    
    def __str__(self):
        return f"User {self.user_id} - {self.metric_name}: {self.metric_value} on {self.metric_date}"


class JobAnalytics(models.Model):
    """
    Job-specific analytics and metrics.
    """
    
    job_id = models.BigIntegerField(help_text=_("Job ID from job-service"))
    metric_name = models.CharField(max_length=100, help_text=_("Name of the metric"))
    metric_value = models.IntegerField(default=0, help_text=_("Metric value"))
    metric_date = models.DateField(help_text=_("Date for the metric"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Job Analytics')
        verbose_name_plural = _('Job Analytics')
        db_table = 'job_analytics'
        unique_together = ('job_id', 'metric_name', 'metric_date')
        ordering = ['-metric_date', 'metric_name']
        indexes = [
            models.Index(fields=['job_id', 'metric_date']),
            models.Index(fields=['metric_name', 'metric_date']),
        ]
    
    def __str__(self):
        return f"Job {self.job_id} - {self.metric_name}: {self.metric_value} on {self.metric_date}"


class PlatformAnalytics(models.Model):
    """
    Platform-wide analytics and metrics.
    """
    
    metric_name = models.CharField(max_length=100, help_text=_("Name of the metric"))
    metric_value = models.DecimalField(max_digits=15, decimal_places=2, blank=True, null=True, help_text=_("Metric value"))
    metric_date = models.DateField(help_text=_("Date for the metric"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Platform Analytics')
        verbose_name_plural = _('Platform Analytics')
        db_table = 'platform_analytics'
        unique_together = ('metric_name', 'metric_date')
        ordering = ['-metric_date', 'metric_name']
        indexes = [
            models.Index(fields=['metric_name', 'metric_date']),
        ]
    
    def __str__(self):
        return f"Platform - {self.metric_name}: {self.metric_value} on {self.metric_date}" 

============================================================
FILE: backend/analytics-service/analytics/serializers.py
============================================================
from rest_framework import serializers
from .models import AnalyticsEvent, UserAnalytics, JobAnalytics, PlatformAnalytics


class AnalyticsEventSerializer(serializers.ModelSerializer):
    class Meta:
        model = AnalyticsEvent
        fields = '__all__'
        read_only_fields = ['timestamp']


class UserAnalyticsSerializer(serializers.ModelSerializer):
    class Meta:
        model = UserAnalytics
        fields = '__all__'
        read_only_fields = ['created_at']


class JobAnalyticsSerializer(serializers.ModelSerializer):
    class Meta:
        model = JobAnalytics
        fields = '__all__'
        read_only_fields = ['created_at']


class PlatformAnalyticsSerializer(serializers.ModelSerializer):
    class Meta:
        model = PlatformAnalytics
        fields = '__all__'
        read_only_fields = ['created_at'] 

============================================================
FILE: backend/analytics-service/analytics/signals.py
============================================================
from django.db.models.signals import post_save
from django.dispatch import receiver
from .models import AnalyticsEvent


@receiver(post_save, sender=AnalyticsEvent)
def process_analytics_event(sender, instance, created, **kwargs):
    """
    Signal to process analytics events when they are created.
    """
    if created:
        # This would typically involve processing the analytics event
        # and updating relevant metrics
        pass 

============================================================
FILE: backend/analytics-service/analytics/urls.py
============================================================
from django.urls import path
from . import views

app_name = 'analytics'

urlpatterns = [
    path('events/', views.analytics_events, name='analytics_events'),
    path('user/', views.user_analytics, name='user_analytics'),
    path('job/', views.job_analytics, name='job_analytics'),
    path('platform/', views.platform_analytics, name='platform_analytics'),
] 

============================================================
FILE: backend/analytics-service/analytics/views.py
============================================================
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.response import Response
from django.utils import timezone
from datetime import datetime, timedelta
from .models import AnalyticsEvent, UserAnalytics, JobAnalytics, PlatformAnalytics
from .serializers import AnalyticsEventSerializer, UserAnalyticsSerializer, JobAnalyticsSerializer, PlatformAnalyticsSerializer


@api_view(['POST'])
@permission_classes([AllowAny])
def analytics_events(request):
    """Create analytics events"""
    serializer = AnalyticsEventSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def user_analytics(request):
    """Get user analytics"""
    user_id = request.GET.get('user_id', request.user.id)
    metric_name = request.GET.get('metric_name')
    start_date = request.GET.get('start_date')
    end_date = request.GET.get('end_date')
    
    queryset = UserAnalytics.objects.filter(user_id=user_id)
    
    if metric_name:
        queryset = queryset.filter(metric_name=metric_name)
    
    if start_date:
        queryset = queryset.filter(metric_date__gte=start_date)
    
    if end_date:
        queryset = queryset.filter(metric_date__lte=end_date)
    
    serializer = UserAnalyticsSerializer(queryset, many=True)
    return Response(serializer.data)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def job_analytics(request):
    """Get job analytics"""
    job_id = request.GET.get('job_id')
    metric_name = request.GET.get('metric_name')
    start_date = request.GET.get('start_date')
    end_date = request.GET.get('end_date')
    
    queryset = JobAnalytics.objects.all()
    
    if job_id:
        queryset = queryset.filter(job_id=job_id)
    
    if metric_name:
        queryset = queryset.filter(metric_name=metric_name)
    
    if start_date:
        queryset = queryset.filter(metric_date__gte=start_date)
    
    if end_date:
        queryset = queryset.filter(metric_date__lte=end_date)
    
    serializer = JobAnalyticsSerializer(queryset, many=True)
    return Response(serializer.data)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def platform_analytics(request):
    """Get platform analytics"""
    metric_name = request.GET.get('metric_name')
    start_date = request.GET.get('start_date')
    end_date = request.GET.get('end_date')
    
    queryset = PlatformAnalytics.objects.all()
    
    if metric_name:
        queryset = queryset.filter(metric_name=metric_name)
    
    if start_date:
        queryset = queryset.filter(metric_date__gte=start_date)
    
    if end_date:
        queryset = queryset.filter(metric_date__lte=end_date)
    
    serializer = PlatformAnalyticsSerializer(queryset, many=True)
    return Response(serializer.data) 

============================================================
FILE: backend/analytics-service/analytics_service/__init__.py
============================================================
 

============================================================
FILE: backend/analytics-service/analytics_service/asgi.py
============================================================
"""
ASGI config for analytics_service project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'analytics_service.settings')

application = get_asgi_application() 

============================================================
FILE: backend/analytics-service/analytics_service/settings.py
============================================================
import os
import sys
from pathlib import Path
from datetime import timedelta
from decouple import config

BASE_DIR = Path(__file__).resolve().parent.parent

# Add shared directory to Python path
shared_path = BASE_DIR.parent / 'shared'
if str(shared_path) not in sys.path:
    sys.path.insert(0, str(shared_path))

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config('SECRET_KEY', default='django-insecure-local-dev-key-change-in-production')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=True, cast=bool)

ALLOWED_HOSTS = ['localhost', '127.0.0.1']

# Application definition
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party apps
    'rest_framework',
    'rest_framework_simplejwt',
    'corsheaders',
    'django_extensions',
    
    # Local apps
    'analytics',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'analytics_service.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'analytics_service.wsgi.application'

# Database - Using PostgreSQL for microservice
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': config('DB_NAME', default='analytics_db'),
        'USER': config('DB_USER', default='postgres'),
        'PASSWORD': config('DB_PASSWORD', default='postgres123'),
        'HOST': config('DB_HOST', default='localhost'),
        'PORT': config('DB_PORT', default='5432'),
    }
}

# Password validation
AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

# Rest Framework Configuration
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}

# JWT Configuration
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
    'BLACKLIST_AFTER_ROTATION': True,
}

# CORS Settings (for local development)
CORS_ALLOW_ALL_ORIGINS = True
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
]

# Internationalization
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

# Media files
MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Microservice Configuration
USER_SERVICE_URL = config('USER_SERVICE_URL', default='http://localhost:8001')
JOB_SERVICE_URL = config('JOB_SERVICE_URL', default='http://localhost:8002')
APPLICATION_SERVICE_URL = config('APPLICATION_SERVICE_URL', default='http://localhost:8003')
SEARCH_SERVICE_URL = config('SEARCH_SERVICE_URL', default='http://localhost:8004')
NOTIFICATION_SERVICE_URL = config('NOTIFICATION_SERVICE_URL', default='http://localhost:8005')

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS = config('KAFKA_BOOTSTRAP_SERVERS', default='localhost:9092').split(',')
KAFKA_GROUP_ID = config('KAFKA_GROUP_ID', default='analytics-service-group')

# Topics
KAFKA_TOPICS = {
    'USER_EVENTS': 'user-events',
    'JOB_EVENTS': 'job-events',
    'APPLICATION_EVENTS': 'application-events'
} 

============================================================
FILE: backend/analytics-service/analytics_service/urls.py
============================================================
from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/analytics/', include('analytics.urls')),
]

# Serve media files during development
if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 

============================================================
FILE: backend/analytics-service/analytics_service/wsgi.py
============================================================
"""
WSGI config for analytics_service project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'analytics_service.settings')

application = get_wsgi_application() 

============================================================
FILE: backend/analytics-service/manage.py
============================================================
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'analytics_service.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main() 

============================================================
FILE: backend/analytics-service/requirements.txt
============================================================
Django==4.2.7
djangorestframework==3.14.0
djangorestframework-simplejwt==5.3.0
django-cors-headers==4.3.1
psycopg[binary]==3.2.9
python-decouple==3.8
django-extensions==3.2.3
requests==2.31.0
celery==5.3.4
redis==5.0.1
Pillow==11.3.0
kafka-python==2.0.2 

============================================================
FILE: backend/application-service/application_service/__init__.py
============================================================
 

============================================================
FILE: backend/application-service/application_service/asgi.py
============================================================
"""
ASGI config for application_service project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'application_service.settings')

application = get_asgi_application() 

============================================================
FILE: backend/application-service/application_service/settings.py
============================================================
import os
import sys
from pathlib import Path
from datetime import timedelta
from decouple import config

BASE_DIR = Path(__file__).resolve().parent.parent

# Add shared directory to Python path
shared_path = BASE_DIR.parent / 'shared'
if str(shared_path) not in sys.path:
    sys.path.insert(0, str(shared_path))

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config('SECRET_KEY', default='django-insecure-local-dev-key-change-in-production')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=True, cast=bool)

ALLOWED_HOSTS = ['localhost', '127.0.0.1']

# Application definition
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party apps
    'rest_framework',
    'rest_framework_simplejwt',
    'corsheaders',
    'django_extensions',
    
    # Local apps
    'applications',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'application_service.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'application_service.wsgi.application'

# Database - Using PostgreSQL for microservice
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': config('DB_NAME', default='applications_db'),
        'USER': config('DB_USER', default='postgres'),
        'PASSWORD': config('DB_PASSWORD', default='postgres123'),
        'HOST': config('DB_HOST', default='localhost'),
        'PORT': config('DB_PORT', default='5432'),
    }
}

# Password validation
AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

# Rest Framework Configuration
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}

# JWT Configuration
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
    'BLACKLIST_AFTER_ROTATION': True,
}

# CORS Settings (for local development)
CORS_ALLOW_ALL_ORIGINS = True
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
]

# Internationalization
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

# Media files
MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Microservice Configuration
USER_SERVICE_URL = config('USER_SERVICE_URL', default='http://localhost:8001')
JOB_SERVICE_URL = config('JOB_SERVICE_URL', default='http://localhost:8002')

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS = config('KAFKA_BOOTSTRAP_SERVERS', default='localhost:9092').split(',')
KAFKA_GROUP_ID = config('KAFKA_GROUP_ID', default='application-service-group')

# Topics
KAFKA_TOPICS = {
    'USER_EVENTS': 'user-events',
    'JOB_EVENTS': 'job-events',
    'APPLICATION_EVENTS': 'application-events'
} 

============================================================
FILE: backend/application-service/application_service/urls.py
============================================================
from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/applications/', include('applications.urls')),
]

# Serve media files during development
if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 

============================================================
FILE: backend/application-service/application_service/wsgi.py
============================================================
"""
WSGI config for application_service project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'application_service.settings')

application = get_wsgi_application() 

============================================================
FILE: backend/application-service/applications/__init__.py
============================================================
 

============================================================
FILE: backend/application-service/applications/admin.py
============================================================
from django.contrib import admin
from .models import Application, ApplicationAttachment, ApplicationStatusHistory, Interview


@admin.register(Application)
class ApplicationAdmin(admin.ModelAdmin):
    list_display = ('id', 'job_id', 'applicant_id', 'employer_id', 'status', 'is_active', 'created_at')
    list_filter = ('status', 'is_active', 'created_at')
    search_fields = ('job_id', 'applicant_id', 'employer_id')
    ordering = ('-created_at',)


@admin.register(ApplicationAttachment)
class ApplicationAttachmentAdmin(admin.ModelAdmin):
    list_display = ('application', 'file_name', 'file_type', 'file_size', 'created_at')
    list_filter = ('file_type', 'created_at')
    search_fields = ('file_name', 'application__id')
    ordering = ('-created_at',)


@admin.register(ApplicationStatusHistory)
class ApplicationStatusHistoryAdmin(admin.ModelAdmin):
    list_display = ('application', 'status', 'changed_by', 'created_at')
    list_filter = ('status', 'created_at')
    search_fields = ('application__id', 'notes')
    ordering = ('-created_at',)


@admin.register(Interview)
class InterviewAdmin(admin.ModelAdmin):
    list_display = ('application', 'interview_type', 'scheduled_at', 'status', 'created_at')
    list_filter = ('interview_type', 'status', 'created_at')
    search_fields = ('application__id', 'location', 'notes')
    ordering = ('-scheduled_at',) 

============================================================
FILE: backend/application-service/applications/apps.py
============================================================
from django.apps import AppConfig
from django.utils.translation import gettext_lazy as _


class ApplicationsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'applications'
    verbose_name = _('Applications')
    
    def ready(self):
        """Import signals when the app is ready."""
        import applications.signals 

============================================================
FILE: backend/application-service/applications/models.py
============================================================
from django.db import models
from django.utils.translation import gettext_lazy as _


class Application(models.Model):
    """
    Job application model.
    This is the core model for the application service.
    """
    
    # Foreign key references (to other services)
    job_id = models.BigIntegerField(help_text=_("Job ID from job-service"))
    applicant_id = models.BigIntegerField(help_text=_("User ID of the applicant (from user-service)"))
    employer_id = models.BigIntegerField(help_text=_("User ID of the employer (from user-service)"))
    
    # Application details
    STATUS_CHOICES = [
        ('pending', _('Pending')),
        ('reviewing', _('Under Review')),
        ('shortlisted', _('Shortlisted')),
        ('interviewing', _('Interviewing')),
        ('offered', _('Offer Made')),
        ('hired', _('Hired')),
        ('rejected', _('Rejected')),
        ('withdrawn', _('Withdrawn')),
    ]
    
    status = models.CharField(max_length=50, choices=STATUS_CHOICES, default='pending', help_text=_("Application status"))
    cover_letter = models.TextField(blank=True, help_text=_("Cover letter"))
    expected_salary = models.DecimalField(max_digits=10, decimal_places=2, blank=True, null=True, help_text=_("Expected salary"))
    availability_date = models.DateField(blank=True, null=True, help_text=_("Availability date"))
    
    # Status
    is_active = models.BooleanField(default=True, help_text=_("Whether the application is active"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('Application')
        verbose_name_plural = _('Applications')
        db_table = 'applications'
        ordering = ['-created_at']
        unique_together = ('job_id', 'applicant_id')  # One application per job per applicant
    
    def __str__(self):
        return f"Application {self.id} - Job {self.job_id} by User {self.applicant_id}"


class ApplicationAttachment(models.Model):
    """
    Attachments for job applications (resume, cover letter, etc.).
    """
    
    application = models.ForeignKey(Application, on_delete=models.CASCADE, related_name='attachments', help_text=_("Related application"))
    file_name = models.CharField(max_length=255, help_text=_("Original file name"))
    file_path = models.CharField(max_length=500, help_text=_("File path in storage"))
    file_type = models.CharField(max_length=100, blank=True, help_text=_("File MIME type"))
    file_size = models.IntegerField(blank=True, null=True, help_text=_("File size in bytes"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Application Attachment')
        verbose_name_plural = _('Application Attachments')
        db_table = 'application_attachments'
    
    def __str__(self):
        return f"{self.file_name} - {self.application}"


class ApplicationStatusHistory(models.Model):
    """
    History of application status changes for audit trail.
    """
    
    application = models.ForeignKey(Application, on_delete=models.CASCADE, related_name='status_history', help_text=_("Related application"))
    status = models.CharField(max_length=50, help_text=_("Status at this point"))
    notes = models.TextField(blank=True, help_text=_("Notes about the status change"))
    changed_by = models.BigIntegerField(help_text=_("User ID who made the change (from user-service)"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Application Status History')
        verbose_name_plural = _('Application Status Histories')
        db_table = 'application_status_history'
        ordering = ['-created_at']
    
    def __str__(self):
        return f"{self.application} - {self.status} at {self.created_at}"


class Interview(models.Model):
    """
    Interview scheduling and management.
    """
    
    application = models.ForeignKey(Application, on_delete=models.CASCADE, related_name='interviews', help_text=_("Related application"))
    
    INTERVIEW_TYPE_CHOICES = [
        ('phone', _('Phone Interview')),
        ('video', _('Video Interview')),
        ('in_person', _('In-Person Interview')),
    ]
    
    interview_type = models.CharField(max_length=50, choices=INTERVIEW_TYPE_CHOICES, default='phone', help_text=_("Type of interview"))
    scheduled_at = models.DateTimeField(blank=True, null=True, help_text=_("Scheduled interview time"))
    duration_minutes = models.IntegerField(default=60, help_text=_("Interview duration in minutes"))
    location = models.CharField(max_length=255, blank=True, help_text=_("Interview location or meeting link"))
    notes = models.TextField(blank=True, help_text=_("Interview notes"))
    
    STATUS_CHOICES = [
        ('scheduled', _('Scheduled')),
        ('completed', _('Completed')),
        ('cancelled', _('Cancelled')),
        ('rescheduled', _('Rescheduled')),
    ]
    
    status = models.CharField(max_length=50, choices=STATUS_CHOICES, default='scheduled', help_text=_("Interview status"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('Interview')
        verbose_name_plural = _('Interviews')
        db_table = 'interviews'
        ordering = ['-scheduled_at']
    
    def __str__(self):
        return f"Interview for {self.application} - {self.interview_type} on {self.scheduled_at}" 

============================================================
FILE: backend/application-service/applications/serializers.py
============================================================
from rest_framework import serializers
from .models import Application, ApplicationAttachment, Interview, ApplicationStatusHistory


class ApplicationAttachmentSerializer(serializers.ModelSerializer):
    class Meta:
        model = ApplicationAttachment
        fields = '__all__'
        read_only_fields = ['created_at']


class ApplicationStatusHistorySerializer(serializers.ModelSerializer):
    class Meta:
        model = ApplicationStatusHistory
        fields = '__all__'
        read_only_fields = ['created_at']


class InterviewSerializer(serializers.ModelSerializer):
    class Meta:
        model = Interview
        fields = '__all__'
        read_only_fields = ['created_at', 'updated_at']


class ApplicationSerializer(serializers.ModelSerializer):
    attachments = ApplicationAttachmentSerializer(many=True, read_only=True)
    interviews = InterviewSerializer(many=True, read_only=True)
    status_history = ApplicationStatusHistorySerializer(many=True, read_only=True)
    
    class Meta:
        model = Application
        fields = '__all__'
        read_only_fields = ['created_at', 'updated_at', 'applicant_id', 'employer_id']
    
    def validate(self, attrs):
        # Check if user has already applied for this job
        job_id = attrs.get('job_id')
        applicant_id = self.context.get('applicant_id')
        
        if job_id and applicant_id:
            if Application.objects.filter(job_id=job_id, applicant_id=applicant_id, is_active=True).exists():
                raise serializers.ValidationError("You have already applied for this job.")
        
        return attrs 

============================================================
FILE: backend/application-service/applications/signals.py
============================================================
from django.db.models.signals import post_save
from django.dispatch import receiver
from .models import Application, ApplicationStatusHistory


@receiver(post_save, sender=Application)
def create_application_status_history(sender, instance, created, **kwargs):
    """
    Signal to create status history when application status changes.
    """
    if created:
        # Create initial status history entry
        ApplicationStatusHistory.objects.create(
            application=instance,
            status=instance.status,
            changed_by=instance.applicant_id,  # Default to applicant
            notes="Application created"
        )
    else:
        # For now, we'll create a history entry on every save
        # In production, you might want to use django-model-utils or similar
        # to track field changes more efficiently
        ApplicationStatusHistory.objects.create(
            application=instance,
            status=instance.status,
            changed_by=instance.applicant_id,  # This should be updated with actual user ID
            notes=f"Application updated"
        ) 

============================================================
FILE: backend/application-service/applications/urls.py
============================================================
from django.urls import path
from . import views

app_name = 'applications'

urlpatterns = [
    # Application endpoints
    path('', views.application_list, name='application_list'),
    path('<int:application_id>/', views.application_detail, name='application_detail'),
    path('create/', views.application_create, name='application_create'),
    path('<int:application_id>/update/', views.application_update, name='application_update'),
    path('<int:application_id>/delete/', views.application_delete, name='application_delete'),
    
    # Interview endpoints
    path('<int:application_id>/interviews/', views.interview_list, name='interview_list'),
    path('<int:application_id>/interviews/create/', views.interview_create, name='interview_create'),
    path('interviews/<int:interview_id>/', views.interview_detail, name='interview_detail'),
    path('interviews/<int:interview_id>/update/', views.interview_update, name='interview_update'),
] 

============================================================
FILE: backend/application-service/applications/views.py
============================================================
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.shortcuts import get_object_or_404
from .models import Application, Interview
from .serializers import ApplicationSerializer, InterviewSerializer


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def application_list(request):
    """List applications for the current user"""
    if request.user.user_type == 'employer':
        applications = Application.objects.filter(employer_id=request.user.id)
    else:
        applications = Application.objects.filter(applicant_id=request.user.id)
    
    serializer = ApplicationSerializer(applications, many=True)
    return Response(serializer.data)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def application_detail(request, application_id):
    """Get application details"""
    application = get_object_or_404(Application, id=application_id)
    
    # Check if user has permission to view this application
    if request.user.id not in [application.applicant_id, application.employer_id]:
        return Response(status=status.HTTP_403_FORBIDDEN)
    
    serializer = ApplicationSerializer(application)
    return Response(serializer.data)


@api_view(['POST'])
@permission_classes([IsAuthenticated])
def application_create(request):
    """Create a new application"""
    serializer = ApplicationSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save(applicant_id=request.user.id)
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['PUT', 'PATCH'])
@permission_classes([IsAuthenticated])
def application_update(request, application_id):
    """Update an application"""
    application = get_object_or_404(Application, id=application_id)
    
    # Check if user has permission to update this application
    if request.user.id not in [application.applicant_id, application.employer_id]:
        return Response(status=status.HTTP_403_FORBIDDEN)
    
    serializer = ApplicationSerializer(application, data=request.data, partial=request.method == 'PATCH')
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['DELETE'])
@permission_classes([IsAuthenticated])
def application_delete(request, application_id):
    """Delete an application"""
    application = get_object_or_404(Application, id=application_id)
    
    # Check if user has permission to delete this application
    if request.user.id != application.applicant_id:
        return Response(status=status.HTTP_403_FORBIDDEN)
    
    application.is_active = False
    application.save()
    return Response(status=status.HTTP_204_NO_CONTENT)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def interview_list(request, application_id):
    """List interviews for an application"""
    application = get_object_or_404(Application, id=application_id)
    
    # Check if user has permission to view interviews
    if request.user.id not in [application.applicant_id, application.employer_id]:
        return Response(status=status.HTTP_403_FORBIDDEN)
    
    interviews = Interview.objects.filter(application=application)
    serializer = InterviewSerializer(interviews, many=True)
    return Response(serializer.data)


@api_view(['POST'])
@permission_classes([IsAuthenticated])
def interview_create(request, application_id):
    """Create a new interview"""
    application = get_object_or_404(Application, id=application_id)
    
    # Check if user has permission to create interviews
    if request.user.id != application.employer_id:
        return Response(status=status.HTTP_403_FORBIDDEN)
    
    serializer = InterviewSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save(application=application)
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def interview_detail(request, interview_id):
    """Get interview details"""
    interview = get_object_or_404(Interview, id=interview_id)
    application = interview.application
    
    # Check if user has permission to view this interview
    if request.user.id not in [application.applicant_id, application.employer_id]:
        return Response(status=status.HTTP_403_FORBIDDEN)
    
    serializer = InterviewSerializer(interview)
    return Response(serializer.data)


@api_view(['PUT', 'PATCH'])
@permission_classes([IsAuthenticated])
def interview_update(request, interview_id):
    """Update an interview"""
    interview = get_object_or_404(Interview, id=interview_id)
    application = interview.application
    
    # Check if user has permission to update this interview
    if request.user.id != application.employer_id:
        return Response(status=status.HTTP_403_FORBIDDEN)
    
    serializer = InterviewSerializer(interview, data=request.data, partial=request.method == 'PATCH')
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 

============================================================
FILE: backend/application-service/manage.py
============================================================
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'application_service.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main() 

============================================================
FILE: backend/application-service/requirements.txt
============================================================
Django==4.2.7
djangorestframework==3.14.0
djangorestframework-simplejwt==5.3.0
django-cors-headers==4.3.1
psycopg[binary]==3.2.9
python-decouple==3.8
django-extensions==3.2.3
requests==2.31.0
celery==5.3.4
redis==5.0.1
Pillow==11.3.0
kafka-python==2.0.2 

============================================================
FILE: backend/job-service/job_service/__init__.py
============================================================
 

============================================================
FILE: backend/job-service/job_service/asgi.py
============================================================
"""
ASGI config for job_service project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'job_service.settings')

application = get_asgi_application() 

============================================================
FILE: backend/job-service/job_service/settings.py
============================================================
import os
import sys
from pathlib import Path
from datetime import timedelta
from decouple import config
import dj_database_url

BASE_DIR = Path(__file__).resolve().parent.parent

# Add shared directory to Python path
shared_path = BASE_DIR.parent / 'shared'
if str(shared_path) not in sys.path:
    sys.path.insert(0, str(shared_path))

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config('SECRET_KEY', default='django-insecure-local-dev-key-change-in-production')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=True, cast=bool)

ALLOWED_HOSTS = ['localhost', '127.0.0.1']

# Application definition
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party apps
    'rest_framework',
    'rest_framework_simplejwt',
    'corsheaders',
    'django_extensions',
    
    # Local apps
    'jobs',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'job_service.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'job_service.wsgi.application'

# Database - Prefer DATABASE_URL if present, fallback to SQLite for local dev
DATABASE_URL = os.getenv('DATABASE_URL')
if DATABASE_URL:
    DATABASES = {
        'default': dj_database_url.parse(DATABASE_URL, conn_max_age=600)
    }
else:
    DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.sqlite3',
            'NAME': BASE_DIR / 'db.sqlite3',
        }
    }

# Password validation
AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

# Rest Framework Configuration
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}

# JWT Configuration
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
    'BLACKLIST_AFTER_ROTATION': True,
}

# CORS Settings (for local development)
CORS_ALLOW_ALL_ORIGINS = True
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
]

# Internationalization
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

# Media files
MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Microservice Configuration
USER_SERVICE_URL = config('USER_SERVICE_URL', default='http://localhost:8001')
APPLICATION_SERVICE_URL = config('APPLICATION_SERVICE_URL', default='http://localhost:8003')

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS = config('KAFKA_BOOTSTRAP_SERVERS', default='kafka:29092').split(',')
KAFKA_GROUP_ID = config('KAFKA_GROUP_ID', default='job-service-group')
KAFKA_TOPICS = {
    'JOB_EVENTS': config('KAFKA_TOPIC_JOB_EVENTS', default='job-events'),
    'USER_EVENTS': config('KAFKA_TOPIC_USER_EVENTS', default='user-events'),
} 

============================================================
FILE: backend/job-service/job_service/urls.py
============================================================
from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/jobs/', include('jobs.urls')),
]

# Serve media files during development
if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 

============================================================
FILE: backend/job-service/job_service/wsgi.py
============================================================
"""
WSGI config for job_service project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'job_service.settings')

application = get_wsgi_application() 

============================================================
FILE: backend/job-service/jobs/__init__.py
============================================================
 

============================================================
FILE: backend/job-service/jobs/admin.py
============================================================
from django.contrib import admin
from .models import Company, Job, JobCategory, JobSkill, JobCategoryJob, JobSkillJob


@admin.register(Company)
class CompanyAdmin(admin.ModelAdmin):
    list_display = ('name', 'industry', 'size', 'location', 'is_verified', 'created_at')
    list_filter = ('industry', 'size', 'is_verified', 'created_at')
    search_fields = ('name', 'description', 'location')
    ordering = ('-created_at',)


@admin.register(JobCategory)
class JobCategoryAdmin(admin.ModelAdmin):
    list_display = ('name', 'parent', 'created_at')
    list_filter = ('parent', 'created_at')
    search_fields = ('name', 'description')
    ordering = ('name',)


@admin.register(JobSkill)
class JobSkillAdmin(admin.ModelAdmin):
    list_display = ('name', 'created_at')
    search_fields = ('name',)
    ordering = ('name',)


@admin.register(Job)
class JobAdmin(admin.ModelAdmin):
    list_display = ('title', 'company', 'employer_id', 'job_type', 'experience_level', 'location', 'is_active', 'created_at')
    list_filter = ('job_type', 'experience_level', 'is_remote', 'is_active', 'created_at')
    search_fields = ('title', 'description', 'requirements')
    ordering = ('-created_at',)
    filter_horizontal = ('categories', 'skills')


@admin.register(JobCategoryJob)
class JobCategoryJobAdmin(admin.ModelAdmin):
    list_display = ('job', 'category')
    list_filter = ('category',)
    search_fields = ('job__title', 'category__name')


@admin.register(JobSkillJob)
class JobSkillJobAdmin(admin.ModelAdmin):
    list_display = ('job', 'skill', 'is_required')
    list_filter = ('is_required', 'skill')
    search_fields = ('job__title', 'skill__name') 

============================================================
FILE: backend/job-service/jobs/apps.py
============================================================
from django.apps import AppConfig
from django.utils.translation import gettext_lazy as _


class JobsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'jobs'
    verbose_name = _('Jobs')
    
    def ready(self):
        """Import signals when the app is ready."""
        import jobs.signals 

============================================================
FILE: backend/job-service/jobs/models.py
============================================================
from django.db import models
from django.utils.translation import gettext_lazy as _
from django.utils import timezone


class Company(models.Model):
    """
    Company model for job postings.
    This is owned by the job service and contains company information.
    """
    
    name = models.CharField(max_length=255, help_text=_("Company name"))
    description = models.TextField(blank=True, help_text=_("Company description"))
    website = models.URLField(blank=True, help_text=_("Company website"))
    logo = models.ImageField(upload_to='company_logos/', blank=True, null=True, help_text=_("Company logo"))
    industry = models.CharField(max_length=100, blank=True, help_text=_("Company industry"))
    
    SIZE_CHOICES = [
        ('startup', _('Startup')),
        ('small', _('Small (1-50 employees)')),
        ('medium', _('Medium (51-200 employees)')),
        ('large', _('Large (200+ employees)')),
    ]
    
    size = models.CharField(max_length=50, choices=SIZE_CHOICES, blank=True, help_text=_("Company size"))
    founded_year = models.IntegerField(blank=True, null=True, help_text=_("Year company was founded"))
    location = models.CharField(max_length=255, blank=True, help_text=_("Company location"))
    is_verified = models.BooleanField(default=False, help_text=_("Whether the company is verified"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('Company')
        verbose_name_plural = _('Companies')
        db_table = 'companies'
    
    def __str__(self):
        return self.name


class JobCategory(models.Model):
    """
    Job categories for organizing jobs.
    """
    
    name = models.CharField(max_length=100, unique=True, help_text=_("Category name"))
    description = models.TextField(blank=True, help_text=_("Category description"))
    parent = models.ForeignKey('self', on_delete=models.CASCADE, blank=True, null=True, help_text=_("Parent category"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Job Category')
        verbose_name_plural = _('Job Categories')
        db_table = 'job_categories'
    
    def __str__(self):
        return self.name


class JobSkill(models.Model):
    """
    Skills that can be associated with jobs.
    """
    
    name = models.CharField(max_length=100, unique=True, help_text=_("Skill name"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Job Skill')
        verbose_name_plural = _('Job Skills')
        db_table = 'job_skills'
    
    def __str__(self):
        return self.name


class Job(models.Model):
    """
    Job posting model.
    This is the core model for the job service.
    """
    
    title = models.CharField(max_length=255, help_text=_("Job title"))
    description = models.TextField(help_text=_("Job description"))
    requirements = models.TextField(blank=True, help_text=_("Job requirements"))
    responsibilities = models.TextField(blank=True, help_text=_("Job responsibilities"))
    
    # Foreign keys
    company = models.ForeignKey(Company, on_delete=models.CASCADE, related_name='jobs', help_text=_("Company posting the job"))
    employer_id = models.BigIntegerField(help_text=_("User ID of the employer (from user-service)"))
    
    # Job details
    JOB_TYPE_CHOICES = [
        ('full_time', _('Full Time')),
        ('part_time', _('Part Time')),
        ('contract', _('Contract')),
        ('internship', _('Internship')),
        ('freelance', _('Freelance')),
    ]
    
    job_type = models.CharField(max_length=50, choices=JOB_TYPE_CHOICES, default='full_time', help_text=_("Type of job"))
    
    EXPERIENCE_LEVEL_CHOICES = [
        ('entry', _('Entry Level')),
        ('mid', _('Mid Level')),
        ('senior', _('Senior Level')),
        ('executive', _('Executive Level')),
    ]
    
    experience_level = models.CharField(max_length=50, choices=EXPERIENCE_LEVEL_CHOICES, default='entry', help_text=_("Experience level required"))
    
    # Salary information
    salary_min = models.DecimalField(max_digits=10, decimal_places=2, blank=True, null=True, help_text=_("Minimum salary"))
    salary_max = models.DecimalField(max_digits=10, decimal_places=2, blank=True, null=True, help_text=_("Maximum salary"))
    salary_currency = models.CharField(max_length=3, default='USD', help_text=_("Salary currency"))
    
    # Location and remote work
    location = models.CharField(max_length=255, blank=True, help_text=_("Job location"))
    is_remote = models.BooleanField(default=False, help_text=_("Whether the job is remote"))
    
    # Status and dates
    is_active = models.BooleanField(default=True, help_text=_("Whether the job posting is active"))
    application_deadline = models.DateField(blank=True, null=True, help_text=_("Application deadline"))
    
    # Many-to-many relationships
    categories = models.ManyToManyField(JobCategory, through='JobCategoryJob', related_name='jobs', help_text=_("Job categories"))
    skills = models.ManyToManyField(JobSkill, through='JobSkillJob', related_name='jobs', help_text=_("Job skills"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('Job')
        verbose_name_plural = _('Jobs')
        db_table = 'jobs'
        ordering = ['-created_at']
    
    def __str__(self):
        return self.title
    
    @property
    def salary_range(self):
        """Return formatted salary range."""
        if self.salary_min and self.salary_max:
            return f"{self.salary_currency} {self.salary_min:,.0f} - {self.salary_max:,.0f}"
        elif self.salary_min:
            return f"{self.salary_currency} {self.salary_min:,.0f}+"
        elif self.salary_max:
            return f"Up to {self.salary_currency} {self.salary_max:,.0f}"
        return "Salary not specified"


class JobCategoryJob(models.Model):
    """
    Through model for Job-Category many-to-many relationship.
    """
    
    job = models.ForeignKey(Job, on_delete=models.CASCADE)
    category = models.ForeignKey(JobCategory, on_delete=models.CASCADE)
    
    class Meta:
        db_table = 'job_categories_jobs'
        unique_together = ('job', 'category')
    
    def __str__(self):
        return f"{self.job.title} - {self.category.name}"


class JobSkillJob(models.Model):
    """
    Through model for Job-Skill many-to-many relationship.
    """
    
    job = models.ForeignKey(Job, on_delete=models.CASCADE)
    skill = models.ForeignKey(JobSkill, on_delete=models.CASCADE)
    is_required = models.BooleanField(default=False, help_text=_("Whether this skill is required"))
    
    class Meta:
        db_table = 'job_skills_jobs'
        unique_together = ('job', 'skill')
    
    def __str__(self):
        return f"{self.job.title} - {self.skill.name}"


class UserProfileCache(models.Model):
    """
    Cache user data from User Service to avoid frequent API calls
    This maintains referential integrity while preserving service isolation
    """
    user_id = models.BigIntegerField(unique=True, db_index=True)
    username = models.CharField(max_length=150)
    email = models.CharField(max_length=254)
    first_name = models.CharField(max_length=150, blank=True)
    last_name = models.CharField(max_length=150, blank=True)
    full_name = models.CharField(max_length=300, blank=True)
    user_type = models.CharField(max_length=20)
    is_active = models.BooleanField(default=True)
    
    # Metadata
    last_synced = models.DateTimeField(auto_now=True)
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        db_table = 'user_profile_cache'
        indexes = [
            models.Index(fields=['user_type', 'is_active']),
            models.Index(fields=['last_synced']),
        ]
    
    def __str__(self):
        return f"{self.username} (ID: {self.user_id})"
    
    @property
    def is_stale(self, max_age_hours=24):
        """Check if cached data is stale"""
        from datetime import timedelta
        max_age = timezone.now() - timedelta(hours=max_age_hours)
        return self.last_synced < max_age

# Extend Job with helpers without altering existing fields
def _job_get_employer_info(self):
    try:
        return UserProfileCache.objects.get(user_id=self.employer_id)
    except UserProfileCache.DoesNotExist:
        return None

@property
def _job_employer_name(self):
    employer = self.get_employer_info()
    return employer.full_name if employer else f"User {self.employer_id}"

# Bind helper methods to Job
Job.get_employer_info = _job_get_employer_info
Job.employer_name = _job_employer_name 

============================================================
FILE: backend/job-service/jobs/serializers.py
============================================================
from rest_framework import serializers
from .models import Job, Company, JobCategory, JobSkill, JobCategoryJob, JobSkillJob


class CompanySerializer(serializers.ModelSerializer):
    class Meta:
        model = Company
        fields = '__all__'
        read_only_fields = ['created_at', 'updated_at']


class JobCategorySerializer(serializers.ModelSerializer):
    class Meta:
        model = JobCategory
        fields = '__all__'
        read_only_fields = ['created_at']


class JobSkillSerializer(serializers.ModelSerializer):
    class Meta:
        model = JobSkill
        fields = '__all__'
        read_only_fields = ['created_at']


class JobSerializer(serializers.ModelSerializer):
    company = CompanySerializer(read_only=True)
    categories = JobCategorySerializer(many=True, read_only=True)
    skills = JobSkillSerializer(many=True, read_only=True)
    salary_range = serializers.ReadOnlyField()
    
    class Meta:
        model = Job
        fields = '__all__'
        read_only_fields = ['created_at', 'updated_at', 'employer_id']
    
    def create(self, validated_data):
        # Handle many-to-many relationships
        categories_data = self.context.get('categories', [])
        skills_data = self.context.get('skills', [])
        
        job = Job.objects.create(**validated_data)
        
        # Add categories
        for category_id in categories_data:
            try:
                category = JobCategory.objects.get(id=category_id)
                JobCategoryJob.objects.create(job=job, category=category)
            except JobCategory.DoesNotExist:
                pass
        
        # Add skills
        for skill_data in skills_data:
            skill_id = skill_data.get('skill_id')
            is_required = skill_data.get('is_required', False)
            try:
                skill = JobSkill.objects.get(id=skill_id)
                JobSkillJob.objects.create(job=job, skill=skill, is_required=is_required)
            except JobSkill.DoesNotExist:
                pass
        
        return job 

============================================================
FILE: backend/job-service/jobs/signals.py
============================================================
from django.db.models.signals import post_save, post_delete
from django.dispatch import receiver
from .models import Job, Company


@receiver(post_save, sender=Job)
def update_job_search_index(sender, instance, created, **kwargs):
    """
    Signal to update search index when a job is created or updated.
    """
    if created:
        # This would typically involve updating the search index
        # for the job in the search service
        pass


@receiver(post_save, sender=Company)
def update_company_search_index(sender, instance, created, **kwargs):
    """
    Signal to update search index when a company is created or updated.
    """
    if created:
        # This would typically involve updating the search index
        # for the company in the search service
        pass 

============================================================
FILE: backend/job-service/jobs/tests.py
============================================================
from django.test import TestCase
from django.contrib.auth import get_user_model
from .models import Company, Job, JobCategory, JobSkill

User = get_user_model()


class JobModelTest(TestCase):
    def setUp(self):
        self.company = Company.objects.create(
            name="Test Company",
            description="A test company",
            industry="Technology",
            location="San Francisco"
        )
        
        self.category = JobCategory.objects.create(
            name="Software Development"
        )
        
        self.skill = JobSkill.objects.create(
            name="Python"
        )
        
        self.job = Job.objects.create(
            title="Software Engineer",
            description="A software engineering position",
            company=self.company,
            employer_id=1,
            job_type="full_time",
            experience_level="mid"
        )

    def test_job_creation(self):
        self.assertEqual(self.job.title, "Software Engineer")
        self.assertEqual(self.job.company, self.company)
        self.assertEqual(self.job.job_type, "full_time")

    def test_job_salary_range(self):
        self.job.salary_min = 80000
        self.job.salary_max = 120000
        self.job.salary_currency = "USD"
        self.assertEqual(self.job.salary_range, "USD 80,000 - 120,000")


class CompanyModelTest(TestCase):
    def setUp(self):
        self.company = Company.objects.create(
            name="Test Company",
            description="A test company",
            industry="Technology"
        )

    def test_company_creation(self):
        self.assertEqual(self.company.name, "Test Company")
        self.assertEqual(self.company.industry, "Technology")
        self.assertFalse(self.company.is_verified) 

============================================================
FILE: backend/job-service/jobs/urls.py
============================================================
from django.urls import path
from . import views

app_name = 'jobs'

urlpatterns = [
    # Job-related endpoints
    path('', views.job_list, name='job_list'),
    path('<int:job_id>/', views.job_detail, name='job_detail'),
    path('create/', views.job_create, name='job_create'),
    path('<int:job_id>/update/', views.job_update, name='job_update'),
    path('<int:job_id>/delete/', views.job_delete, name='job_delete'),
    
    # Company-related endpoints
    path('companies/', views.company_list, name='company_list'),
    path('companies/<int:company_id>/', views.company_detail, name='company_detail'),
    path('companies/create/', views.company_create, name='company_create'),
    
    # Category and skill endpoints
    path('categories/', views.category_list, name='category_list'),
    path('skills/', views.skill_list, name='skill_list'),
] 

============================================================
FILE: backend/job-service/jobs/views.py
============================================================
from rest_framework import generics, status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.response import Response
from django.shortcuts import get_object_or_404
from .models import Job, Company, JobCategory, JobSkill
from .serializers import JobSerializer, CompanySerializer, JobCategorySerializer, JobSkillSerializer


@api_view(['GET'])
@permission_classes([AllowAny])
def job_list(request):
    """List all jobs"""
    jobs = Job.objects.filter(is_active=True)
    serializer = JobSerializer(jobs, many=True)
    return Response(serializer.data)


@api_view(['GET'])
@permission_classes([AllowAny])
def job_detail(request, job_id):
    """Get job details"""
    job = get_object_or_404(Job, id=job_id, is_active=True)
    serializer = JobSerializer(job)
    return Response(serializer.data)


@api_view(['POST'])
@permission_classes([IsAuthenticated])
def job_create(request):
    """Create a new job"""
    serializer = JobSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save(employer_id=request.user.id)
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['PUT', 'PATCH'])
@permission_classes([IsAuthenticated])
def job_update(request, job_id):
    """Update a job"""
    job = get_object_or_404(Job, id=job_id)
    serializer = JobSerializer(job, data=request.data, partial=request.method == 'PATCH')
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['DELETE'])
@permission_classes([IsAuthenticated])
def job_delete(request, job_id):
    """Delete a job"""
    job = get_object_or_404(Job, id=job_id)
    job.is_active = False
    job.save()
    return Response(status=status.HTTP_204_NO_CONTENT)


@api_view(['GET'])
@permission_classes([AllowAny])
def company_list(request):
    """List all companies"""
    companies = Company.objects.all()
    serializer = CompanySerializer(companies, many=True)
    return Response(serializer.data)


@api_view(['GET'])
@permission_classes([AllowAny])
def company_detail(request, company_id):
    """Get company details"""
    company = get_object_or_404(Company, id=company_id)
    serializer = CompanySerializer(company)
    return Response(serializer.data)


@api_view(['POST'])
@permission_classes([IsAuthenticated])
def company_create(request):
    """Create a new company"""
    serializer = CompanySerializer(data=request.data)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['GET'])
@permission_classes([AllowAny])
def category_list(request):
    """List all job categories"""
    categories = JobCategory.objects.all()
    serializer = JobCategorySerializer(categories, many=True)
    return Response(serializer.data)


@api_view(['GET'])
@permission_classes([AllowAny])
def skill_list(request):
    """List all job skills"""
    skills = JobSkill.objects.all()
    serializer = JobSkillSerializer(skills, many=True)
    return Response(serializer.data) 

============================================================
FILE: backend/job-service/events.py
============================================================
import logging
from django.conf import settings
from shared.kafka_utils import get_event_publisher
from shared.events import JobCreatedEvent, JobUpdatedEvent, JobDeletedEvent, CompanyCreatedEvent
import uuid
from django.utils import timezone

logger = logging.getLogger(__name__)

class JobEventPublisher:
    """Publisher for job-related events"""
    
    def __init__(self):
        self.publisher = get_event_publisher(settings.KAFKA_BOOTSTRAP_SERVERS)
        self.topic = settings.KAFKA_TOPICS['JOB_EVENTS']
        self.service_name = 'job-service'
    
    def publish_job_created(self, job):
        """Publish job created event"""
        try:
            event = JobCreatedEvent(
                event_id=str(uuid.uuid4()),
                timestamp=timezone.now().isoformat(),
                service_name=self.service_name,
                job_id=job.id,
                title=job.title,
                company_id=job.company.id,
                employer_id=job.employer_id,
                job_type=job.job_type,
                location=job.location or '',
                is_remote=job.is_remote,
                salary_min=float(job.salary_min) if job.salary_min else None,
                salary_max=float(job.salary_max) if job.salary_max else None
            )
            
            self.publisher.publish_event(
                topic=self.topic,
                event_type='job_created',
                data=event.to_dict(),
                key=str(job.id),
                service_name=self.service_name
            )
            
            logger.info(f"Published job_created event for job {job.id}")
            
        except Exception as e:
            logger.error(f"Failed to publish job_created event: {str(e)}")
    
    def publish_job_updated(self, job, changes=None):
        """Publish job updated event"""
        try:
            event = JobUpdatedEvent(
                event_id=str(uuid.uuid4()),
                timestamp=timezone.now().isoformat(),
                service_name=self.service_name,
                job_id=job.id,
                title=job.title,
                company_id=job.company.id,
                employer_id=job.employer_id,
                changes=changes or {}
            )
            
            self.publisher.publish_event(
                topic=self.topic,
                event_type='job_updated',
                data=event.to_dict(),
                key=str(job.id),
                service_name=self.service_name
            )
            
            logger.info(f"Published job_updated event for job {job.id}")
            
        except Exception as e:
            logger.error(f"Failed to publish job_updated event: {str(e)}")
    
    def publish_job_deleted(self, job_id, employer_id):
        """Publish job deleted event"""
        try:
            event = JobDeletedEvent(
                event_id=str(uuid.uuid4()),
                timestamp=timezone.now().isoformat(),
                service_name=self.service_name,
                job_id=job_id,
                employer_id=employer_id,
            )
            
            self.publisher.publish_event(
                topic=self.topic,
                event_type='job_deleted',
                data=event.to_dict(),
                key=str(job_id),
                service_name=self.service_name
            )
            
            logger.info(f"Published job_deleted event for job {job_id}")
            
        except Exception as e:
            logger.error(f"Failed to publish job_deleted event: {str(e)}")
 
    def publish_company_created(self, company):
        """Publish company created event"""
        try:
            event = CompanyCreatedEvent(
                event_id=str(uuid.uuid4()),
                timestamp=timezone.now().isoformat(),
                service_name=self.service_name,
                company_id=company.id,
                name=company.name,
                industry=company.industry,
                size=company.size,
            )
            
            self.publisher.publish_event(
                topic=self.topic,
                event_type='company_created',
                data=event.to_dict(),
                key=str(company.id),
                service_name=self.service_name
            )
            
            logger.info(f"Published company_created event for company {company.id}")
            
        except Exception as e:
            logger.error(f"Failed to publish company_created event: {str(e)}")

============================================================
FILE: backend/job-service/manage.py
============================================================
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'job_service.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main() 

============================================================
FILE: backend/job-service/requirements.txt
============================================================
Django==4.2.7
djangorestframework==3.14.0
djangorestframework-simplejwt==5.3.0
django-cors-headers==4.3.1
psycopg[binary]==3.2.9
python-decouple==3.8
django-extensions==3.2.3
requests==2.31.0
celery==5.3.4
redis==5.0.1
Pillow==11.3.0
kafka-python==2.0.2 

============================================================
FILE: backend/notification-service/notification_service/__init__.py
============================================================
 

============================================================
FILE: backend/notification-service/notification_service/asgi.py
============================================================
"""
ASGI config for notification_service project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'notification_service.settings')

application = get_asgi_application() 

============================================================
FILE: backend/notification-service/notification_service/settings.py
============================================================
import os
from pathlib import Path
from datetime import timedelta
from decouple import config

BASE_DIR = Path(__file__).resolve().parent.parent

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config('SECRET_KEY', default='django-insecure-local-dev-key-change-in-production')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=True, cast=bool)

ALLOWED_HOSTS = ['localhost', '127.0.0.1']

# Application definition
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party apps
    'rest_framework',
    'rest_framework_simplejwt',
    'corsheaders',
    'django_extensions',
    
    # Local apps
    'notifications',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'notification_service.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'notification_service.wsgi.application'

# Database - Using PostgreSQL for microservice
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': config('DB_NAME', default='notifications_db'),
        'USER': config('DB_USER', default='postgres'),
        'PASSWORD': config('DB_PASSWORD', default='postgres123'),
        'HOST': config('DB_HOST', default='localhost'),
        'PORT': config('DB_PORT', default='5432'),
    }
}

# Password validation
AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

# Rest Framework Configuration
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}

# JWT Configuration
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
    'BLACKLIST_AFTER_ROTATION': True,
}

# CORS Settings (for local development)
CORS_ALLOW_ALL_ORIGINS = True
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
]

# Internationalization
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

# Media files
MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Microservice Configuration
USER_SERVICE_URL = config('USER_SERVICE_URL', default='http://localhost:8001')
JOB_SERVICE_URL = config('JOB_SERVICE_URL', default='http://localhost:8002')
APPLICATION_SERVICE_URL = config('APPLICATION_SERVICE_URL', default='http://localhost:8003') 

============================================================
FILE: backend/notification-service/notification_service/urls.py
============================================================
from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/notifications/', include('notifications.urls')),
]

# Serve media files during development
if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 

============================================================
FILE: backend/notification-service/notification_service/wsgi.py
============================================================
"""
WSGI config for notification_service project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'notification_service.settings')

application = get_wsgi_application() 

============================================================
FILE: backend/notification-service/notifications/__init__.py
============================================================
 

============================================================
FILE: backend/notification-service/notifications/admin.py
============================================================
from django.contrib import admin
from .models import Notification, NotificationTemplate, UserNotificationPreference


@admin.register(NotificationTemplate)
class NotificationTemplateAdmin(admin.ModelAdmin):
    list_display = ('name', 'notification_type', 'is_active', 'created_at')
    list_filter = ('notification_type', 'is_active', 'created_at')
    search_fields = ('name', 'subject', 'body')
    ordering = ('name',)


@admin.register(Notification)
class NotificationAdmin(admin.ModelAdmin):
    list_display = ('user_id', 'title', 'notification_type', 'status', 'created_at')
    list_filter = ('notification_type', 'status', 'created_at')
    search_fields = ('title', 'message', 'user_id')
    ordering = ('-created_at',)


@admin.register(UserNotificationPreference)
class UserNotificationPreferenceAdmin(admin.ModelAdmin):
    list_display = ('user_id', 'notification_type', 'is_enabled', 'created_at')
    list_filter = ('notification_type', 'is_enabled', 'created_at')
    search_fields = ('user_id',)
    ordering = ('user_id', 'notification_type') 

============================================================
FILE: backend/notification-service/notifications/apps.py
============================================================
from django.apps import AppConfig
from django.utils.translation import gettext_lazy as _


class NotificationsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'notifications'
    verbose_name = _('Notifications')
    
    def ready(self):
        """Import signals when the app is ready."""
        import notifications.signals 

============================================================
FILE: backend/notification-service/notifications/models.py
============================================================
from django.db import models
from django.utils.translation import gettext_lazy as _


class NotificationTemplate(models.Model):
    """
    Templates for notifications (email, SMS, push notifications).
    """
    
    name = models.CharField(max_length=100, unique=True, help_text=_("Template name"))
    subject = models.CharField(max_length=255, blank=True, help_text=_("Email subject (for email notifications)"))
    body = models.TextField(help_text=_("Notification body content"))
    
    NOTIFICATION_TYPE_CHOICES = [
        ('email', _('Email')),
        ('push', _('Push Notification')),
        ('sms', _('SMS')),
        ('in_app', _('In-App Notification')),
    ]
    
    notification_type = models.CharField(max_length=50, choices=NOTIFICATION_TYPE_CHOICES, help_text=_("Type of notification"))
    is_active = models.BooleanField(default=True, help_text=_("Whether the template is active"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('Notification Template')
        verbose_name_plural = _('Notification Templates')
        db_table = 'notification_templates'
    
    def __str__(self):
        return f"{self.name} - {self.notification_type}"


class Notification(models.Model):
    """
    Individual notifications sent to users.
    """
    
    user_id = models.BigIntegerField(help_text=_("User ID from user-service"))
    title = models.CharField(max_length=255, help_text=_("Notification title"))
    message = models.TextField(help_text=_("Notification message"))
    
    NOTIFICATION_TYPE_CHOICES = [
        ('email', _('Email')),
        ('push', _('Push Notification')),
        ('sms', _('SMS')),
        ('in_app', _('In-App Notification')),
    ]
    
    notification_type = models.CharField(max_length=50, choices=NOTIFICATION_TYPE_CHOICES, help_text=_("Type of notification"))
    
    STATUS_CHOICES = [
        ('pending', _('Pending')),
        ('sent', _('Sent')),
        ('failed', _('Failed')),
        ('read', _('Read')),
    ]
    
    status = models.CharField(max_length=50, choices=STATUS_CHOICES, default='pending', help_text=_("Notification status"))
    metadata = models.JSONField(default=dict, blank=True, help_text=_("Additional metadata for the notification"))
    
    # Timestamps
    sent_at = models.DateTimeField(blank=True, null=True, help_text=_("When the notification was sent"))
    read_at = models.DateTimeField(blank=True, null=True, help_text=_("When the notification was read"))
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Notification')
        verbose_name_plural = _('Notifications')
        db_table = 'notifications'
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['user_id', 'status']),
            models.Index(fields=['notification_type', 'status']),
            models.Index(fields=['created_at']),
        ]
    
    def __str__(self):
        return f"Notification to User {self.user_id}: {self.title}"


class UserNotificationPreference(models.Model):
    """
    User preferences for notification types.
    """
    
    user_id = models.BigIntegerField(help_text=_("User ID from user-service"))
    notification_type = models.CharField(max_length=50, choices=Notification.NOTIFICATION_TYPE_CHOICES, help_text=_("Type of notification"))
    is_enabled = models.BooleanField(default=True, help_text=_("Whether this notification type is enabled for the user"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('User Notification Preference')
        verbose_name_plural = _('User Notification Preferences')
        db_table = 'user_notification_preferences'
        unique_together = ('user_id', 'notification_type')
        indexes = [
            models.Index(fields=['user_id', 'is_enabled']),
        ]
    
    def __str__(self):
        return f"User {self.user_id} - {self.notification_type}: {'Enabled' if self.is_enabled else 'Disabled'}" 

============================================================
FILE: backend/notification-service/notifications/serializers.py
============================================================
from rest_framework import serializers
from .models import Notification, NotificationTemplate, UserNotificationPreference


class NotificationTemplateSerializer(serializers.ModelSerializer):
    class Meta:
        model = NotificationTemplate
        fields = '__all__'
        read_only_fields = ['created_at', 'updated_at']


class UserNotificationPreferenceSerializer(serializers.ModelSerializer):
    class Meta:
        model = UserNotificationPreference
        fields = '__all__'
        read_only_fields = ['created_at', 'updated_at']


class NotificationSerializer(serializers.ModelSerializer):
    class Meta:
        model = Notification
        fields = '__all__'
        read_only_fields = ['created_at', 'sent_at', 'read_at'] 

============================================================
FILE: backend/notification-service/notifications/signals.py
============================================================
from django.db.models.signals import post_save
from django.dispatch import receiver
from .models import Notification


@receiver(post_save, sender=Notification)
def send_notification(sender, instance, created, **kwargs):
    """
    Signal to send notification when a new notification is created.
    """
    if created and instance.status == 'pending':
        # This would typically involve sending the notification
        # via email, SMS, push notification, etc.
        # For now, we'll just mark it as sent
        # Note: We need to use update to avoid triggering the signal again
        Notification.objects.filter(id=instance.id).update(status='sent') 

============================================================
FILE: backend/notification-service/notifications/urls.py
============================================================
from django.urls import path
from . import views

app_name = 'notifications'

urlpatterns = [
    path('', views.notification_list, name='notification_list'),
    path('<int:notification_id>/', views.notification_detail, name='notification_detail'),
    path('<int:notification_id>/read/', views.mark_as_read, name='mark_as_read'),
    path('preferences/', views.notification_preferences, name='notification_preferences'),
    path('templates/', views.template_list, name='template_list'),
] 

============================================================
FILE: backend/notification-service/notifications/views.py
============================================================
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.shortcuts import get_object_or_404
from .models import Notification, NotificationTemplate, UserNotificationPreference
from .serializers import NotificationSerializer, NotificationTemplateSerializer, UserNotificationPreferenceSerializer


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def notification_list(request):
    """List notifications for the current user"""
    notifications = Notification.objects.filter(user_id=request.user.id).order_by('-created_at')
    serializer = NotificationSerializer(notifications, many=True)
    return Response(serializer.data)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def notification_detail(request, notification_id):
    """Get notification details"""
    notification = get_object_or_404(Notification, id=notification_id, user_id=request.user.id)
    serializer = NotificationSerializer(notification)
    return Response(serializer.data)


@api_view(['POST'])
@permission_classes([IsAuthenticated])
def mark_as_read(request, notification_id):
    """Mark notification as read"""
    notification = get_object_or_404(Notification, id=notification_id, user_id=request.user.id)
    notification.status = 'read'
    notification.save()
    return Response({'status': 'marked as read'})


@api_view(['GET', 'PUT'])
@permission_classes([IsAuthenticated])
def notification_preferences(request):
    """Get or update notification preferences"""
    if request.method == 'GET':
        preferences = UserNotificationPreference.objects.filter(user_id=request.user.id)
        serializer = UserNotificationPreferenceSerializer(preferences, many=True)
        return Response(serializer.data)
    
    elif request.method == 'PUT':
        # Update preferences
        for preference_data in request.data:
            preference, created = UserNotificationPreference.objects.get_or_create(
                user_id=request.user.id,
                notification_type=preference_data['notification_type']
            )
            preference.is_enabled = preference_data.get('is_enabled', True)
            preference.save()
        
        return Response({'status': 'preferences updated'})


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def template_list(request):
    """List notification templates"""
    templates = NotificationTemplate.objects.filter(is_active=True)
    serializer = NotificationTemplateSerializer(templates, many=True)
    return Response(serializer.data) 

============================================================
FILE: backend/notification-service/manage.py
============================================================
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'notification_service.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main() 

============================================================
FILE: backend/notification-service/requirements.txt
============================================================
Django==4.2.7
djangorestframework==3.14.0
djangorestframework-simplejwt==5.3.0
django-cors-headers==4.3.1
psycopg[binary]==3.2.9
python-decouple==3.8
django-extensions==3.2.3
requests==2.31.0
celery==5.3.4
redis==5.0.1
Pillow==11.3.0
kafka-python==2.0.2 

============================================================
FILE: backend/search-service/search/__init__.py
============================================================
 

============================================================
FILE: backend/search-service/search/admin.py
============================================================
from django.contrib import admin
from .models import SearchIndex, SearchHistory, SearchAnalytics


@admin.register(SearchIndex)
class SearchIndexAdmin(admin.ModelAdmin):
    list_display = ('entity_type', 'entity_id', 'created_at', 'updated_at')
    list_filter = ('entity_type', 'created_at')
    search_fields = ('entity_id',)
    ordering = ('-created_at',)


@admin.register(SearchHistory)
class SearchHistoryAdmin(admin.ModelAdmin):
    list_display = ('user_id', 'query', 'results_count', 'created_at')
    list_filter = ('created_at',)
    search_fields = ('query', 'user_id')
    ordering = ('-created_at',)


@admin.register(SearchAnalytics)
class SearchAnalyticsAdmin(admin.ModelAdmin):
    list_display = ('query', 'search_count', 'last_searched_at', 'created_at')
    list_filter = ('created_at',)
    search_fields = ('query',)
    ordering = ('-search_count',) 

============================================================
FILE: backend/search-service/search/apps.py
============================================================
from django.apps import AppConfig
from django.utils.translation import gettext_lazy as _


class SearchConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'search'
    verbose_name = _('Search')
    
    def ready(self):
        """Import signals when the app is ready."""
        import search.signals 

============================================================
FILE: backend/search-service/search/models.py
============================================================
from django.db import models
from django.contrib.postgres.search import SearchVectorField
from django.contrib.postgres.indexes import GinIndex
from django.utils.translation import gettext_lazy as _


class SearchIndex(models.Model):
    """
    Search index for full-text search across different entities.
    This model stores searchable content from other services.
    """
    
    ENTITY_TYPE_CHOICES = [
        ('job', _('Job')),
        ('company', _('Company')),
        ('user', _('User')),
    ]
    
    entity_type = models.CharField(max_length=50, choices=ENTITY_TYPE_CHOICES, help_text=_("Type of entity being indexed"))
    entity_id = models.BigIntegerField(help_text=_("ID of the entity from the source service"))
    search_vector = SearchVectorField(blank=True, help_text=_("Full-text search vector"))
    metadata = models.JSONField(default=dict, blank=True, help_text=_("Additional metadata for search"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('Search Index')
        verbose_name_plural = _('Search Indexes')
        db_table = 'search_indexes'
        unique_together = ('entity_type', 'entity_id')
        indexes = [
            GinIndex(fields=['search_vector']),
            models.Index(fields=['entity_type', 'entity_id']),
        ]
    
    def __str__(self):
        return f"{self.entity_type} - {self.entity_id}"


class SearchHistory(models.Model):
    """
    Search history for analytics and user experience improvements.
    """
    
    user_id = models.BigIntegerField(help_text=_("User ID from user-service"))
    query = models.TextField(help_text=_("Search query"))
    filters = models.JSONField(default=dict, blank=True, help_text=_("Applied filters"))
    results_count = models.IntegerField(blank=True, null=True, help_text=_("Number of results returned"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Search History')
        verbose_name_plural = _('Search Histories')
        db_table = 'search_history'
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['user_id', 'created_at']),
            models.Index(fields=['query']),
        ]
    
    def __str__(self):
        return f"Search by User {self.user_id}: {self.query[:50]}..."


class SearchAnalytics(models.Model):
    """
    Analytics data for search queries and patterns.
    """
    
    query = models.TextField(help_text=_("Search query"))
    search_count = models.IntegerField(default=1, help_text=_("Number of times this query was searched"))
    last_searched_at = models.DateTimeField(auto_now=True, help_text=_("Last time this query was searched"))
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        verbose_name = _('Search Analytics')
        verbose_name_plural = _('Search Analytics')
        db_table = 'search_analytics'
        unique_together = ('query',)
        ordering = ['-search_count']
        indexes = [
            models.Index(fields=['query']),
            models.Index(fields=['search_count']),
        ]
    
    def __str__(self):
        return f"{self.query} - {self.search_count} searches" 

============================================================
FILE: backend/search-service/search/signals.py
============================================================
from django.db.models.signals import post_save, post_delete
from django.dispatch import receiver
from .models import SearchIndex


@receiver(post_save, sender=SearchIndex)
def update_search_vector(sender, instance, **kwargs):
    """
    Signal to update search vector when search index is saved.
    """
    # This would typically involve updating the search vector
    # based on the entity type and metadata
    pass


@receiver(post_delete, sender=SearchIndex)
def cleanup_search_index(sender, instance, **kwargs):
    """
    Signal to cleanup when search index is deleted.
    """
    # Cleanup any related search data
    pass 

============================================================
FILE: backend/search-service/search/urls.py
============================================================
from django.urls import path
from . import views

app_name = 'search'

urlpatterns = [
    path('', views.search, name='search'),
    path('history/', views.search_history, name='search_history'),
    path('analytics/', views.search_analytics, name='search_analytics'),
] 

============================================================
FILE: backend/search-service/search/views.py
============================================================
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.response import Response
from django.contrib.postgres.search import SearchQuery, SearchRank
from .models import SearchIndex, SearchHistory, SearchAnalytics


@api_view(['GET'])
@permission_classes([AllowAny])
def search(request):
    """Search across different entities"""
    query = request.GET.get('q', '')
    entity_type = request.GET.get('type', '')
    
    if not query:
        return Response({'error': 'Query parameter is required'}, status=status.HTTP_400_BAD_REQUEST)
    
    # Create search query
    search_query = SearchQuery(query, config='english')
    
    # Filter by entity type if specified
    queryset = SearchIndex.objects.filter(search_vector=search_query)
    if entity_type:
        queryset = queryset.filter(entity_type=entity_type)
    
    # Rank results
    queryset = queryset.annotate(rank=SearchRank('search_vector', search_query)).order_by('-rank')
    
    # Limit results
    results = queryset[:50]
    
    # Save search history if user is authenticated
    if request.user.is_authenticated:
        SearchHistory.objects.create(
            user_id=request.user.id,
            query=query,
            filters={'type': entity_type} if entity_type else {},
            results_count=len(results)
        )
    
    # Update search analytics
    analytics, created = SearchAnalytics.objects.get_or_create(query=query)
    if not created:
        analytics.search_count += 1
        analytics.save()
    
    return Response({
        'query': query,
        'results': [{'entity_type': item.entity_type, 'entity_id': item.entity_id, 'rank': item.rank} for item in results],
        'total_results': len(results)
    })


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def search_history(request):
    """Get search history for the current user"""
    history = SearchHistory.objects.filter(user_id=request.user.id).order_by('-created_at')[:20]
    return Response([{
        'query': item.query,
        'filters': item.filters,
        'results_count': item.results_count,
        'created_at': item.created_at
    } for item in history])


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def search_analytics(request):
    """Get search analytics"""
    analytics = SearchAnalytics.objects.order_by('-search_count')[:20]
    return Response([{
        'query': item.query,
        'search_count': item.search_count,
        'last_searched_at': item.last_searched_at
    } for item in analytics]) 

============================================================
FILE: backend/search-service/search_service/__init__.py
============================================================
 

============================================================
FILE: backend/search-service/search_service/asgi.py
============================================================
"""
ASGI config for search_service project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'search_service.settings')

application = get_asgi_application() 

============================================================
FILE: backend/search-service/search_service/settings.py
============================================================
import os
from pathlib import Path
from datetime import timedelta
from decouple import config

BASE_DIR = Path(__file__).resolve().parent.parent

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config('SECRET_KEY', default='django-insecure-local-dev-key-change-in-production')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=True, cast=bool)

ALLOWED_HOSTS = ['localhost', '127.0.0.1']

# Application definition
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party apps
    'rest_framework',
    'rest_framework_simplejwt',
    'corsheaders',
    'django_extensions',
    
    # Local apps
    'search',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'search_service.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'search_service.wsgi.application'

# Database - Using PostgreSQL for microservice
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': config('DB_NAME', default='search_db'),
        'USER': config('DB_USER', default='postgres'),
        'PASSWORD': config('DB_PASSWORD', default='postgres123'),
        'HOST': config('DB_HOST', default='localhost'),
        'PORT': config('DB_PORT', default='5432'),
    }
}

# Password validation
AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

# Rest Framework Configuration
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}

# JWT Configuration
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
    'BLACKLIST_AFTER_ROTATION': True,
}

# CORS Settings (for local development)
CORS_ALLOW_ALL_ORIGINS = True
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
]

# Internationalization
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

# Media files
MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Microservice Configuration
USER_SERVICE_URL = config('USER_SERVICE_URL', default='http://localhost:8001')
JOB_SERVICE_URL = config('JOB_SERVICE_URL', default='http://localhost:8002')
APPLICATION_SERVICE_URL = config('APPLICATION_SERVICE_URL', default='http://localhost:8003') 

============================================================
FILE: backend/search-service/search_service/urls.py
============================================================
from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/search/', include('search.urls')),
]

# Serve media files during development
if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 

============================================================
FILE: backend/search-service/search_service/wsgi.py
============================================================
"""
WSGI config for search_service project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'search_service.settings')

application = get_wsgi_application() 

============================================================
FILE: backend/search-service/manage.py
============================================================
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'search_service.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main() 

============================================================
FILE: backend/search-service/requirements.txt
============================================================
Django==4.2.7
djangorestframework==3.14.0
djangorestframework-simplejwt==5.3.0
django-cors-headers==4.3.1
psycopg[binary]==3.2.9
python-decouple==3.8
django-extensions==3.2.3
requests==2.31.0
celery==5.3.4
redis==5.0.1
Pillow==11.3.0
kafka-python==2.0.2 

============================================================
FILE: backend/shared/__init__.py
============================================================
# Shared utilities package for microservices 

============================================================
FILE: backend/shared/events.py
============================================================
from dataclasses import dataclass, asdict
from typing import Optional, Dict, Any
from datetime import datetime

# User Service Events
@dataclass
class UserCreatedEvent:
    """Event published when a new user is created"""
    event_id: str
    timestamp: str
    service_name: str
    user_id: int
    username: str
    email: str
    user_type: str
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    version: str = "1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

@dataclass
class UserUpdatedEvent:
    """Event published when a user is updated"""
    event_id: str
    timestamp: str
    service_name: str
    user_id: int
    username: str
    email: str
    user_type: str
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    changes: Dict[str, Any] = None
    version: str = "1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

@dataclass
class UserDeletedEvent:
    """Event published when a user is deleted"""
    event_id: str
    timestamp: str
    service_name: str
    user_id: int
    username: str
    version: str = "1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

# Job Service Events
@dataclass
class JobCreatedEvent:
    """Event published when a new job is created"""
    event_id: str
    timestamp: str
    service_name: str
    job_id: int
    title: str
    company_id: int
    employer_id: int
    job_type: str
    location: str
    is_remote: bool
    salary_min: Optional[float] = None
    salary_max: Optional[float] = None
    version: str = "1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

@dataclass
class JobUpdatedEvent:
    """Event published when a job is updated"""
    event_id: str
    timestamp: str
    service_name: str
    job_id: int
    title: str
    company_id: int
    employer_id: int
    changes: Dict[str, Any] = None
    version: str = "1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

@dataclass
class JobDeletedEvent:
    """Event published when a job is deleted"""
    event_id: str
    timestamp: str
    service_name: str
    job_id: int
    employer_id: int
    version: str = "1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

# Company Events
@dataclass
class CompanyCreatedEvent:
    """Event published when a new company is created"""
    event_id: str
    timestamp: str
    service_name: str
    company_id: int
    name: str
    industry: Optional[str] = None
    size: Optional[str] = None
    version: str = "1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self) 

============================================================
FILE: backend/shared/kafka_utils.py
============================================================
import json
import logging
from typing import Dict, Any, Callable, Optional
from kafka import KafkaProducer, KafkaConsumer
from kafka.errors import KafkaError
import threading
import uuid
from datetime import datetime

logger = logging.getLogger(__name__)

class KafkaEventPublisher:
    """Kafka event publisher for microservices"""
    
    def __init__(self, bootstrap_servers=None):
        if bootstrap_servers is None:
            # Default fallback
            bootstrap_servers = ['localhost:9092']
            
        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            key_serializer=lambda v: str(v).encode('utf-8') if v else None,
            acks='all',  # Wait for all replicas
            retries=3,
            max_in_flight_requests_per_connection=1,  # Ensure ordering
            enable_idempotence=True  # Prevent duplicates
        )
    
    def publish_event(self, topic: str, event_type: str, data: Dict[Any, Any], 
                     key: Optional[str] = None, service_name: str = None):
        """
        Publish an event to Kafka topic
        
        Args:
            topic: Kafka topic name
            event_type: Type of event (user_created, job_created, etc.)
            data: Event data payload
            key: Optional partition key
            service_name: Name of the publishing service
        """
        event_payload = {
            'event_id': str(uuid.uuid4()),
            'event_type': event_type,
            'service_name': service_name or 'unknown',
            'timestamp': datetime.now().isoformat(),
            'version': '1.0',
            'data': data
        }
        
        try:
            future = self.producer.send(topic, value=event_payload, key=key)
            record_metadata = future.get(timeout=10)
            
            logger.info(f"Event published successfully: {event_type} to {topic}")
            logger.debug(f"Event metadata: partition={record_metadata.partition}, offset={record_metadata.offset}")
            
        except KafkaError as e:
            logger.error(f"Failed to publish event {event_type}: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error publishing event: {str(e)}")
            raise
    
    def close(self):
        """Close the producer"""
        self.producer.flush()
        self.producer.close()

class KafkaEventConsumer:
    """Kafka event consumer for microservices"""
    
    def __init__(self, topics: list, group_id: str, bootstrap_servers=None):
        if bootstrap_servers is None:
            # Default fallback
            bootstrap_servers = ['localhost:9092']
            
        self.topics = topics
        self.group_id = group_id
        self.consumer = KafkaConsumer(
            *topics,
            bootstrap_servers=bootstrap_servers,
            group_id=group_id,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            key_deserializer=lambda m: m.decode('utf-8') if m else None,
            auto_offset_reset='earliest',
            enable_auto_commit=False,  # Manual commit for better control
            max_poll_records=10  # Process in small batches
        )
        self.event_handlers: Dict[str, Callable] = {}
        self.is_running = False
        
    def register_handler(self, event_type: str, handler: Callable):
        """Register an event handler for a specific event type"""
        self.event_handlers[event_type] = handler
        logger.info(f"Registered handler for event type: {event_type}")
    
    def start_consuming(self):
        """Start consuming events in a separate thread"""
        if self.is_running:
            logger.warning("Consumer is already running")
            return
            
        self.is_running = True
        consumer_thread = threading.Thread(target=self._consume_events, daemon=True)
        consumer_thread.start()
        logger.info(f"Started Kafka consumer for topics: {self.topics}")
    
    def _consume_events(self):
        """Internal method to consume events"""
        try:
            for message in self.consumer:
                if not self.is_running:
                    break
                    
                try:
                    event = message.value
                    event_type = event.get('event_type')
                    
                    logger.info(f"Received event: {event_type} from topic: {message.topic}")
                    
                    # Check for duplicate processing
                    if self._is_duplicate_event(event):
                        logger.warning(f"Duplicate event detected: {event.get('event_id')}")
                        self.consumer.commit()
                        continue
                    
                    # Handle the event
                    if event_type in self.event_handlers:
                        try:
                            self.event_handlers[event_type](event)
                            self.consumer.commit()  # Commit only after successful processing
                            logger.info(f"Successfully processed event: {event_type}")
                            
                        except Exception as handler_error:
                            logger.error(f"Error processing event {event_type}: {str(handler_error)}")
                            # Could implement dead letter queue here
                            
                    else:
                        logger.warning(f"No handler registered for event type: {event_type}")
                        self.consumer.commit()  # Still commit to avoid reprocessing
                        
                except Exception as e:
                    logger.error(f"Error processing message: {str(e)}")
                    
        except Exception as e:
            logger.error(f"Consumer error: {str(e)}")
        finally:
            self.consumer.close()
    
    def _is_duplicate_event(self, event: Dict) -> bool:
        """
        Check if this event has already been processed
        This is a simple implementation - in production, use Redis or database
        """
        # TODO: Implement proper duplicate detection
        # Could use Redis to store processed event IDs with TTL
        return False
    
    def stop_consuming(self):
        """Stop the consumer"""
        self.is_running = False
        self.consumer.close()
        logger.info("Kafka consumer stopped")

# Global instances (initialized in Django apps)
event_publisher = None
event_consumer = None

def get_event_publisher(bootstrap_servers=None) -> KafkaEventPublisher:
    """Get global event publisher instance"""
    global event_publisher
    if event_publisher is None:
        event_publisher = KafkaEventPublisher(bootstrap_servers)
    return event_publisher

def get_event_consumer(topics: list, group_id: str, bootstrap_servers=None) -> KafkaEventConsumer:
    """Get event consumer instance"""
    return KafkaEventConsumer(topics, group_id, bootstrap_servers)

============================================================
FILE: backend/shared/service_registry.py
============================================================
import os
import requests
from typing import Dict, Optional
from urllib.parse import urljoin

class ServiceRegistry:
    """Centralized service discovery and communication"""
    
    _instance = None
    _services = {}
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ServiceRegistry, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.services = {
                'user-service': os.getenv('USER_SERVICE_URL', 'http://localhost:8001'),
                'job-service': os.getenv('JOB_SERVICE_URL', 'http://localhost:8002'),
                'application-service': os.getenv('APPLICATION_SERVICE_URL', 'http://localhost:8003'),
                'search-service': os.getenv('SEARCH_SERVICE_URL', 'http://localhost:8004'),
                'notification-service': os.getenv('NOTIFICATION_SERVICE_URL', 'http://localhost:8005'),
                'analytics-service': os.getenv('ANALYTICS_SERVICE_URL', 'http://localhost:8006'),
            }
            self.initialized = True
    
    def get_service_url(self, service_name: str) -> Optional[str]:
        return self.services.get(service_name)
    
    def make_request(self, service_name: str, endpoint: str, method: str = 'GET', 
                    data: Dict = None, headers: Dict = None):
        """Make HTTP request to another service"""
        base_url = self.get_service_url(service_name)
        if not base_url:
            raise ValueError(f"Service {service_name} not found in registry")
        
        url = urljoin(base_url, endpoint)
        
        try:
            response = requests.request(method, url, json=data, headers=headers, timeout=30)
            response.raise_for_status()
            return response.json() if response.content else {}
        except requests.RequestException as e:
            raise Exception(f"Service communication failed: {str(e)}")

# Global instance
service_registry = ServiceRegistry()

============================================================
FILE: backend/shared/settings.py
============================================================
import os
from pathlib import Path
from datetime import timedelta

BASE_DIR = Path(__file__).resolve().parent.parent

# Common Django settings for all services
DJANGO_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
]

THIRD_PARTY_APPS = [
    'rest_framework',
    'rest_framework_simplejwt',
    'corsheaders',
    'django_extensions',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

# Database configuration
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME', 'job_platform'),
        'USER': os.getenv('DB_USER', 'postgres'),
        'PASSWORD': os.getenv('DB_PASSWORD', 'postgres123'),
        'HOST': os.getenv('DB_HOST', 'localhost'),
        'PORT': os.getenv('DB_PORT', '5432'),
    }
}

# Rest Framework Configuration
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}

# JWT Configuration
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
}

# Redis Configuration
REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')

# CORS Settings
CORS_ALLOW_ALL_ORIGINS = True  # Only for development
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
]

# Internationalization
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

============================================================
FILE: backend/user-service/user_service/asgi.py
============================================================
"""
ASGI config for user_service project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'user_service.settings')

application = get_asgi_application()


============================================================
FILE: backend/user-service/user_service/settings.py
============================================================
import os
import sys
from pathlib import Path
from datetime import timedelta
from decouple import config
import dj_database_url

BASE_DIR = Path(__file__).resolve().parent.parent

# Add shared directory to Python path
shared_path = BASE_DIR.parent / 'shared'
if str(shared_path) not in sys.path:
    sys.path.insert(0, str(shared_path))

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config('SECRET_KEY', default='django-insecure-local-dev-key-change-in-production')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=True, cast=bool)

ALLOWED_HOSTS = ['localhost', '127.0.0.1']

# Application definition
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party apps
    'rest_framework',
    'rest_framework_simplejwt',
    'corsheaders',
    'django_extensions',
    
    # Local apps
    'users',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'user_service.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'user_service.wsgi.application'

# Database - Prefer DATABASE_URL if present, fallback to SQLite for local dev
DATABASE_URL = os.getenv('DATABASE_URL')
if DATABASE_URL:
    DATABASES = {
        'default': dj_database_url.parse(DATABASE_URL, conn_max_age=600)
    }
else:
    DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.sqlite3',
            'NAME': BASE_DIR / 'db.sqlite3',
        }
    }

# Password validation
AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

# Rest Framework Configuration
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}

# JWT Configuration
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
    'BLACKLIST_AFTER_ROTATION': True,
}

# CORS Settings (for local development)
CORS_ALLOW_ALL_ORIGINS = True
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
]

# Internationalization
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_TZ = True

# Static files
STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

# Media files
MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Custom user model
AUTH_USER_MODEL = 'users.User'

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS = config('KAFKA_BOOTSTRAP_SERVERS', default='localhost:9092').split(',')
KAFKA_GROUP_ID = config('KAFKA_GROUP_ID', default='user-service-group')

# Topics
KAFKA_TOPICS = {
    'USER_EVENTS': 'user-events',
    'JOB_EVENTS': 'job-events'
}

# Logging
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
    },
    'handlers': {
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'verbose',
        },
        'file': {
            'level': 'INFO',
            'class': 'logging.FileHandler',
            'filename': 'user_service.log',
            'formatter': 'verbose',
        },
    },
    'loggers': {
        'kafka': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False,
        },
        '': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
        },
    },
}

============================================================
FILE: backend/user-service/user_service/urls.py
============================================================
from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/users/', include('users.urls')),
]

# Serve media files during development
if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)

============================================================
FILE: backend/user-service/user_service/wsgi.py
============================================================
"""
WSGI config for user_service project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'user_service.settings')

application = get_wsgi_application()


============================================================
FILE: backend/user-service/users/migrations/0001_initial.py
============================================================
# Generated by Django 4.2.7 on 2025-08-06 21:31

import django.contrib.auth.models
import django.contrib.auth.validators
from django.db import migrations, models
import django.utils.timezone


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('auth', '0012_alter_user_first_name_max_length'),
    ]

    operations = [
        migrations.CreateModel(
            name='User',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('password', models.CharField(max_length=128, verbose_name='password')),
                ('last_login', models.DateTimeField(blank=True, null=True, verbose_name='last login')),
                ('is_superuser', models.BooleanField(default=False, help_text='Designates that this user has all permissions without explicitly assigning them.', verbose_name='superuser status')),
                ('username', models.CharField(error_messages={'unique': 'A user with that username already exists.'}, help_text='Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only.', max_length=150, unique=True, validators=[django.contrib.auth.validators.UnicodeUsernameValidator()], verbose_name='username')),
                ('first_name', models.CharField(blank=True, max_length=150, verbose_name='first name')),
                ('last_name', models.CharField(blank=True, max_length=150, verbose_name='last name')),
                ('email', models.EmailField(blank=True, max_length=254, verbose_name='email address')),
                ('is_staff', models.BooleanField(default=False, help_text='Designates whether the user can log into this admin site.', verbose_name='staff status')),
                ('date_joined', models.DateTimeField(default=django.utils.timezone.now, verbose_name='date joined')),
                ('phone_number', models.CharField(blank=True, help_text="User's phone number", max_length=15, null=True)),
                ('date_of_birth', models.DateField(blank=True, help_text="User's date of birth", null=True)),
                ('profile_picture', models.ImageField(blank=True, help_text="User's profile picture", null=True, upload_to='profile_pictures/')),
                ('bio', models.TextField(blank=True, help_text="User's bio/description", max_length=500)),
                ('user_type', models.CharField(choices=[('job_seeker', 'Job Seeker'), ('employer', 'Employer'), ('admin', 'Admin')], default='job_seeker', help_text='Type of user', max_length=20)),
                ('is_verified', models.BooleanField(default=False, help_text="Whether the user's email is verified")),
                ('is_active', models.BooleanField(default=True, help_text='Whether the user account is active')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('groups', models.ManyToManyField(blank=True, help_text='The groups this user belongs to. A user will get all permissions granted to each of their groups.', related_name='user_set', related_query_name='user', to='auth.group', verbose_name='groups')),
                ('user_permissions', models.ManyToManyField(blank=True, help_text='Specific permissions for this user.', related_name='user_set', related_query_name='user', to='auth.permission', verbose_name='user permissions')),
            ],
            options={
                'verbose_name': 'User',
                'verbose_name_plural': 'Users',
                'db_table': 'users',
            },
            managers=[
                ('objects', django.contrib.auth.models.UserManager()),
            ],
        ),
    ]


============================================================
FILE: backend/user-service/users/admin.py
============================================================
from django.contrib import admin
from django.contrib.auth.admin import UserAdmin
from django.utils.translation import gettext_lazy as _
from .models import User


@admin.register(User)
class CustomUserAdmin(UserAdmin):
    """Admin configuration for the custom User model."""
    
    list_display = ('username', 'email', 'full_name', 'user_type', 'is_verified', 'is_active', 'date_joined')
    list_filter = ('user_type', 'is_verified', 'is_active', 'is_staff', 'is_superuser', 'date_joined')
    search_fields = ('username', 'email', 'first_name', 'last_name', 'phone_number')
    ordering = ('-date_joined',)
    
    # Fieldsets for the edit form
    fieldsets = (
        (None, {'fields': ('username', 'password')}),
        (_('Personal info'), {
            'fields': (
                'first_name', 'last_name', 'email', 'phone_number', 
                'date_of_birth', 'profile_picture', 'bio'
            )
        }),
        (_('User Type & Status'), {
            'fields': ('user_type', 'is_verified')
        }),
        (_('Permissions'), {
            'fields': (
                'is_staff', 'is_superuser', 'groups', 'user_permissions'
            ),
        }),
        (_('Important dates'), {'fields': ('last_login', 'date_joined', 'created_at', 'updated_at')}),
    )
    
    # Fieldsets for the add form
    add_fieldsets = (
        (None, {
            'classes': ('wide',),
            'fields': (
                'username', 'email', 'password1', 'password2', 'user_type',
                'first_name', 'last_name'
            ),
        }),
    )
    
    readonly_fields = ('created_at', 'updated_at', 'last_login', 'date_joined')


============================================================
FILE: backend/user-service/users/apps.py
============================================================
from django.apps import AppConfig
import logging

logger = logging.getLogger(__name__)

class UsersConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'users'

    def ready(self):
        import users.signals  # Import signals
        # Kafka consumers should run in a dedicated process (e.g., management command)
        # to avoid duplicate consumers and lifecycle issues.

============================================================
FILE: backend/user-service/users/consumers.py
============================================================
import logging
from django.conf import settings
from shared.kafka_utils import get_event_consumer
from .models import User

logger = logging.getLogger(__name__)

class UserEventConsumer:
    """Consumer for user service events"""
    
    def __init__(self):
        self.topics = [settings.KAFKA_TOPICS['JOB_EVENTS']]
        self.group_id = settings.KAFKA_GROUP_ID
        self.consumer = get_event_consumer(self.topics, self.group_id, settings.KAFKA_BOOTSTRAP_SERVERS)
        
        # Register event handlers
        self.consumer.register_handler('job_created', self.handle_job_created)
        self.consumer.register_handler('job_updated', self.handle_job_updated)
        self.consumer.register_handler('job_deleted', self.handle_job_deleted)
    
    def handle_job_created(self, event):
        """Handle job created event"""
        try:
            data = event['data']
            job_id = data['job_id']
            employer_id = data['employer_id']
            title = data['title']
            
            logger.info(f"Received job_created event: Job {job_id} by user {employer_id}")
            
            # Example: Update user's job posting count or send notification
            # This is where you'd implement business logic based on job events
            
        except Exception as e:
            logger.error(f"Error handling job_created event: {str(e)}")
            raise  # Re-raise to trigger retry logic
    
    def handle_job_updated(self, event):
        """Handle job updated event"""
        try:
            data = event['data']
            job_id = data['job_id']
            logger.info(f"Received job_updated event: Job {job_id}")
            # Implement business logic
            
        except Exception as e:
            logger.error(f"Error handling job_updated event: {str(e)}")
            raise
    
    def handle_job_deleted(self, event):
        """Handle job deleted event"""
        try:
            data = event['data']
            job_id = data['job_id']
            logger.info(f"Received job_deleted event: Job {job_id}")
            # Implement business logic
            
        except Exception as e:
            logger.error(f"Error handling job_deleted event: {str(e)}")
            raise
    
    def start_consuming(self):
        """Start consuming events"""
        self.consumer.start_consuming()
        logger.info("User service event consumer started")

# Global instance
user_event_consumer = UserEventConsumer()

============================================================
FILE: backend/user-service/users/events.py
============================================================
import logging
from django.conf import settings
from shared.kafka_utils import get_event_publisher
from shared.events import UserCreatedEvent, UserUpdatedEvent, UserDeletedEvent
import uuid
from django.utils import timezone

logger = logging.getLogger(__name__)

class UserEventPublisher:
    """Publisher for user-related events"""
    
    def __init__(self):
        self.publisher = get_event_publisher(settings.KAFKA_BOOTSTRAP_SERVERS)
        self.topic = settings.KAFKA_TOPICS['USER_EVENTS']
        self.service_name = 'user-service'
    
    def publish_user_created(self, user):
        """Publish user created event"""
        try:
            event = UserCreatedEvent(
                event_id=str(uuid.uuid4()),
                timestamp=timezone.now().isoformat(),
                service_name=self.service_name,
                user_id=user.id,
                username=user.username,
                email=user.email,
                user_type=user.user_type,
                first_name=user.first_name,
                last_name=user.last_name
            )
            
            self.publisher.publish_event(
                topic=self.topic,
                event_type='user_created',
                data=event.to_dict(),
                key=str(user.id),
                service_name=self.service_name
            )
            
            logger.info(f"Published user_created event for user {user.id}")
            
        except Exception as e:
            logger.error(f"Failed to publish user_created event: {str(e)}")
            # Don't raise - we don't want to fail user creation due to event failure
    
    def publish_user_updated(self, user, changes=None):
        """Publish user updated event"""
        try:
            event = UserUpdatedEvent(
                event_id=str(uuid.uuid4()),
                timestamp=timezone.now().isoformat(),
                service_name=self.service_name,
                user_id=user.id,
                username=user.username,
                email=user.email,
                user_type=user.user_type,
                first_name=user.first_name,
                last_name=user.last_name,
                changes=changes or {}
            )
            
            self.publisher.publish_event(
                topic=self.topic,
                event_type='user_updated',
                data=event.to_dict(),
                key=str(user.id),
                service_name=self.service_name
            )
            
            logger.info(f"Published user_updated event for user {user.id}")
            
        except Exception as e:
            logger.error(f"Failed to publish user_updated event: {str(e)}")
    
    def publish_user_deleted(self, user_id, username):
        """Publish user deleted event"""
        try:
            event = UserDeletedEvent(
                event_id=str(uuid.uuid4()),
                timestamp=timezone.now().isoformat(),
                service_name=self.service_name,
                user_id=user_id,
                username=username
            )
            
            self.publisher.publish_event(
                topic=self.topic,
                event_type='user_deleted',
                data=event.to_dict(),
                key=str(user_id),
                service_name=self.service_name
            )
            
            logger.info(f"Published user_deleted event for user {user_id}")
            
        except Exception as e:
            logger.error(f"Failed to publish user_deleted event: {str(e)}")

# Global instance
user_event_publisher = UserEventPublisher()

============================================================
FILE: backend/user-service/users/models.py
============================================================
from django.db import models
from django.contrib.auth.models import AbstractUser
from django.utils.translation import gettext_lazy as _


class User(AbstractUser):
    """
    Custom User model for the job platform.
    Extends Django's AbstractUser with additional fields.
    """
    
    # Additional fields
    phone_number = models.CharField(
        max_length=15, 
        blank=True, 
        null=True,
        help_text=_("User's phone number")
    )
    
    date_of_birth = models.DateField(
        blank=True, 
        null=True,
        help_text=_("User's date of birth")
    )
    
    profile_picture = models.ImageField(
        upload_to='profile_pictures/',
        blank=True, 
        null=True,
        help_text=_("User's profile picture")
    )
    
    bio = models.TextField(
        max_length=500, 
        blank=True,
        help_text=_("User's bio/description")
    )
    
    # User type (job seeker, employer, admin)
    USER_TYPE_CHOICES = [
        ('job_seeker', _('Job Seeker')),
        ('employer', _('Employer')),
        ('admin', _('Admin')),
    ]
    
    user_type = models.CharField(
        max_length=20,
        choices=USER_TYPE_CHOICES,
        default='job_seeker',
        help_text=_("Type of user")
    )
    
    # Account status
    is_verified = models.BooleanField(
        default=False,
        help_text=_("Whether the user's email is verified")
    )
    
    is_active = models.BooleanField(
        default=True,
        help_text=_("Whether the user account is active")
    )
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = _('User')
        verbose_name_plural = _('Users')
        db_table = 'users'
    
    def __str__(self):
        return self.username
    
    @property
    def full_name(self):
        """Return the user's full name."""
        return f"{self.first_name} {self.last_name}".strip() or self.username


============================================================
FILE: backend/user-service/users/serializers.py
============================================================
from rest_framework import serializers
from django.contrib.auth import authenticate
from .models import User

class UserRegistrationSerializer(serializers.ModelSerializer):
    password = serializers.CharField(write_only=True, min_length=8)
    password_confirm = serializers.CharField(write_only=True)
    
    class Meta:
        model = User
        fields = [
            'email', 'username', 'user_type', 'phone_number', 
            'date_of_birth', 'password', 'password_confirm'
        ]
    
    def validate(self, attrs):
        if attrs['password'] != attrs['password_confirm']:
            raise serializers.ValidationError("Passwords don't match")
        return attrs
    
    def create(self, validated_data):
        validated_data.pop('password_confirm')
        password = validated_data.pop('password')
        user = User.objects.create_user(password=password, **validated_data)
        return user

class UserLoginSerializer(serializers.Serializer):
    email = serializers.EmailField()
    password = serializers.CharField()
    
    def validate(self, attrs):
        email = attrs.get('email')
        password = attrs.get('password')
        
        if email and password:
            # Try to authenticate with email as username first
            user = authenticate(username=email, password=password)
            
            # If that fails, try to find user by email and authenticate with username
            if not user:
                try:
                    user_obj = User.objects.get(email=email)
                    user = authenticate(username=user_obj.username, password=password)
                except User.DoesNotExist:
                    pass
            
            if not user:
                raise serializers.ValidationError('Invalid credentials')
            if not user.is_active:
                raise serializers.ValidationError('User account is disabled')
            attrs['user'] = user
        return attrs

class UserProfileSerializer(serializers.ModelSerializer):
    full_name = serializers.ReadOnlyField()
    
    class Meta:
        model = User
        fields = [
            'id', 'email', 'username', 'user_type', 'phone_number',
            'date_of_birth', 'profile_picture', 'bio', 'is_verified',
            'full_name', 'created_at', 'updated_at'
        ]
        read_only_fields = ['id', 'created_at', 'updated_at', 'is_verified']

class UserUpdateSerializer(serializers.ModelSerializer):
    class Meta:
        model = User
        fields = [
            'username', 'phone_number', 'date_of_birth', 
            'profile_picture', 'bio'
        ]

============================================================
FILE: backend/user-service/users/signals.py
============================================================
import logging
from django.db.models.signals import post_save, post_delete, pre_save
from django.dispatch import receiver
from django.contrib.auth import get_user_model

User = get_user_model()
logger = logging.getLogger(__name__)

# Track changes for update events
user_original_data = {}

def get_user_event_publisher():
    """Lazy import to avoid circular import issues"""
    from .events import user_event_publisher
    return user_event_publisher

@receiver(pre_save, sender=User)
def capture_user_changes(sender, instance, **kwargs):
    """Capture original user data before save to detect changes"""
    if instance.pk:
        try:
            original = User.objects.get(pk=instance.pk)
            user_original_data[instance.pk] = {
                'username': original.username,
                'email': original.email,
                'first_name': original.first_name,
                'last_name': original.last_name,
                'user_type': original.user_type,
            }
        except User.DoesNotExist:
            pass

@receiver(post_save, sender=User)
def user_saved_handler(sender, instance, created, **kwargs):
    """Handle user creation and updates"""
    try:
        user_event_publisher = get_user_event_publisher()
        if created:
            logger.info(f"User created: {instance.username} (ID: {instance.id})")
            user_event_publisher.publish_user_created(instance)
        else:
            original_data = user_original_data.get(instance.pk, {})
            if original_data:
                changes = {}
                current_data = {
                    'username': instance.username,
                    'email': instance.email,
                    'first_name': instance.first_name,
                    'last_name': instance.last_name,
                    'user_type': instance.user_type,
                }
                for field, new_value in current_data.items():
                    old_value = original_data.get(field)
                    if old_value != new_value:
                        changes[field] = {'old': old_value, 'new': new_value}
                if changes:
                    logger.info(f"User updated: {instance.username} (ID: {instance.id})")
                    user_event_publisher.publish_user_updated(instance, changes)
                user_original_data.pop(instance.pk, None)
    except Exception as e:
        logger.error(f"Error in user_saved_handler: {str(e)}")

@receiver(post_delete, sender=User)
def user_deleted_handler(sender, instance, **kwargs):
    """Handle user deletion"""
    try:
        user_event_publisher = get_user_event_publisher()
        logger.info(f"User deleted: {instance.username} (ID: {instance.id})")
        user_event_publisher.publish_user_deleted(instance.id, instance.username)
    except Exception as e:
        logger.error(f"Error in user_deleted_handler: {str(e)}") 

============================================================
FILE: backend/user-service/users/tests.py
============================================================
from django.test import TestCase

class PlaceholderTests(TestCase):
    def test_sanity(self):
        self.assertTrue(True)

============================================================
FILE: backend/user-service/users/urls.py
============================================================
from django.urls import path
from . import views

app_name = 'users'

urlpatterns = [
    # Authentication endpoints
    path('register/', views.register, name='register'),
    path('login/', views.login, name='login'),
    path('logout/', views.logout, name='logout'),
    
    # Profile endpoints
    path('profile/', views.profile, name='profile'),
    path('profile/update/', views.update_profile, name='update_profile'),
    
    # User management
    path('list/', views.user_list, name='user_list'),
]

============================================================
FILE: backend/user-service/users/views.py
============================================================
from rest_framework import generics, status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.response import Response
from rest_framework_simplejwt.tokens import RefreshToken
from django.contrib.auth import get_user_model
from .serializers import (
    UserRegistrationSerializer,
    UserLoginSerializer, 
    UserProfileSerializer,
    UserUpdateSerializer
)

User = get_user_model()

@api_view(['POST'])
@permission_classes([AllowAny])
def register(request):
    """User registration endpoint"""
    serializer = UserRegistrationSerializer(data=request.data)
    if serializer.is_valid():
        user = serializer.save()
        
        # Generate JWT tokens
        refresh = RefreshToken.for_user(user)
        
        return Response({
            'message': 'User registered successfully',
            'user': UserProfileSerializer(user).data,
            'tokens': {
                'access': str(refresh.access_token),
                'refresh': str(refresh),
            }
        }, status=status.HTTP_201_CREATED)
    
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
@permission_classes([AllowAny])
def login(request):
    """User login endpoint"""
    serializer = UserLoginSerializer(data=request.data)
    if serializer.is_valid():
        user = serializer.validated_data['user']
        
        # Generate JWT tokens
        refresh = RefreshToken.for_user(user)
        
        return Response({
            'message': 'Login successful',
            'user': UserProfileSerializer(user).data,
            'tokens': {
                'access': str(refresh.access_token),
                'refresh': str(refresh),
            }
        }, status=status.HTTP_200_OK)
    
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['GET'])
@permission_classes([IsAuthenticated])
def profile(request):
    """Get current user profile"""
    serializer = UserProfileSerializer(request.user)
    return Response(serializer.data)

@api_view(['PUT', 'PATCH'])
@permission_classes([IsAuthenticated])
def update_profile(request):
    """Update current user profile"""
    serializer = UserUpdateSerializer(
        request.user, 
        data=request.data, 
        partial=request.method == 'PATCH'
    )
    if serializer.is_valid():
        serializer.save()
        return Response({
            'message': 'Profile updated successfully',
            'user': UserProfileSerializer(request.user).data
        })
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['GET'])
@permission_classes([IsAuthenticated])
def user_list(request):
    """List users (for admin/employer features later)"""
    users = User.objects.filter(is_active=True)
    
    # Filter by user type if specified
    user_type = request.query_params.get('user_type')
    if user_type:
        users = users.filter(user_type=user_type)
    
    serializer = UserProfileSerializer(users, many=True)
    return Response(serializer.data)

@api_view(['POST'])
@permission_classes([AllowAny])
def logout(request):
    """Logout endpoint (for token blacklisting if needed)"""
    try:
        refresh_token = request.data["refresh"]
        token = RefreshToken(refresh_token)
        token.blacklist()
        return Response({
            'message': 'Successfully logged out'
        }, status=status.HTTP_200_OK)
    except Exception as e:
        return Response({
            'error': 'Invalid token'
        }, status=status.HTTP_400_BAD_REQUEST)

============================================================
FILE: backend/user-service/manage.py
============================================================
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'user_service.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()


============================================================
FILE: backend/user-service/requirements.txt
============================================================
Django==4.2.7
djangorestframework==3.14.0
djangorestframework-simplejwt==5.3.0
django-cors-headers==4.3.1
psycopg[binary]==3.2.9
python-decouple==3.8
django-extensions==3.2.3
requests==2.31.0
celery==5.3.4
redis==5.0.1
Pillow==11.3.0
kafka-python==2.0.2

============================================================
FILE: docs/database-design.md
============================================================
# Job Platform - Microservice Database Design

## Overview

This document outlines the database design for the job platform following microservice architecture principles. Each service will have its own dedicated database to ensure loose coupling and independent scalability.

## Microservice Database Architecture

### 1. User Service Database (`users_db`)

**Purpose**: Manages user accounts, authentication, and user profiles.

#### Tables:

```sql
-- Users table (extends Django's AbstractUser)
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    username VARCHAR(150) UNIQUE NOT NULL,
    email VARCHAR(254) UNIQUE NOT NULL,
    password VARCHAR(128) NOT NULL,
    first_name VARCHAR(150),
    last_name VARCHAR(150),
    phone_number VARCHAR(15),
    date_of_birth DATE,
    profile_picture VARCHAR(255),
    bio TEXT,
    user_type VARCHAR(20) DEFAULT 'job_seeker' CHECK (user_type IN ('job_seeker', 'employer', 'admin')),
    is_verified BOOLEAN DEFAULT FALSE,
    is_active BOOLEAN DEFAULT TRUE,
    is_staff BOOLEAN DEFAULT FALSE,
    is_superuser BOOLEAN DEFAULT FALSE,
    last_login TIMESTAMP,
    date_joined TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- User verification tokens
CREATE TABLE user_verification_tokens (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT REFERENCES users(id) ON DELETE CASCADE,
    token VARCHAR(255) UNIQUE NOT NULL,
    token_type VARCHAR(50) NOT NULL, -- 'email_verification', 'password_reset'
    expires_at TIMESTAMP NOT NULL,
    used_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- User sessions (for JWT token blacklisting)
CREATE TABLE user_sessions (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT REFERENCES users(id) ON DELETE CASCADE,
    refresh_token VARCHAR(255) UNIQUE NOT NULL,
    expires_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 2. Job Service Database (`jobs_db`)

**Purpose**: Manages job postings, company information, and job-related data.

#### Tables:

```sql
-- Companies table
CREATE TABLE companies (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    website VARCHAR(255),
    logo VARCHAR(255),
    industry VARCHAR(100),
    size VARCHAR(50), -- 'startup', 'small', 'medium', 'large'
    founded_year INTEGER,
    location VARCHAR(255),
    is_verified BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Jobs table
CREATE TABLE jobs (
    id BIGSERIAL PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT NOT NULL,
    requirements TEXT,
    responsibilities TEXT,
    company_id BIGINT REFERENCES companies(id) ON DELETE CASCADE,
    employer_id BIGINT NOT NULL, -- References user_id from user-service
    job_type VARCHAR(50) DEFAULT 'full_time' CHECK (job_type IN ('full_time', 'part_time', 'contract', 'internship', 'freelance')),
    experience_level VARCHAR(50) DEFAULT 'entry' CHECK (experience_level IN ('entry', 'mid', 'senior', 'executive')),
    salary_min DECIMAL(10,2),
    salary_max DECIMAL(10,2),
    salary_currency VARCHAR(3) DEFAULT 'USD',
    location VARCHAR(255),
    is_remote BOOLEAN DEFAULT FALSE,
    is_active BOOLEAN DEFAULT TRUE,
    application_deadline DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Job categories
CREATE TABLE job_categories (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE NOT NULL,
    description TEXT,
    parent_id BIGINT REFERENCES job_categories(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Job-category relationships
CREATE TABLE job_categories_jobs (
    id BIGSERIAL PRIMARY KEY,
    job_id BIGINT REFERENCES jobs(id) ON DELETE CASCADE,
    category_id BIGINT REFERENCES job_categories(id) ON DELETE CASCADE,
    UNIQUE(job_id, category_id)
);

-- Job skills
CREATE TABLE job_skills (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Job-skill relationships
CREATE TABLE job_skills_jobs (
    id BIGSERIAL PRIMARY KEY,
    job_id BIGINT REFERENCES jobs(id) ON DELETE CASCADE,
    skill_id BIGINT REFERENCES job_skills(id) ON DELETE CASCADE,
    is_required BOOLEAN DEFAULT FALSE,
    UNIQUE(job_id, skill_id)
);
```

### 3. Application Service Database (`applications_db`)

**Purpose**: Manages job applications, application status, and application-related data.

#### Tables:

```sql
-- Applications table
CREATE TABLE applications (
    id BIGSERIAL PRIMARY KEY,
    job_id BIGINT NOT NULL, -- References job from job-service
    applicant_id BIGINT NOT NULL, -- References user_id from user-service
    employer_id BIGINT NOT NULL, -- References user_id from user-service
    status VARCHAR(50) DEFAULT 'pending' CHECK (status IN ('pending', 'reviewing', 'shortlisted', 'interviewing', 'offered', 'hired', 'rejected', 'withdrawn')),
    cover_letter TEXT,
    expected_salary DECIMAL(10,2),
    availability_date DATE,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Application attachments
CREATE TABLE application_attachments (
    id BIGSERIAL PRIMARY KEY,
    application_id BIGINT REFERENCES applications(id) ON DELETE CASCADE,
    file_name VARCHAR(255) NOT NULL,
    file_path VARCHAR(500) NOT NULL,
    file_type VARCHAR(100),
    file_size INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Application status history
CREATE TABLE application_status_history (
    id BIGSERIAL PRIMARY KEY,
    application_id BIGINT REFERENCES applications(id) ON DELETE CASCADE,
    status VARCHAR(50) NOT NULL,
    notes TEXT,
    changed_by BIGINT NOT NULL, -- References user_id from user-service
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Interviews table
CREATE TABLE interviews (
    id BIGSERIAL PRIMARY KEY,
    application_id BIGINT REFERENCES applications(id) ON DELETE CASCADE,
    interview_type VARCHAR(50) DEFAULT 'phone' CHECK (interview_type IN ('phone', 'video', 'in_person')),
    scheduled_at TIMESTAMP,
    duration_minutes INTEGER DEFAULT 60,
    location VARCHAR(255),
    notes TEXT,
    status VARCHAR(50) DEFAULT 'scheduled' CHECK (status IN ('scheduled', 'completed', 'cancelled', 'rescheduled')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 4. Search Service Database (`search_db`)

**Purpose**: Manages search indexes, search history, and search-related analytics.

#### Tables:

```sql
-- Search indexes (for full-text search)
CREATE TABLE search_indexes (
    id BIGSERIAL PRIMARY KEY,
    entity_type VARCHAR(50) NOT NULL, -- 'job', 'company', 'user'
    entity_id BIGINT NOT NULL,
    search_vector tsvector,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Search history
CREATE TABLE search_history (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL, -- References user_id from user-service
    query TEXT NOT NULL,
    filters JSONB,
    results_count INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Search analytics
CREATE TABLE search_analytics (
    id BIGSERIAL PRIMARY KEY,
    query TEXT NOT NULL,
    search_count INTEGER DEFAULT 1,
    last_searched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 5. Notification Service Database (`notifications_db`)

**Purpose**: Manages notifications, email templates, and notification preferences.

#### Tables:

```sql
-- Notifications table
CREATE TABLE notifications (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL, -- References user_id from user-service
    title VARCHAR(255) NOT NULL,
    message TEXT NOT NULL,
    notification_type VARCHAR(50) NOT NULL, -- 'email', 'push', 'sms', 'in_app'
    status VARCHAR(50) DEFAULT 'pending' CHECK (status IN ('pending', 'sent', 'failed', 'read')),
    metadata JSONB,
    sent_at TIMESTAMP,
    read_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Notification templates
CREATE TABLE notification_templates (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE NOT NULL,
    subject VARCHAR(255),
    body TEXT NOT NULL,
    notification_type VARCHAR(50) NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- User notification preferences
CREATE TABLE user_notification_preferences (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL, -- References user_id from user-service
    notification_type VARCHAR(50) NOT NULL,
    is_enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, notification_type)
);
```

### 6. Analytics Service Database (`analytics_db`)

**Purpose**: Manages analytics data, metrics, and reporting.

#### Tables:

```sql
-- Analytics events
CREATE TABLE analytics_events (
    id BIGSERIAL PRIMARY KEY,
    event_type VARCHAR(100) NOT NULL,
    user_id BIGINT, -- References user_id from user-service (nullable for anonymous events)
    session_id VARCHAR(255),
    properties JSONB,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- User analytics
CREATE TABLE user_analytics (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL, -- References user_id from user-service
    metric_name VARCHAR(100) NOT NULL,
    metric_value DECIMAL(15,2),
    metric_date DATE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Job analytics
CREATE TABLE job_analytics (
    id BIGSERIAL PRIMARY KEY,
    job_id BIGINT NOT NULL, -- References job from job-service
    metric_name VARCHAR(100) NOT NULL,
    metric_value INTEGER DEFAULT 0,
    metric_date DATE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Platform analytics
CREATE TABLE platform_analytics (
    id BIGSERIAL PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    metric_value DECIMAL(15,2),
    metric_date DATE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## Database Design Principles

### 1. Service Isolation
- Each service has its own dedicated database
- No direct database sharing between services
- Services communicate via APIs only

### 2. Data Ownership
- User Service owns all user-related data
- Job Service owns job and company data
- Application Service owns application data
- Each service is responsible for its own data consistency

### 3. Eventual Consistency
- Services can have eventual consistency for cross-service data
- Use event-driven architecture for data synchronization
- Implement saga pattern for distributed transactions

### 4. Scalability
- Each database can be scaled independently
- Use read replicas for read-heavy operations
- Implement caching strategies (Redis)

### 5. Data Replication Strategy
- User data can be replicated to other services as needed
- Use event sourcing for audit trails
- Implement CQRS pattern for read/write separation

## Cross-Service Data Relationships

### 1. User References
- Other services reference users by `user_id` (BIGINT)
- User data is replicated via events when needed
- User service is the source of truth for user information

### 2. Job References
- Application service references jobs by `job_id` (BIGINT)
- Job data is replicated via events when needed
- Job service is the source of truth for job information

### 3. Event-Driven Synchronization
- Use message queues (RabbitMQ/Apache Kafka) for events
- Implement event sourcing for data consistency
- Use saga pattern for distributed transactions

## Migration Strategy

### Phase 1: Service Isolation
1. Separate existing monolithic database into service-specific databases
2. Implement service boundaries
3. Set up event-driven communication

### Phase 2: Data Optimization
1. Optimize each service's database schema
2. Implement caching strategies
3. Set up read replicas

### Phase 3: Advanced Features
1. Implement CQRS pattern
2. Add event sourcing
3. Implement advanced analytics

## Security Considerations

1. **Database Access**: Each service only has access to its own database
2. **Encryption**: All sensitive data should be encrypted at rest
3. **Network Security**: Use private networks for database communication
4. **Audit Logging**: Implement comprehensive audit trails
5. **Data Privacy**: Implement data retention and deletion policies

## Monitoring and Observability

1. **Database Metrics**: Monitor each database's performance
2. **Service Dependencies**: Track cross-service dependencies
3. **Data Consistency**: Monitor eventual consistency
4. **Error Tracking**: Implement comprehensive error tracking
5. **Performance Monitoring**: Monitor query performance and optimization 

============================================================
FILE: docs/database-migration-strategy.md
============================================================
# Database Migration Strategy for Microservices

## Overview

This document outlines the step-by-step strategy for migrating from the current monolithic database to a microservice-based database architecture.

## Current State Analysis

### Existing Database Structure
- **User Service**: Currently using SQLite with Django's AbstractUser model
- **Other Services**: Empty or minimal structure
- **Docker Compose**: Configured for PostgreSQL databases per service

### Migration Goals
1. Separate data by service boundaries
2. Maintain data integrity during migration
3. Minimize downtime
4. Ensure backward compatibility
5. Implement proper data synchronization

## Phase 1: Database Setup and Service Isolation

### Step 1: Database Infrastructure Setup

1. **Create Service-Specific Databases**
   ```bash
   # Create databases for each service
   createdb users_db
   createdb jobs_db
   createdb applications_db
   createdb search_db
   createdb notifications_db
   createdb analytics_db
   ```

2. **Update Docker Compose Configuration**
   - Ensure each service connects to its dedicated database
   - Configure proper networking between services
   - Set up database backup strategies

### Step 2: Service Model Implementation

1. **User Service Migration**
   - Keep existing User model structure
   - Add new fields for microservice integration
   - Create migration scripts for data transfer

2. **Job Service Implementation**
   - Implement Company, Job, JobCategory, JobSkill models
   - Set up proper relationships and constraints
   - Create initial data migration scripts

3. **Application Service Implementation**
   - Implement Application, ApplicationAttachment, Interview models
   - Set up cross-service references
   - Create data synchronization mechanisms

4. **Search Service Implementation**
   - Implement SearchIndex, SearchHistory, SearchAnalytics models
   - Set up full-text search capabilities
   - Create indexing strategies

5. **Notification Service Implementation**
   - Implement Notification, NotificationTemplate, UserNotificationPreference models
   - Set up notification delivery mechanisms
   - Create template management system

6. **Analytics Service Implementation**
   - Implement AnalyticsEvent, UserAnalytics, JobAnalytics, PlatformAnalytics models
   - Set up event tracking mechanisms
   - Create reporting infrastructure

## Phase 2: Data Migration and Synchronization

### Step 1: Data Extraction and Transformation

1. **User Data Migration**
   ```python
   # Migration script for user data
   def migrate_user_data():
       # Extract user data from existing database
       # Transform data to new schema
       # Load data into new user service database
       pass
   ```

2. **Job Data Migration**
   ```python
   # Migration script for job data
   def migrate_job_data():
       # Extract job-related data
       # Transform and normalize data
       # Load into job service database
       pass
   ```

3. **Application Data Migration**
   ```python
   # Migration script for application data
   def migrate_application_data():
       # Extract application data
       # Transform and link to users and jobs
       # Load into application service database
       pass
   ```

### Step 2: Data Validation and Testing

1. **Data Integrity Checks**
   - Verify all data migrated correctly
   - Check referential integrity
   - Validate business rules

2. **Performance Testing**
   - Test query performance
   - Optimize indexes
   - Monitor resource usage

3. **Integration Testing**
   - Test cross-service communication
   - Verify API endpoints
   - Test data synchronization

## Phase 3: Service Communication and Data Synchronization

### Step 1: Event-Driven Architecture Implementation

1. **Message Queue Setup**
   ```yaml
   # RabbitMQ or Apache Kafka configuration
   services:
     rabbitmq:
       image: rabbitmq:3-management
       ports:
         - "5672:5672"
         - "15672:15672"
   ```

2. **Event Publishing**
   ```python
   # Example event publisher
   class EventPublisher:
       def publish_user_created(self, user_data):
           # Publish user created event
           pass
       
       def publish_job_created(self, job_data):
           # Publish job created event
           pass
   ```

3. **Event Consumers**
   ```python
   # Example event consumer
   class EventConsumer:
       def handle_user_created(self, event_data):
           # Handle user created event
           # Update search index
           # Create analytics record
           pass
   ```

### Step 2: Data Replication Strategy

1. **Read Replicas**
   - Set up read replicas for each service
   - Implement read/write separation
   - Configure load balancing

2. **Caching Strategy**
   ```python
   # Redis caching configuration
   CACHES = {
       'default': {
           'BACKEND': 'django_redis.cache.RedisCache',
           'LOCATION': 'redis://127.0.0.1:6379/1',
           'OPTIONS': {
               'CLIENT_CLASS': 'django_redis.client.DefaultClient',
           }
       }
   }
   ```

3. **Data Consistency**
   - Implement eventual consistency
   - Use saga pattern for distributed transactions
   - Handle data conflicts

## Phase 4: API Gateway and Service Discovery

### Step 1: API Gateway Implementation

1. **Service Routing**
   ```nginx
   # Nginx configuration for API gateway
   upstream user_service {
       server user-service:8000;
   }
   
   upstream job_service {
       server job-service:8000;
   }
   
   server {
       listen 80;
       
       location /api/users/ {
           proxy_pass http://user_service;
       }
       
       location /api/jobs/ {
           proxy_pass http://job_service;
       }
   }
   ```

2. **Authentication and Authorization**
   - Implement JWT token validation
   - Set up service-to-service authentication
   - Configure role-based access control

### Step 2: Service Discovery

1. **Service Registry**
   ```python
   # Service registry implementation
   class ServiceRegistry:
       def register_service(self, service_name, service_url):
           # Register service
           pass
       
       def get_service_url(self, service_name):
           # Get service URL
           pass
   ```

2. **Health Checks**
   ```python
   # Health check endpoint
   @api_view(['GET'])
   def health_check(request):
       return Response({
           'status': 'healthy',
           'timestamp': timezone.now(),
           'service': 'user-service'
       })
   ```

## Phase 5: Monitoring and Observability

### Step 1: Logging and Monitoring

1. **Centralized Logging**
   ```python
   # Logging configuration
   LOGGING = {
       'version': 1,
       'disable_existing_loggers': False,
       'handlers': {
           'file': {
               'level': 'INFO',
               'class': 'logging.FileHandler',
               'filename': 'django.log',
           },
       },
       'loggers': {
           'django': {
               'handlers': ['file'],
               'level': 'INFO',
               'propagate': True,
           },
       },
   }
   ```

2. **Metrics Collection**
   - Implement Prometheus metrics
   - Set up Grafana dashboards
   - Monitor service performance

### Step 2: Error Handling and Alerting

1. **Error Tracking**
   - Implement error tracking (Sentry)
   - Set up alerting mechanisms
   - Create error recovery procedures

2. **Performance Monitoring**
   - Monitor database performance
   - Track API response times
   - Monitor resource usage

## Phase 6: Testing and Validation

### Step 1: Comprehensive Testing

1. **Unit Testing**
   ```python
   # Example unit test
   class UserServiceTest(TestCase):
       def test_user_creation(self):
           # Test user creation
           pass
   ```

2. **Integration Testing**
   ```python
   # Example integration test
   class ServiceIntegrationTest(TestCase):
       def test_user_job_application_flow(self):
           # Test complete user-job-application flow
           pass
   ```

3. **Load Testing**
   - Test system under load
   - Identify performance bottlenecks
   - Optimize resource usage

### Step 2: Data Validation

1. **Data Quality Checks**
   - Validate data integrity
   - Check for data inconsistencies
   - Verify business rules

2. **Backup and Recovery Testing**
   - Test backup procedures
   - Verify recovery processes
   - Document disaster recovery plans

## Phase 7: Deployment and Rollback

### Step 1: Deployment Strategy

1. **Blue-Green Deployment**
   - Deploy new services alongside existing ones
   - Switch traffic gradually
   - Monitor for issues

2. **Canary Deployment**
   - Deploy to subset of users
   - Monitor performance and errors
   - Gradually increase traffic

### Step 2: Rollback Procedures

1. **Rollback Triggers**
   - Define rollback criteria
   - Set up automated rollback triggers
   - Document rollback procedures

2. **Data Recovery**
   - Implement data recovery procedures
   - Test recovery processes
   - Document recovery steps

## Success Criteria

### Technical Criteria
1. All services are running independently
2. Data integrity is maintained
3. Performance meets requirements
4. Error rates are within acceptable limits
5. Monitoring and alerting are working

### Business Criteria
1. No data loss during migration
2. Minimal downtime during transition
3. All functionality is preserved
4. User experience is maintained or improved
5. System is more scalable and maintainable

## Risk Mitigation

### Technical Risks
1. **Data Loss**: Implement comprehensive backup strategies
2. **Performance Issues**: Monitor and optimize continuously
3. **Service Failures**: Implement circuit breakers and fallbacks
4. **Data Inconsistency**: Use eventual consistency and conflict resolution

### Business Risks
1. **Downtime**: Use blue-green deployment strategy
2. **User Experience**: Test thoroughly before deployment
3. **Data Privacy**: Implement proper security measures
4. **Compliance**: Ensure regulatory compliance

## Timeline

### Week 1-2: Infrastructure Setup
- Set up databases and networking
- Configure Docker containers
- Implement basic service structure

### Week 3-4: Data Migration
- Implement migration scripts
- Test data migration
- Validate data integrity

### Week 5-6: Service Communication
- Implement event-driven architecture
- Set up API gateway
- Test service communication

### Week 7-8: Testing and Validation
- Comprehensive testing
- Performance optimization
- Security validation

### Week 9-10: Deployment
- Gradual deployment
- Monitoring and alerting
- Documentation and training

## Conclusion

This migration strategy provides a comprehensive approach to transitioning from a monolithic database to a microservice architecture. The phased approach ensures minimal risk and maximum success probability while maintaining system stability and data integrity throughout the process. 

============================================================
FILE: docs/documentation.md
============================================================
I'll scan the repository to inventory files and collect line numbers for classes and functions so I can produce clickable links into the code. Then I'll generate the full documentation with architecture diagrams and a file-by-file walkthrough.
```bash
git ls-files | sed 's/^/\//'
```

```bash
grep -RIn "^[[:space:]]*\(class\|def\) " backend | sed 's/^/\//'
```

Ran tool

Ran tool

### Project Documentation

Below is a comprehensive, structured guide to the entire repository to help you take ownership quickly.

## 1) Project Overview

- Purpose: Multi-tenant job platform, decomposed into microservices for users, jobs, applications, search, notifications, and analytics. Each service has its own PostgreSQL database and Django app with DRF APIs, containerized via Docker Compose and fronted by an Nginx API gateway.

- High-level architecture:
  - API Gateway (Nginx) routes requests to Django services
  - Database-per-service (PostgreSQL)
  - Authentication with JWT (DRF + Simple JWT)
  - Redis for caching/broker (future: Celery)
  - Event-driven patterns and eventual consistency (laid out in docs; lightweight signals in code as placeholders)

Architecture diagram:
- Microservices and data stores (rendered above).
- Request flow sequence (rendered above).

- Module interaction:
  - API Gateway proxies all client requests to service endpoints
  - Services use `ServiceRegistry` to discover base URLs via env
  - Cross-service references are via ID fields (BigInteger) and HTTP calls (planned)
  - Analytics consumes events; Search indexes entities; Notifications sends messages to users

## 2) Full File-by-File Walkthrough

Notes:
- Click any link to jump to the file or specific line(s).
- Line numbers are provided for classes/functions where applicable.
- Some files are standard boilerplate and described succinctly.

### Root

- .gitignore: Standard ignores for Python, Django, Node, Flutter, Docker, etc.

- docker-compose.yml
  - Orchestrates all microservices, 6 Postgres instances, Redis, and API gateway.
  - Defines networks, volumes, environment variables per service for DB and inter-service URLs.

### Backend Shared

- backend/shared/service_registry.py
  - What: Lightweight service discovery and HTTP client wrapper.
  - Key elements:
    - Class singleton init reads env-based service URLs [ServiceRegistry.__init__](/backend/shared/service_registry.py#L17)
    - get_service_url(service_name) [link](/backend/shared/service_registry.py#L29)
    - make_request(service_name, endpoint, method, data, headers) with error handling [link](/backend/shared/service_registry.py#L32)

- backend/shared/settings.py
  - Base/shared settings scaffold (not actively imported by services).
  - Defines default DATABASES (PostgreSQL), REST_FRAMEWORK auth/permissions, JWT lifetimes, CORS and static settings.

### User Service

- backend/user-service/Dockerfile: Build/run steps (installs requirements, migrates, runsserver).

- backend/user-service/requirements.txt: Django, DRF, Simple JWT, CORS, psycopg, decouple, extensions, redis, pillow.

- backend/user-service/manage.py: Standard Django CLI entrypoint.

- backend/user-service/user_service/settings.py
  - Uses sqlite for local-only in this service (intentionally simple for dev).
  - INSTALLED_APPS includes `users`; DRF + JWT, CORS, static/media.
  - AUTH_USER_MODEL set to `users.User`.

- backend/user-service/user_service/urls.py
  - Routes admin and users API: `api/users/`.

- backend/user-service/user_service/asgi.py, wsgi.py: Standard.

- backend/user-service/users/models.py
  - Custom user model extending Django `AbstractUser` with additional fields:
    - Class `User` [link](/backend/user-service/users/models.py#L6)
    - Fields: phone, dob, profile_picture, bio, user_type, is_verified, timestamps.
    - `full_name` property [link](/backend/user-service/users/models.py#L76)

- backend/user-service/users/migrations/0001_initial.py: Creates `users` table consistent with model.

- backend/user-service/users/admin.py
  - `CustomUserAdmin` adds extra fields and readonly timestamps to admin view [link](/backend/user-service/users/admin.py#L8)

- backend/user-service/users/apps.py
  - `UsersConfig` with signals import [link](/backend/user-service/users/apps.py#L5).

- backend/user-service/users/serializers.py
  - `UserRegistrationSerializer` [link](/backend/user-service/users/serializers.py#L5) validate+create
  - `UserLoginSerializer` [link](/backend/user-service/users/serializers.py#L27) authenticate by email/username
  - `UserProfileSerializer` [link](/backend/user-service/users/serializers.py#L54) includes full_name
  - `UserUpdateSerializer` [link](/backend/user-service/users/serializers.py#L66)

- backend/user-service/users/views.py
  - Register [link](/backend/user-service/users/views.py#L16) (AllowAny)
  - Login [link](/backend/user-service/users/views.py#L38) (AllowAny)
  - Profile [link](/backend/user-service/users/views.py#L60)
  - Update profile [link](/backend/user-service/users/views.py#L67)
  - List users [link](/backend/user-service/users/views.py#L84) (filter by user_type)
  - Logout [link](/backend/user-service/users/views.py#L98)

- backend/user-service/users/signals.py
  - Placeholders for post_save hooks (profile creation, updates) [link](/backend/user-service/users/signals.py#L8)

### Job Service

- backend/job-service/job_service/settings.py
  - PostgreSQL DB (jobs_db) via decouple, DRF+JWT, CORS, `jobs` app.

- backend/job-service/job_service/urls.py
  - Routes `api/jobs/` to jobs app.

- ASGI/WSGI: standard.

- backend/job-service/jobs/models.py
  - `Company` [link](/backend/job-service/jobs/models.py#L5)
  - `JobCategory` (self-referencing parent) [link](/backend/job-service/jobs/models.py#L42)
  - `JobSkill` [link](/backend/job-service/jobs/models.py#L63)
  - `Job` [link](/backend/job-service/jobs/models.py#L82) references `Company` and external `employer_id`
    - Salary helpers: `salary_range` property [link](/backend/job-service/jobs/models.py#L147)
    - M2M through tables:
      - `JobCategoryJob` [link](/backend/job-service/jobs/models.py#L159)
      - `JobSkillJob` [link](/backend/job-service/jobs/models.py#L175)

- backend/job-service/jobs/serializers.py
  - Model serializers for Company, Category, Skill
  - `JobSerializer` [link](/backend/job-service/jobs/serializers.py#L26) read-only nested company/categories/skills; custom create handles through relations.

- backend/job-service/jobs/views.py
  - Job list/detail/create/update/delete [link](/backend/job-service/jobs/views.py#L10)
  - Company list/detail/create [link](/backend/job-service/jobs/views.py#L61)
  - Category list, Skill list [link](/backend/job-service/jobs/views.py#L90)

- backend/job-service/jobs/urls.py
  - URL patterns for all above [link](/backend/job-service/jobs/urls.py#L6)

- backend/job-service/jobs/admin.py
  - Admin registration for all models [link](/backend/job-service/jobs/admin.py#L6)

- backend/job-service/jobs/signals.py
  - Placeholders to push search updates on create [link](/backend/job-service/jobs/signals.py#L6)

- backend/job-service/jobs/tests.py
  - Basic model tests [link](/backend/job-service/jobs/tests.py#L8)

### Application Service

- backend/application-service/application_service/settings.py
  - PostgreSQL DB (applications_db), DRF+JWT, `applications` app.

- URLs/ASGI/WSGI: standard.

- backend/application-service/applications/models.py
  - `Application` [link](/backend/application-service/applications/models.py#L5), unique (job_id, applicant_id)
  - `ApplicationAttachment` [link](/backend/application-service/applications/models.py#L51)
  - `ApplicationStatusHistory` [link](/backend/application-service/applications/models.py#L74)
  - `Interview` [link](/backend/application-service/applications/models.py#L97)

- backend/application-service/applications/serializers.py
  - Nested read-only relationships in ApplicationSerializer [link](/backend/application-service/applications/serializers.py#L26)
  - Validation to prevent duplicate active applications [link](/backend/application-service/applications/serializers.py#L36)

- backend/application-service/applications/views.py
  - Application list/detail/create/update/delete [link](/backend/application-service/applications/views.py#L10)
  - Interview list/create/detail/update [link](/backend/application-service/applications/views.py#L80)

- backend/application-service/applications/urls.py
  - Routes endpoints for application and interviews [link](/backend/application-service/applications/urls.py#L6)

- backend/application-service/applications/admin.py
  - Admin registrations [link](/backend/application-service/applications/admin.py#L5)

- backend/application-service/applications/signals.py
  - Status history captured on create and update [link](/backend/application-service/applications/signals.py#L6)

### Search Service

- backend/search-service/search_service/settings.py
  - PostgreSQL DB (search_db), DRF+JWT, `search` app.

- URLs/ASGI/WSGI: standard.

- backend/search-service/search/models.py
  - `SearchIndex` uses `SearchVectorField` + `GinIndex` [link](/backend/search-service/search/models.py#L7)
  - `SearchHistory` [link](/backend/search-service/search/models.py#L42)
  - `SearchAnalytics` [link](/backend/search-service/search/models.py#L69)

- backend/search-service/search/views.py
  - search(q, type) using Postgres FTS with rank [link](/backend/search-service/search/views.py#L9)
  - Save history (if authenticated), update analytics [link](/backend/search-service/search/views.py#L33)
  - endpoints: history, analytics [link](/backend/search-service/search/views.py#L55)

- backend/search-service/search/urls.py
  - Routes search endpoints [link](/backend/search-service/search/urls.py#L6)

- backend/search-service/search/admin.py
  - Admin registrations [link](/backend/search-service/search/admin.py#L5)

- backend/search-service/search/signals.py
  - Placeholders for vector maintenance [link](/backend/search-service/search/signals.py#L6)

### Notification Service

- backend/notification-service/notification_service/settings.py
  - PostgreSQL DB (notifications_db), DRF+JWT, `notifications` app.

- URLs/ASGI/WSGI: standard.

- backend/notification-service/notifications/models.py
  - `NotificationTemplate` [link](/backend/notification-service/notifications/models.py#L5)
  - `Notification` (status: pending/sent/failed/read) [link](/backend/notification-service/notifications/models.py#L37)
  - `UserNotificationPreference` [link](/backend/notification-service/notifications/models.py#L85)

- backend/notification-service/notifications/views.py
  - List/detail/mark-as-read; preferences get/put; templates list [link](/backend/notification-service/notifications/views.py#L10)

- backend/notification-service/notifications/urls.py
  - Routes endpoints [link](/backend/notification-service/notifications/urls.py#L6)

- backend/notification-service/notifications/admin.py
  - Admin registrations [link](/backend/notification-service/notifications/admin.py#L5)

- backend/notification-service/notifications/signals.py
  - On create, transitions `pending` → `sent` via update (avoids infinite loop) [link](/backend/notification-service/notifications/signals.py#L6)

### Analytics Service

- backend/analytics-service/analytics_service/settings.py
  - PostgreSQL DB (analytics_db), DRF+JWT, `analytics` app.

- URLs/ASGI/WSGI: standard.

- backend/analytics-service/analytics/models.py
  - `AnalyticsEvent` [link](/backend/analytics-service/analytics/models.py#L5)
  - `UserAnalytics` [link](/backend/analytics-service/analytics/models.py#L31)
  - `JobAnalytics` [link](/backend/analytics-service/analytics/models.py#L59)
  - `PlatformAnalytics` [link](/backend/analytics-service/analytics/models.py#L87)

- backend/analytics-service/analytics/views.py
  - POST analytics_events; GET user, job, platform analytics [link](/backend/analytics-service/analytics/views.py#L11)

- backend/analytics-service/analytics/urls.py
  - Routes analytics endpoints [link](/backend/analytics-service/analytics/urls.py#L6)

- backend/analytics-service/analytics/admin.py
  - Admin registrations [link](/backend/analytics-service/analytics/admin.py#L5)

- backend/analytics-service/analytics/signals.py
  - Placeholder for event processing [link](/backend/analytics-service/analytics/signals.py#L6)

### API Gateway

- infrastructure/docker/api-gateway/Dockerfile: Nginx image build.

- infrastructure/docker/api-gateway/nginx.conf
  - Reverse-proxy routes to each service upstream (by Docker service name/port).
  - Central point for CORS, rate limits, TLS (future).

### Infrastructure

- infrastructure/kubernetes/.gitkeep: Placeholder for future manifests.
- infrastructure/scripts/setup.sh: Setup helper (if any steps added later).

### Frontend (stubs)

- frontend/README.md, frontend/flutter-app/README.md: Frontend placeholders.
- frontend/flutter-app/pubspec.yaml: Flutter dependencies metadata.
- frontend/shared/constants/api.ts: API endpoints constants.
- frontend/shared/types/api.ts: Shared TypeScript types.

### Docs

- docs/database-design.md: Detailed per-service DDL and design principles.
- docs/database-migration-strategy.md: Phased roadmap for migrating from monolith to microservices.
- docs/microservice-database-summary.md: Executive summary of architecture.

## 3) Concepts & Technology Explanations

- Django + DRF
  - What: Python web framework + REST toolkit for rapid API development.
  - Why: Mature ORM, admin, authentication, robust ecosystem.
  - How:
    - Models define tables; serializers map model ↔ JSON; views handle requests; URLs route endpoints.
    - Example (serializer create with M2M through):
      ```python
      # Pseudo-code
      job = Job.objects.create(**validated_data)
      for category_id in categories:
        JobCategoryJob.objects.create(job=job, category_id=category_id)
      ```

- Simple JWT
  - What: JSON Web Tokens for stateless auth.
  - Why: Microservices-friendly, no shared session state needed.
  - How: DRF authentication class validates Authorization: Bearer <token>.
    - In services settings: DEFAULT_AUTHENTICATION_CLASSES include Simple JWT.

- Database per service (PostgreSQL)
  - What: Each service runs its own DB schema.
  - Why: Strong data ownership, independent scaling, fault isolation.
  - How: Each service `settings.py DATABASES` points to its own containerized Postgres.

- Postgres Full-Text Search (Search Service)
  - What: Built-in FTS with `SearchVectorField` and `GIN` index.
  - Why: Efficient ranking/scoring for job/company/user searches.
  - How: `SearchIndex.search_vector` + `SearchRank`, filter and order by rank.

- Redis
  - What: In-memory data store used as cache/broker.
  - Why: Future caching, Celery broker for async tasks (not wired yet).
  - How: `REDIS_URL` configured in docker-compose; services can connect when needed.

- Event-driven architecture
  - What: Services publish/consume events to sync data asynchronously.
  - Why: Loose coupling, scalability.
  - How: For now, signals are placeholders. Docs outline RabbitMQ/Kafka adoption plan.

- Saga pattern and eventual consistency
  - What: Distributed transaction orchestration; accept temporary inconsistencies.
  - Why: Microservice boundary crossing updates need orchestration.
  - How: Documented for future implementation.

- CQRS
  - What: Separate read models from write models.
  - Why: Scaling queries independently, aggregate views (e.g., Search/Analytics).
  - How: Search/Analytics services act as read-models populated by domain events (future).

- Docker & Docker Compose
  - What: Containerization and local multi-service orchestration.
  - Why: Fast reproducible environment with DB-per-service.
  - How: docker-compose defines services, networks, volumes, env vars.

- Nginx API Gateway
  - What: Central routing, static hosting, TLS terminator.
  - Why: Single entry point, cross-cutting concerns.
  - How: nginx.conf reverse proxies to each service.

## 4) Execution Flow

- Startup:
  - docker-compose launches Postgres containers, Redis, services, and API gateway.
  - Django services migrate and start gunicorn/runserver (user-service Dockerfile migrates on run).
  - API Gateway exposes port 8000 → routes to services.

- Request lifecycle (example: list jobs)
  - Client → Gateway `/api/jobs/` → Job Service
  - DRF checks JWT (IsAuthenticated is default; some endpoints AllowAny)
  - ORM reads from `jobs_db`, serializer emits JSON response.

- Cross-service data flow examples:
  - Employeers create jobs (Job Service uses `employer_id` from User Service JWT claims).
  - Applicants submit applications referencing `job_id` and `applicant_id` (Application Service).
  - Search service indexes jobs/companies (planned async via events).
  - Notifications service sends messages when application status changes (planned events; minimal signals exist).
  - Analytics records events and aggregates metrics.

## 5) Past Steps Reconstruction (Inferred)

- Initial monolith (user-service had sqlite for local).
- Design moved to microservices: wrote database design and migration strategy docs.
- Bootstrapped each service with Django + DRF + PostgreSQL configs.
- Implemented core domain models per service.
- Wired serializers, views, and URLs; added admin for operational visibility.
- Added signals as placeholders for future event-driven integrations.
- Upgraded docker-compose to include all DBs and services.
- Added shared `ServiceRegistry` to centralize base URLs for inter-service HTTP calls.

Design decisions:
- BigInteger foreign keys across services (store IDs, not FK constraints) to preserve isolation.
- Default IsAuthenticated for DRF; selectively allow unauth endpoints.
- Keep signals minimal to avoid premature complexity; defer event buses to later.
- Separate search and analytics concerns into dedicated services (CQRS read side).

## 6) Knowledge Gaps To Close

- Django advanced:
  - Custom user models, signal usage, admin customization, migrations management.
  - Reference: Django docs “Customizing authentication” and “Signals”.

- DRF:
  - Serializers, viewsets vs function-based views, permissions, throttling.
  - Reference: DRF official tutorial and API guide.

- Simple JWT:
  - Token creation/blacklisting/refresh flow.
  - Reference: `djangorestframework-simplejwt` docs.

- PostgreSQL:
  - Indexing, FTS, JSONB, performance tuning.
  - Reference: Postgres docs (GIN, Search, JSONB best practices).

- Event-driven architecture:
  - RabbitMQ/Kafka, consumer groups, idempotency, outbox pattern.
  - Reference: Microservices Patterns by Chris Richardson.

- Saga/CQRS:
  - Orchestration vs choreography, read models, projections.
  - Reference: Patterns literature and practical guides.

- Nginx:
  - Reverse proxy configuration, rate limiting, TLS.
  - Reference: Nginx docs and production hardening guides.

- Docker/Kubernetes:
  - Multi-stage builds, healthchecks, manifests (Deployments, Services, Ingress, Secrets).
  - Reference: Kubernetes docs, Docker best practices.

- Observability:
  - Centralized logging (ELK/EFK), metrics (Prometheus/Grafana), tracing (OpenTelemetry).
  - Reference: OpenTelemetry docs.

## 7) Future Steps Roadmap

- Event Bus Integration:
  - Introduce RabbitMQ/Kafka; implement publishers in Job/Application services and consumers in Search/Analytics/Notification services.
  - Adopt outbox pattern for reliable event publishing.

- Authentication hardening:
  - Central Auth service or maintain per-service JWT validation with shared public key (JWKS).
  - Implement roles/permissions per endpoint.

- Data consistency & backfill:
  - Create backfill jobs to populate Search/Analytics from source-of-truth services.
  - Implement dead-letter queues and retries.

- Caching & performance:
  - Add Redis caching layers for hot endpoints (jobs list/search).
  - Add pagination tuning and indices based on query patterns.

- Testing & CI/CD:
  - Expand unit/integration tests, contract tests between services.
  - Add GitHub Actions/CI pipelines with docker-compose integration tests.

- Deployment:
  - Kubernetes manifests (Deployments, Services, Ingress, ConfigMaps/Secrets).
  - Blue-green/canary rollout strategies.

- Security:
  - TLS termination at the gateway, service-to-service mTLS (optional).
  - Secrets management (Vault/KMS/Sealed Secrets).

- Observability:
  - Centralized logs, metrics, tracing to quickly identify cross-service issues.

- API Gateway features:
  - Rate limiting, request/response normalization, circuit breakers (via an API gateway like Kong/Traefik/Envoy).

- Search Improvements:
  - Real indexing pipeline with updates on job/company/user changes.
  - Synonyms, stemming, language configs.

- Analytics:
  - Event schema standardization; background jobs for aggregation.
  - Dashboards and KPIs.

- Notification channels:
  - Integrate email provider (SES/SendGrid), push (FCM/APNs), SMS (Twilio).
  - Preference-driven delivery.

- Data governance:
  - GDPR compliance, PII redaction, data retention policies.

Short example of a potential pitfall:
- Pitfall: Triggering signals that call remote services synchronously can cause cascading latency/failure.
  - Mitigation: Use async event queues; apply retries with backoff; ensure idempotency keys.

---

If you want, I can generate service-specific READMEs (setup, run, API endpoints) and a top-level README with diagrams and quickstart commands.

- I’ve included clickable references. For key code chunks, you can also view them inline if needed:
```20:45:backend/shared/service_registry.py
class ServiceRegistry:
    """Centralized service discovery and communication"""
    # ...
    def make_request(self, service_name: str, endpoint: str, method: str = 'GET', 
                    data: Dict = None, headers: Dict = None):
        # ...
```

- The architecture and sequence diagrams in this doc are already embedded and render above.

- Everything is aligned with the docs in `docs/` and current codebase state.

============================================================
FILE: docs/microservice-database-summary.md
============================================================
# Microservice Database Design Summary

## Overview

This document provides a comprehensive summary of the microservice database design for the job platform. The design follows microservice architecture principles with each service having its own dedicated database.

## Architecture Overview

### Service Boundaries and Database Ownership

1. **User Service** (`users_db`)
   - **Ownership**: User accounts, authentication, profiles
   - **Key Models**: User, UserVerificationToken, UserSession
   - **Data**: User information, authentication tokens, session management

2. **Job Service** (`jobs_db`)
   - **Ownership**: Job postings, companies, job categories
   - **Key Models**: Company, Job, JobCategory, JobSkill
   - **Data**: Job listings, company information, job classifications

3. **Application Service** (`applications_db`)
   - **Ownership**: Job applications, interviews, application status
   - **Key Models**: Application, ApplicationAttachment, Interview, ApplicationStatusHistory
   - **Data**: Job applications, application tracking, interview scheduling

4. **Search Service** (`search_db`)
   - **Ownership**: Search indexes, search history, search analytics
   - **Key Models**: SearchIndex, SearchHistory, SearchAnalytics
   - **Data**: Searchable content, user search patterns, search performance

5. **Notification Service** (`notifications_db`)
   - **Ownership**: Notifications, notification templates, user preferences
   - **Key Models**: Notification, NotificationTemplate, UserNotificationPreference
   - **Data**: User notifications, notification templates, delivery tracking

6. **Analytics Service** (`analytics_db`)
   - **Ownership**: Analytics events, metrics, reporting
   - **Key Models**: AnalyticsEvent, UserAnalytics, JobAnalytics, PlatformAnalytics
   - **Data**: User behavior, system metrics, business intelligence

## Database Design Principles

### 1. Service Isolation
- Each service has its own dedicated PostgreSQL database
- No direct database sharing between services
- Services communicate via APIs and events only

### 2. Data Ownership
- Clear ownership boundaries for each service
- Single source of truth for each data domain
- Service-specific data models and schemas

### 3. Eventual Consistency
- Cross-service data can have eventual consistency
- Event-driven architecture for data synchronization
- Saga pattern for distributed transactions

### 4. Scalability
- Independent scaling of each database
- Read replicas for read-heavy operations
- Caching strategies with Redis

## Cross-Service Data Relationships

### 1. User References
- Other services reference users by `user_id` (BIGINT)
- User data replicated via events when needed
- User service is the source of truth for user information

### 2. Job References
- Application service references jobs by `job_id` (BIGINT)
- Job data replicated via events when needed
- Job service is the source of truth for job information

### 3. Data Synchronization
- Event-driven synchronization using message queues
- Event sourcing for audit trails
- CQRS pattern for read/write separation

## Key Database Features

### 1. Full-Text Search
- PostgreSQL full-text search capabilities
- Search indexes for jobs, companies, and users
- Search analytics and performance tracking

### 2. JSON Support
- JSONB fields for flexible metadata storage
- Event properties and notification metadata
- Search filters and analytics properties

### 3. Audit Trails
- Comprehensive audit logging
- Status history tracking
- Data change tracking

### 4. Performance Optimization
- Proper indexing strategies
- Query optimization
- Caching mechanisms

## Migration Strategy

### Phase 1: Infrastructure Setup
- Set up service-specific databases
- Configure Docker containers
- Implement basic service structure

### Phase 2: Data Migration
- Implement migration scripts
- Test data migration
- Validate data integrity

### Phase 3: Service Communication
- Implement event-driven architecture
- Set up API gateway
- Test service communication

### Phase 4: Testing and Validation
- Comprehensive testing
- Performance optimization
- Security validation

### Phase 5: Deployment
- Gradual deployment
- Monitoring and alerting
- Documentation and training

## Security Considerations

### 1. Database Security
- Each service only has access to its own database
- Encrypted connections between services
- Proper authentication and authorization

### 2. Data Privacy
- Data encryption at rest
- Secure data transmission
- Compliance with privacy regulations

### 3. Access Control
- Role-based access control
- Service-to-service authentication
- API security and rate limiting

## Monitoring and Observability

### 1. Database Monitoring
- Performance metrics tracking
- Query performance monitoring
- Resource usage monitoring

### 2. Service Monitoring
- Service health checks
- Error tracking and alerting
- Performance monitoring

### 3. Data Quality
- Data integrity checks
- Consistency monitoring
- Data quality validation

## Benefits of This Design

### 1. Scalability
- Independent scaling of services
- Better resource utilization
- Improved performance

### 2. Maintainability
- Clear service boundaries
- Easier to understand and modify
- Better code organization

### 3. Reliability
- Service isolation
- Fault tolerance
- Better error handling

### 4. Flexibility
- Technology diversity
- Independent deployment
- Faster development cycles

## Challenges and Mitigation

### 1. Data Consistency
- **Challenge**: Maintaining consistency across services
- **Mitigation**: Eventual consistency, saga pattern, conflict resolution

### 2. Complexity
- **Challenge**: Increased system complexity
- **Mitigation**: Clear documentation, monitoring, testing

### 3. Performance
- **Challenge**: Network latency between services
- **Mitigation**: Caching, optimization, monitoring

### 4. Data Migration
- **Challenge**: Complex data migration process
- **Mitigation**: Phased approach, testing, rollback procedures

## Next Steps

### 1. Implementation
- Start with Phase 1 of the migration strategy
- Implement service-specific databases
- Set up basic service structure

### 2. Testing
- Comprehensive testing of each service
- Integration testing
- Performance testing

### 3. Deployment
- Gradual deployment strategy
- Monitoring and alerting setup
- Documentation and training

### 4. Optimization
- Performance optimization
- Security hardening
- Monitoring improvements

## Conclusion

This microservice database design provides a robust, scalable, and maintainable architecture for the job platform. The design follows best practices for microservice architecture while ensuring data integrity, security, and performance. The phased migration strategy ensures a smooth transition from the current monolithic structure to the new microservice architecture.

The key success factors for this implementation are:
1. Clear service boundaries and data ownership
2. Proper event-driven communication
3. Comprehensive testing and validation
4. Monitoring and observability
5. Security and compliance considerations

By following this design and migration strategy, the job platform will be well-positioned for future growth and scalability while maintaining high performance and reliability. 

============================================================
FILE: docs/PROJECT_SUMMARY.md
============================================================
# Project Summary: Job Platform Microservices

This document provides an overview of the current state of the Job Platform microservices project, summarizing the implemented features, current architecture, and planned future phases.

## Current State of the Project

The Job Platform is being developed as a set of interconnected microservices, each responsible for a specific domain. The backend services are built using Django and Django REST Framework, communicating primarily via REST APIs and asynchronously through Kafka for event-driven interactions.

Currently, the core services are:
- **User Service**: Manages user authentication, profiles, and roles (job seeker, employer, admin).
- **Job Service**: Manages job postings, companies, categories, and skills.
- **Application Service**: Handles job applications and interviews.
- **Analytics Service**: Collects and processes analytics events.
- **Notification Service**: Manages and sends notifications to users.
- **Search Service**: Provides full-text search capabilities across entities.

The recent focus has been on integrating Kafka for inter-service communication, ensuring robust event publishing and consumption.

## Summary of Implemented Features

### Core Functionality
- **User Management**: User registration, login, profile management, and user listing.
- **Job Management**: Creation, listing, detail viewing, updating, and soft-deletion of job postings. Management of companies, job categories, and skills.
- **Application Management**: Creation, listing, detail viewing, updating, and soft-deletion of job applications. Interview scheduling and tracking.
- **Basic Analytics**: Recording of analytics events, user, job, and platform specific metrics.
- **Basic Notifications**: Notification templates, individual notifications, and user preferences.
- **Basic Search**: Full-text search across entities, search history, and search analytics.

### Kafka Integration
- **Event Publishing**: Services can publish domain-specific events (e.g., `UserCreatedEvent`, `JobCreatedEvent`, `CompanyCreatedEvent`) to Kafka topics.
- **Event Consumption**: Services are set up to consume relevant events from Kafka topics, enabling asynchronous updates and reactions across the platform.
- **Shared Utilities**: A `shared` Python package contains common event definitions (`events.py`) and Kafka utility classes (`kafka_utils.py`) for consistent event handling across microservices.
- **Configuration**: Kafka broker addresses, group IDs, and topic names are configurable via environment variables in each service's `settings.py`.

## Overview of Current Project Architecture

The project follows a microservices architecture with a shared Kafka message broker for asynchronous communication.

- **Services**: Each service (User, Job, Application, Analytics, Notification, Search) is an independent Django application with its own database.
- **API Gateway (Planned)**: An API Gateway will sit in front of the services to handle routing, authentication, and potentially rate limiting. (Not yet implemented, but implied by service structure).
- **Kafka**: Acts as the central nervous system for inter-service communication, enabling event-driven patterns. Events are defined in a shared module to ensure consistency.
- **Databases**: Each service uses PostgreSQL (or SQLite for local development fallback) for its persistent data storage, maintaining data isolation.
- **Shared Module**: A `backend/shared` directory contains common Python utilities, such as Kafka event definitions and Kafka producer/consumer wrappers, to reduce code duplication and enforce consistency. This module is added to the Python path of each service.

```
[Client Applications]
      |
      V
[API Gateway] (Planned)
      |
      +---------------------------------------------------------------------------------+
      |                                                                                 |
      V                                                                                 V
[User Service] <-----> [Kafka Broker] <-----> [Job Service] <-----> [Application Service]
      ^                      ^                      ^                      ^
      |                      |                      |                      |
      +----------------------+----------------------+----------------------+
                             |                      |                      |
                             V                      V                      V
                           [Analytics Service]    [Notification Service]   [Search Service]

```

## Planned Next Phases of the Project

1.  **Complete Kafka Integration for All Services**:
    - Implement event consumers and publishers for Analytics, Application, Notification, and Search services, similar to the User and Job services.
    - Define necessary event types for these services in `shared/events.py`.

2.  **Implement Comprehensive Event Handling Logic**:
    - Develop the business logic within each service's Kafka consumers to react to events from other services (e.g., Job Service updating `UserProfileCache` on `UserUpdatedEvent`, Search Service updating its index on `JobCreatedEvent`).

3.  **API Gateway Implementation**:
    - Set up an API Gateway (e.g., using Django REST Framework or a dedicated gateway like Kong/Ocelot) to centralize API access, authentication, and routing.

4.  **Frontend Development**:
    - Develop client applications (web, mobile) that interact with the API Gateway to provide the user interface for the job platform.

5.  **Deployment and Infrastructure Automation**:
    - Containerize all services using Docker.
    - Orchestrate deployment using Docker Compose for local development and Kubernetes for production.
    - Set up a production-ready Kafka cluster.

6.  **Monitoring and Logging**:
    - Implement centralized logging (e.g., ELK stack).
    - Set up monitoring and alerting for service health and performance.

7.  **Advanced Features**:
    - Real-time notifications using WebSockets.
    - Recommendation engine for jobs/candidates.
    - Advanced analytics and reporting dashboards.
    - Payment integration for premium features.

The current work has laid a solid foundation for the Kafka integration, making the project ready to scale and expand its event-driven capabilities across all microservices. 

============================================================
FILE: frontend/flutter-app/android/app/src/debug/AndroidManifest.xml
============================================================
<manifest xmlns:android="http://schemas.android.com/apk/res/android">
    <!-- The INTERNET permission is required for development. Specifically,
         the Flutter tool needs it to communicate with the running application
         to allow setting breakpoints, to provide hot reload, etc.
    -->
    <uses-permission android:name="android.permission.INTERNET"/>
</manifest>


============================================================
FILE: frontend/flutter-app/android/app/src/main/java/io/flutter/plugins/GeneratedPluginRegistrant.java
============================================================
package io.flutter.plugins;

import androidx.annotation.Keep;
import androidx.annotation.NonNull;
import io.flutter.Log;

import io.flutter.embedding.engine.FlutterEngine;

/**
 * Generated file. Do not edit.
 * This file is generated by the Flutter tool based on the
 * plugins that support the Android platform.
 */
@Keep
public final class GeneratedPluginRegistrant {
  private static final String TAG = "GeneratedPluginRegistrant";
  public static void registerWith(@NonNull FlutterEngine flutterEngine) {
    try {
      flutterEngine.getPlugins().add(new dev.fluttercommunity.plus.connectivity.ConnectivityPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin connectivity_plus, dev.fluttercommunity.plus.connectivity.ConnectivityPlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new io.flutter.plugins.flutter_plugin_android_lifecycle.FlutterAndroidLifecyclePlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin flutter_plugin_android_lifecycle, io.flutter.plugins.flutter_plugin_android_lifecycle.FlutterAndroidLifecyclePlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new com.it_nomads.fluttersecurestorage.FlutterSecureStoragePlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin flutter_secure_storage, com.it_nomads.fluttersecurestorage.FlutterSecureStoragePlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new io.flutter.plugins.imagepicker.ImagePickerPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin image_picker_android, io.flutter.plugins.imagepicker.ImagePickerPlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new io.flutter.plugins.localauth.LocalAuthPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin local_auth_android, io.flutter.plugins.localauth.LocalAuthPlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new io.flutter.plugins.pathprovider.PathProviderPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin path_provider_android, io.flutter.plugins.pathprovider.PathProviderPlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new com.baseflow.permissionhandler.PermissionHandlerPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin permission_handler_android, com.baseflow.permissionhandler.PermissionHandlerPlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new dev.fluttercommunity.plus.share.SharePlusPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin share_plus, dev.fluttercommunity.plus.share.SharePlusPlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new io.flutter.plugins.sharedpreferences.SharedPreferencesPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin shared_preferences_android, io.flutter.plugins.sharedpreferences.SharedPreferencesPlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new com.tekartik.sqflite.SqflitePlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin sqflite_android, com.tekartik.sqflite.SqflitePlugin", e);
    }
    try {
      flutterEngine.getPlugins().add(new io.flutter.plugins.urllauncher.UrlLauncherPlugin());
    } catch (Exception e) {
      Log.e(TAG, "Error registering plugin url_launcher_android, io.flutter.plugins.urllauncher.UrlLauncherPlugin", e);
    }
  }
}


============================================================
FILE: frontend/flutter-app/android/app/src/main/kotlin/com/example/job_seeker_app/MainActivity.kt
============================================================
package com.example.job_seeker_app

import io.flutter.embedding.android.FlutterActivity

class MainActivity : FlutterActivity()


============================================================
FILE: frontend/flutter-app/android/app/src/main/res/drawable/launch_background.xml
============================================================
<?xml version="1.0" encoding="utf-8"?>
<!-- Modify this file to customize your launch splash screen -->
<layer-list xmlns:android="http://schemas.android.com/apk/res/android">
    <item android:drawable="@android:color/white" />

    <!-- You can insert your own image assets here -->
    <!-- <item>
        <bitmap
            android:gravity="center"
            android:src="@mipmap/launch_image" />
    </item> -->
</layer-list>


============================================================
FILE: frontend/flutter-app/android/app/src/main/res/drawable-v21/launch_background.xml
============================================================
<?xml version="1.0" encoding="utf-8"?>
<!-- Modify this file to customize your launch splash screen -->
<layer-list xmlns:android="http://schemas.android.com/apk/res/android">
    <item android:drawable="?android:colorBackground" />

    <!-- You can insert your own image assets here -->
    <!-- <item>
        <bitmap
            android:gravity="center"
            android:src="@mipmap/launch_image" />
    </item> -->
</layer-list>


============================================================
FILE: frontend/flutter-app/android/app/src/main/res/values/styles.xml
============================================================
<?xml version="1.0" encoding="utf-8"?>
<resources>
    <!-- Theme applied to the Android Window while the process is starting when the OS's Dark Mode setting is off -->
    <style name="LaunchTheme" parent="@android:style/Theme.Light.NoTitleBar">
        <!-- Show a splash screen on the activity. Automatically removed when
             the Flutter engine draws its first frame -->
        <item name="android:windowBackground">@drawable/launch_background</item>
    </style>
    <!-- Theme applied to the Android Window as soon as the process has started.
         This theme determines the color of the Android Window while your
         Flutter UI initializes, as well as behind your Flutter UI while its
         running.

         This Theme is only used starting with V2 of Flutter's Android embedding. -->
    <style name="NormalTheme" parent="@android:style/Theme.Light.NoTitleBar">
        <item name="android:windowBackground">?android:colorBackground</item>
    </style>
</resources>


============================================================
FILE: frontend/flutter-app/android/app/src/main/res/values-night/styles.xml
============================================================
<?xml version="1.0" encoding="utf-8"?>
<resources>
    <!-- Theme applied to the Android Window while the process is starting when the OS's Dark Mode setting is on -->
    <style name="LaunchTheme" parent="@android:style/Theme.Black.NoTitleBar">
        <!-- Show a splash screen on the activity. Automatically removed when
             the Flutter engine draws its first frame -->
        <item name="android:windowBackground">@drawable/launch_background</item>
    </style>
    <!-- Theme applied to the Android Window as soon as the process has started.
         This theme determines the color of the Android Window while your
         Flutter UI initializes, as well as behind your Flutter UI while its
         running.

         This Theme is only used starting with V2 of Flutter's Android embedding. -->
    <style name="NormalTheme" parent="@android:style/Theme.Black.NoTitleBar">
        <item name="android:windowBackground">?android:colorBackground</item>
    </style>
</resources>


============================================================
FILE: frontend/flutter-app/android/app/src/main/AndroidManifest.xml
============================================================
<manifest xmlns:android="http://schemas.android.com/apk/res/android">
    <application
        android:label="job_seeker_app"
        android:name="${applicationName}"
        android:icon="@mipmap/ic_launcher">
        <activity
            android:name=".MainActivity"
            android:exported="true"
            android:launchMode="singleTop"
            android:taskAffinity=""
            android:theme="@style/LaunchTheme"
            android:configChanges="orientation|keyboardHidden|keyboard|screenSize|smallestScreenSize|locale|layoutDirection|fontScale|screenLayout|density|uiMode"
            android:hardwareAccelerated="true"
            android:windowSoftInputMode="adjustResize">
            <!-- Specifies an Android theme to apply to this Activity as soon as
                 the Android process has started. This theme is visible to the user
                 while the Flutter UI initializes. After that, this theme continues
                 to determine the Window background behind the Flutter UI. -->
            <meta-data
              android:name="io.flutter.embedding.android.NormalTheme"
              android:resource="@style/NormalTheme"
              />
            <intent-filter>
                <action android:name="android.intent.action.MAIN"/>
                <category android:name="android.intent.category.LAUNCHER"/>
            </intent-filter>
        </activity>
        <!-- Don't delete the meta-data below.
             This is used by the Flutter tool to generate GeneratedPluginRegistrant.java -->
        <meta-data
            android:name="flutterEmbedding"
            android:value="2" />
    </application>
    <!-- Required to query activities that can process text, see:
         https://developer.android.com/training/package-visibility and
         https://developer.android.com/reference/android/content/Intent#ACTION_PROCESS_TEXT.

         In particular, this is used by the Flutter engine in io.flutter.plugin.text.ProcessTextPlugin. -->
    <queries>
        <intent>
            <action android:name="android.intent.action.PROCESS_TEXT"/>
            <data android:mimeType="text/plain"/>
        </intent>
    </queries>
</manifest>


============================================================
FILE: frontend/flutter-app/android/app/src/profile/AndroidManifest.xml
============================================================
<manifest xmlns:android="http://schemas.android.com/apk/res/android">
    <!-- The INTERNET permission is required for development. Specifically,
         the Flutter tool needs it to communicate with the running application
         to allow setting breakpoints, to provide hot reload, etc.
    -->
    <uses-permission android:name="android.permission.INTERNET"/>
</manifest>


============================================================
FILE: frontend/flutter-app/android/app/build.gradle.kts
============================================================
plugins {
    id("com.android.application")
    id("kotlin-android")
    // The Flutter Gradle Plugin must be applied after the Android and Kotlin Gradle plugins.
    id("dev.flutter.flutter-gradle-plugin")
}

android {
    namespace = "com.example.job_seeker_app"
    compileSdk = flutter.compileSdkVersion
    ndkVersion = "24.0.8215888" // Use alternative stable NDK version

    compileOptions {
        sourceCompatibility = JavaVersion.VERSION_11
        targetCompatibility = JavaVersion.VERSION_11
        isCoreLibraryDesugaringEnabled = true
    }

    kotlinOptions {
        jvmTarget = JavaVersion.VERSION_11.toString()
    }

    defaultConfig {
        // TODO: Specify your own unique Application ID (https://developer.android.com/studio/build/application-id.html).
        applicationId = "com.example.job_seeker_app"
        // You can update the following values to match your application needs.
        // For more information, see: https://flutter.dev/to/review-gradle-config.
        minSdk = flutter.minSdkVersion
        targetSdk = flutter.targetSdkVersion
        versionCode = flutter.versionCode
        versionName = flutter.versionName
    }

    buildTypes {
        release {
            // TODO: Add your own signing config for the release build.
            // Signing with the debug keys for now, so `flutter run --release` works.
            signingConfig = signingConfigs.getByName("debug")
        }
    }
}

flutter {
    source = "../.."
}

dependencies {
    coreLibraryDesugaring("com.android.tools:desugar_jdk_libs:2.0.4")
}


============================================================
FILE: frontend/flutter-app/android/gradle/wrapper/gradle-wrapper.properties
============================================================
distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-8.12-all.zip


============================================================
FILE: frontend/flutter-app/android/build.gradle.kts
============================================================
allprojects {
    repositories {
        google()
        mavenCentral()
    }
}

val newBuildDir: Directory = rootProject.layout.buildDirectory.dir("../../build").get()
rootProject.layout.buildDirectory.value(newBuildDir)

subprojects {
    val newSubprojectBuildDir: Directory = newBuildDir.dir(project.name)
    project.layout.buildDirectory.value(newSubprojectBuildDir)
}
subprojects {
    project.evaluationDependsOn(":app")
}

tasks.register<Delete>("clean") {
    delete(rootProject.layout.buildDirectory)
}


============================================================
FILE: frontend/flutter-app/android/gradle.properties
============================================================
org.gradle.jvmargs=-Xmx8G -XX:MaxMetaspaceSize=4G -XX:ReservedCodeCacheSize=512m -XX:+HeapDumpOnOutOfMemoryError
android.useAndroidX=true
android.enableJetifier=true


============================================================
FILE: frontend/flutter-app/android/gradlew
============================================================
#!/usr/bin/env bash

##############################################################################
##
##  Gradle start up script for UN*X
##
##############################################################################

# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
DEFAULT_JVM_OPTS=""

APP_NAME="Gradle"
APP_BASE_NAME=`basename "$0"`

# Use the maximum available, or set MAX_FD != -1 to use that value.
MAX_FD="maximum"

warn ( ) {
    echo "$*"
}

die ( ) {
    echo
    echo "$*"
    echo
    exit 1
}

# OS specific support (must be 'true' or 'false').
cygwin=false
msys=false
darwin=false
case "`uname`" in
  CYGWIN* )
    cygwin=true
    ;;
  Darwin* )
    darwin=true
    ;;
  MINGW* )
    msys=true
    ;;
esac

# Attempt to set APP_HOME
# Resolve links: $0 may be a link
PRG="$0"
# Need this for relative symlinks.
while [ -h "$PRG" ] ; do
    ls=`ls -ld "$PRG"`
    link=`expr "$ls" : '.*-> \(.*\)$'`
    if expr "$link" : '/.*' > /dev/null; then
        PRG="$link"
    else
        PRG=`dirname "$PRG"`"/$link"
    fi
done
SAVED="`pwd`"
cd "`dirname \"$PRG\"`/" >/dev/null
APP_HOME="`pwd -P`"
cd "$SAVED" >/dev/null

CLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar

# Determine the Java command to use to start the JVM.
if [ -n "$JAVA_HOME" ] ; then
    if [ -x "$JAVA_HOME/jre/sh/java" ] ; then
        # IBM's JDK on AIX uses strange locations for the executables
        JAVACMD="$JAVA_HOME/jre/sh/java"
    else
        JAVACMD="$JAVA_HOME/bin/java"
    fi
    if [ ! -x "$JAVACMD" ] ; then
        die "ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
else
    JAVACMD="java"
    which java >/dev/null 2>&1 || die "ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
fi

# Increase the maximum file descriptors if we can.
if [ "$cygwin" = "false" -a "$darwin" = "false" ] ; then
    MAX_FD_LIMIT=`ulimit -H -n`
    if [ $? -eq 0 ] ; then
        if [ "$MAX_FD" = "maximum" -o "$MAX_FD" = "max" ] ; then
            MAX_FD="$MAX_FD_LIMIT"
        fi
        ulimit -n $MAX_FD
        if [ $? -ne 0 ] ; then
            warn "Could not set maximum file descriptor limit: $MAX_FD"
        fi
    else
        warn "Could not query maximum file descriptor limit: $MAX_FD_LIMIT"
    fi
fi

# For Darwin, add options to specify how the application appears in the dock
if $darwin; then
    GRADLE_OPTS="$GRADLE_OPTS \"-Xdock:name=$APP_NAME\" \"-Xdock:icon=$APP_HOME/media/gradle.icns\""
fi

# For Cygwin, switch paths to Windows format before running java
if $cygwin ; then
    APP_HOME=`cygpath --path --mixed "$APP_HOME"`
    CLASSPATH=`cygpath --path --mixed "$CLASSPATH"`
    JAVACMD=`cygpath --unix "$JAVACMD"`

    # We build the pattern for arguments to be converted via cygpath
    ROOTDIRSRAW=`find -L / -maxdepth 1 -mindepth 1 -type d 2>/dev/null`
    SEP=""
    for dir in $ROOTDIRSRAW ; do
        ROOTDIRS="$ROOTDIRS$SEP$dir"
        SEP="|"
    done
    OURCYGPATTERN="(^($ROOTDIRS))"
    # Add a user-defined pattern to the cygpath arguments
    if [ "$GRADLE_CYGPATTERN" != "" ] ; then
        OURCYGPATTERN="$OURCYGPATTERN|($GRADLE_CYGPATTERN)"
    fi
    # Now convert the arguments - kludge to limit ourselves to /bin/sh
    i=0
    for arg in "$@" ; do
        CHECK=`echo "$arg"|egrep -c "$OURCYGPATTERN" -`
        CHECK2=`echo "$arg"|egrep -c "^-"`                                 ### Determine if an option

        if [ $CHECK -ne 0 ] && [ $CHECK2 -eq 0 ] ; then                    ### Added a condition
            eval `echo args$i`=`cygpath --path --ignore --mixed "$arg"`
        else
            eval `echo args$i`="\"$arg\""
        fi
        i=$((i+1))
    done
    case $i in
        (0) set -- ;;
        (1) set -- "$args0" ;;
        (2) set -- "$args0" "$args1" ;;
        (3) set -- "$args0" "$args1" "$args2" ;;
        (4) set -- "$args0" "$args1" "$args2" "$args3" ;;
        (5) set -- "$args0" "$args1" "$args2" "$args3" "$args4" ;;
        (6) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" ;;
        (7) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" ;;
        (8) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" "$args7" ;;
        (9) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" "$args7" "$args8" ;;
    esac
fi

# Split up the JVM_OPTS And GRADLE_OPTS values into an array, following the shell quoting and substitution rules
function splitJvmOpts() {
    JVM_OPTS=("$@")
}
eval splitJvmOpts $DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS
JVM_OPTS[${#JVM_OPTS[*]}]="-Dorg.gradle.appname=$APP_BASE_NAME"

exec "$JAVACMD" "${JVM_OPTS[@]}" -classpath "$CLASSPATH" org.gradle.wrapper.GradleWrapperMain "$@"


============================================================
FILE: frontend/flutter-app/android/settings.gradle.kts
============================================================
pluginManagement {
    val flutterSdkPath = run {
        val properties = java.util.Properties()
        file("local.properties").inputStream().use { properties.load(it) }
        val flutterSdkPath = properties.getProperty("flutter.sdk")
        require(flutterSdkPath != null) { "flutter.sdk not set in local.properties" }
        flutterSdkPath
    }

    includeBuild("$flutterSdkPath/packages/flutter_tools/gradle")

    repositories {
        google()
        mavenCentral()
        gradlePluginPortal()
    }
}

plugins {
    id("dev.flutter.flutter-plugin-loader") version "1.0.0"
    id("com.android.application") version "8.7.3" apply false
    id("org.jetbrains.kotlin.android") version "2.1.0" apply false
}

include(":app")


============================================================
FILE: frontend/flutter-app/assets/fonts/README.md
============================================================
# Fonts Directory

This directory should contain the Inter font family files:

- `Inter-Regular.ttf` - Regular weight (400)
- `Inter-Medium.ttf` - Medium weight (500) 
- `Inter-SemiBold.ttf` - Semi-bold weight (600)
- `Inter-Bold.ttf` - Bold weight (700)

## Download Inter Font

You can download the Inter font family from:
- [Google Fonts](https://fonts.google.com/specimen/Inter)
- [Inter Font Website](https://rsms.me/inter/)

## Alternative Fonts

If you prefer different fonts, you can:
1. Replace the font files in this directory
2. Update the font family names in `lib/core/theme/app_theme.dart`
3. Update the font references in `pubspec.yaml`

## Note

The app will fall back to system fonts if these files are not present. 

============================================================
FILE: frontend/flutter-app/test/widget_test.dart
============================================================
// This is a basic Flutter widget test.
//
// To perform an interaction with a widget in your test, use the WidgetTester
// utility in the flutter_test package. For example, you can send tap and scroll
// gestures. You can also use WidgetTester to find child widgets in the widget
// tree, read text, and verify that the values of widget properties are correct.

import 'package:flutter/material.dart';
import 'package:flutter_test/flutter_test.dart';

import 'package:job_seeker_app/main.dart';

void main() {
  testWidgets('App should build without errors', (WidgetTester tester) async {
    // Build our app and trigger a frame.
    await tester.pumpWidget(const JobSeekerApp());

    // Verify that the app builds successfully
    expect(find.byType(JobSeekerApp), findsOneWidget);
  });
}


============================================================
FILE: frontend/flutter-app/web/manifest.json
============================================================
{
    "name": "job_seeker_app",
    "short_name": "job_seeker_app",
    "start_url": ".",
    "display": "standalone",
    "background_color": "#0175C2",
    "theme_color": "#0175C2",
    "description": "A new Flutter project.",
    "orientation": "portrait-primary",
    "prefer_related_applications": false,
    "icons": [
        {
            "src": "icons/Icon-192.png",
            "sizes": "192x192",
            "type": "image/png"
        },
        {
            "src": "icons/Icon-512.png",
            "sizes": "512x512",
            "type": "image/png"
        },
        {
            "src": "icons/Icon-maskable-192.png",
            "sizes": "192x192",
            "type": "image/png",
            "purpose": "maskable"
        },
        {
            "src": "icons/Icon-maskable-512.png",
            "sizes": "512x512",
            "type": "image/png",
            "purpose": "maskable"
        }
    ]
}


============================================================
FILE: frontend/flutter-app/.metadata
============================================================
# This file tracks properties of this Flutter project.
# Used by Flutter tool to assess capabilities and perform upgrades etc.
#
# This file should be version controlled and should not be manually edited.

version:
  revision: "edada7c56edf4a183c1735310e123c7f923584f1"
  channel: "stable"

project_type: app

# Tracks metadata for the flutter migrate command
migration:
  platforms:
    - platform: root
      create_revision: edada7c56edf4a183c1735310e123c7f923584f1
      base_revision: edada7c56edf4a183c1735310e123c7f923584f1
    - platform: android
      create_revision: edada7c56edf4a183c1735310e123c7f923584f1
      base_revision: edada7c56edf4a183c1735310e123c7f923584f1

  # User provided section

  # List of Local paths (relative to this file) that should be
  # ignored by the migrate tool.
  #
  # Files that are not part of the templates will be ignored by default.
  unmanaged_files:
    - 'lib/main.dart'
    - 'ios/Runner.xcodeproj/project.pbxproj'


============================================================
FILE: frontend/flutter-app/analysis_options.yaml
============================================================
# This file configures the analyzer, which statically analyzes Dart code to
# check for errors, warnings, and lints.
#
# The issues identified by the analyzer are surfaced in the UI of Dart-enabled
# IDEs (https://dart.dev/tools#ides-and-editors). The analyzer can also be
# invoked from the command line by running `flutter analyze`.

# The following line activates a set of recommended lints for Flutter apps,
# packages, and plugins designed to encourage good coding practices.
include: package:flutter_lints/flutter.yaml

linter:
  # The lint rules applied to this project can be customized in the
  # section below to disable rules from the `package:flutter_lints/flutter.yaml`
  # included above or to enable additional rules. A list of all available lints
  # and their documentation is published at https://dart.dev/lints.
  #
  # Instead of disabling a lint rule for the entire project in the
  # section below, it can also be suppressed for a single line of code
  # or a specific dart file by using the `// ignore: name_of_lint` and
  # `// ignore_for_file: name_of_lint` syntax on the line or in the file
  # producing the lint.
  rules:
    # avoid_print: false  # Uncomment to disable the `avoid_print` rule
    # prefer_single_quotes: true  # Uncomment to enable the `prefer_single_quotes` rule

# Additional information about this file can be found at
# https://dart.dev/guides/language/analysis-options


============================================================
FILE: frontend/flutter-app/pubspec.yaml
============================================================
name: job_seeker_app
description: A modern job platform mobile application built with Flutter
publish_to: 'none'
version: 1.0.0+1

environment:
  sdk: '>=3.0.0 <4.0.0'
  flutter: ">=3.10.0"

dependencies:
  flutter:
    sdk: flutter
  
  # State Management
  flutter_riverpod: ^2.4.9
  riverpod_annotation: ^2.3.3
  
  # HTTP Client
  dio: ^5.4.0
  pretty_dio_logger: ^1.3.1
  
  # Authentication & Security
  flutter_secure_storage: ^9.0.0
  local_auth: ^2.1.7
  
  # UI Components
  cupertino_icons: ^1.0.6
  # google_fonts: ^6.1.0
  flutter_svg: ^2.0.9
  cached_network_image: ^3.3.0
  image_picker: ^1.0.4
  
  # Navigation
  go_router: ^12.1.3
  
  # Forms & Validation
  flutter_hook_form: ^0.0.1
  
  # Notifications
  # flutter_local_notifications: ^15.1.3  # Temporarily disabled due to Android compatibility issues
  
  # Utils
  intl: ^0.18.1
  url_launcher: ^6.2.2
  share_plus: ^7.2.1
  permission_handler: ^11.1.0
  
  # Charts & Analytics
  fl_chart: ^0.66.0
  
  # Connectivity
  connectivity_plus: ^5.0.2
  
  # Storage
  shared_preferences: ^2.2.2
  hive: ^2.2.3
  hive_flutter: ^1.1.0

dev_dependencies:
  flutter_test:
    sdk: flutter
  
  # Code Generation
  build_runner: ^2.4.7
  riverpod_generator: ^2.3.9
  hive_generator: ^2.0.1
  
  # Linting
  flutter_lints: ^3.0.1
  custom_lint: ^0.5.11
  riverpod_lint: ^2.3.7

flutter:
  uses-material-design: true
  
  assets:
    - assets/images/
    - assets/icons/
    - assets/animations/
  
  # fonts:
  #   - family: Inter
  #     fonts:
  #       - asset: assets/fonts/Inter-Regular.ttf
  #       - asset: assets/fonts/Inter-Medium.ttf
  #         weight: 500
  #       - asset: assets/fonts/Inter-SemiBold.ttf
  #         weight: 600
  #       - asset: assets/fonts/Inter-Bold.ttf
  #         weight: 700 

============================================================
FILE: frontend/flutter-app/README.md
============================================================
# Job Seeker Flutter App

A modern, feature-rich mobile application for job seekers and employers built with Flutter.

## 🏗️ Architecture Overview

```
lib/
├── core/                    # Core functionality
│   ├── config/             # App configuration
│   ├── constants/          # App constants
│   ├── router/             # Navigation
│   ├── theme/              # App theming
│   ├── utils/              # Utility functions
│   └── widgets/            # Shared widgets
├── features/               # Feature modules
│   ├── auth/               # Authentication
│   ├── jobs/               # Job management
│   ├── applications/       # Job applications
│   ├── profile/            # User profile
│   ├── search/             # Job search
│   └── notifications/      # Notifications
├── shared/                 # Shared resources
│   ├── models/             # Data models
│   ├── services/           # API services
│   └── providers/          # State providers
└── main.dart              # App entry point
```

## 🚀 Features

### For Job Seekers
- **User Registration & Authentication**: Secure JWT-based authentication
- **Job Search**: Advanced search with filters (location, salary, skills)
- **Job Applications**: Apply to jobs with cover letters and resumes
- **Profile Management**: Complete profile with skills, experience, education
- **Application Tracking**: Track application status and responses
- **Job Recommendations**: AI-powered job recommendations
- **Notifications**: Real-time notifications for job updates

### For Employers
- **Job Posting**: Create and manage job listings
- **Application Management**: Review and manage applications
- **Candidate Search**: Search and filter candidates
- **Company Profile**: Manage company information
- **Analytics**: View job posting performance

## 🛠️ Tech Stack

- **Framework**: Flutter 3.x
- **Language**: Dart
- **State Management**: Riverpod
- **Navigation**: GoRouter
- **HTTP Client**: Dio
- **Local Storage**: Hive + SharedPreferences
- **Authentication**: JWT + Secure Storage
- **UI Components**: Custom design system
- **Theming**: Material 3 with dark/light modes

## 📱 Screens & Navigation

### Authentication Flow
- Splash Screen
- Onboarding
- Login
- Registration
- Forgot Password

### Main App Flow
- Home Dashboard
- Job Search
- Job Details
- Application Form
- Profile
- Applications
- Notifications
- Settings

## 🔧 Setup Instructions

### Prerequisites
- Flutter SDK 3.10.0 or higher
- Dart SDK 3.0.0 or higher
- Android Studio / VS Code
- Android SDK / Xcode (for mobile development)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/3wes22/job-seeker.git
   cd job-seeker/frontend/flutter-app
   ```

2. **Install dependencies**
   ```bash
   flutter pub get
   ```

3. **Run the app**
   ```bash
   flutter run
   ```

### Environment Configuration

Create a `.env` file in the root directory:
```env
API_BASE_URL=http://localhost:8001
ENVIRONMENT=development
```

## 🏗️ Project Structure Details

### Core Module (`lib/core/`)
- **config/**: App configuration, environment settings
- **constants/**: App-wide constants, API endpoints
- **router/**: Navigation configuration with GoRouter
- **theme/**: Material 3 theming with light/dark modes
- **utils/**: Utility functions, helpers, extensions
- **widgets/**: Reusable UI components

### Features Module (`lib/features/`)
Each feature follows a clean architecture pattern:
```
feature/
├── data/
│   ├── datasources/
│   ├── models/
│   └── repositories/
├── domain/
│   ├── entities/
│   ├── repositories/
│   └── usecases/
├── presentation/
│   ├── pages/
│   ├── widgets/
│   └── providers/
└── feature.dart
```

### Shared Module (`lib/shared/`)
- **models/**: Shared data models
- **services/**: API service classes
- **providers/**: Global state providers

## 🎨 Design System

### Colors
- **Primary**: Blue (#2563EB)
- **Secondary**: Green (#10B981)
- **Accent**: Orange (#F59E0B)
- **Error**: Red (#EF4444)
- **Success**: Green (#22C55E)

### Typography
- **Font Family**: Inter
- **Weights**: Regular, Medium, SemiBold, Bold
- **Sizes**: 10px to 32px

### Components
- Custom buttons, cards, inputs
- Consistent spacing and elevation
- Responsive design patterns

## 🔐 Security Features

- JWT token management
- Secure local storage
- Biometric authentication
- Network security
- Input validation

## 📊 State Management

Using Riverpod for:
- **Authentication state**
- **User profile data**
- **Job listings**
- **Application status**
- **Theme preferences**
- **Network connectivity**

## 🧪 Testing

- **Unit Tests**: Business logic and utilities
- **Widget Tests**: UI components
- **Integration Tests**: Feature workflows
- **Golden Tests**: Visual regression testing

## 📦 Build & Deployment

### Android
```bash
flutter build apk --release
flutter build appbundle --release
```

### iOS
```bash
flutter build ios --release
```

## 🔄 API Integration

The app connects to the Django backend services:
- **User Service**: Authentication and user management
- **Job Service**: Job listings and management
- **Application Service**: Job applications
- **Search Service**: Job search functionality
- **Notification Service**: Real-time notifications

## 📈 Performance

- **Lazy loading** for images and data
- **Caching** strategies for API responses
- **Optimized** widget rebuilds
- **Memory management** best practices

## 🐛 Debugging

- **Logging**: Structured logging with different levels
- **Error tracking**: Comprehensive error handling
- **Performance monitoring**: App performance metrics
- **Network debugging**: API request/response logging

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## 📄 License

This project is licensed under the MIT License.

## 🆘 Support

For support and questions:
- Create an issue on GitHub
- Check the documentation
- Review the code examples 

============================================================
FILE: frontend/README.md
============================================================
# Frontend Architecture

This directory contains the frontend applications for the Job Seeker Platform.

## Structure

```
frontend/
├── web-app/           # React/Next.js web application
├── flutter-app/       # Flutter mobile application
├── shared/            # Shared components, types, and utilities
└── README.md          # This file
```

## Technologies

### Web Application (React/Next.js)
- **Framework**: Next.js 14 with App Router
- **Language**: TypeScript
- **Styling**: Tailwind CSS + Shadcn/ui
- **State Management**: Zustand
- **HTTP Client**: Axios
- **Authentication**: JWT with refresh tokens
- **Form Handling**: React Hook Form + Zod validation

### Mobile Application (Flutter)
- **Framework**: Flutter 3.x
- **Language**: Dart
- **State Management**: Riverpod
- **HTTP Client**: Dio
- **Authentication**: JWT with secure storage
- **UI Components**: Custom design system

## Shared Resources
- **API Types**: TypeScript interfaces shared between web and mobile
- **Constants**: API endpoints, configuration
- **Utilities**: Common helper functions

## Development Setup

### Web App
```bash
cd frontend/web-app
npm install
npm run dev
```

### Flutter App
```bash
cd frontend/flutter-app
flutter pub get
flutter run
```

## API Integration
Both applications connect to the Django backend services:
- User Service: Authentication and user management
- Job Service: Job listings and management
- Application Service: Job applications
- Search Service: Job search functionality
- Notification Service: Real-time notifications 

============================================================
FILE: infrastructure/docker/api-gateway/nginx.conf
============================================================
upstream user_service {
    server user-service:8000;
}

upstream job_service {
    server job-service:8000;
}

upstream application_service {
    server application-service:8000;
}

server {
    listen 80;
    server_name localhost;

    # CORS headers
    add_header Access-Control-Allow-Origin *;
    add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS";
    add_header Access-Control-Allow-Headers "Content-Type, Authorization";

    # Handle preflight requests
    if ($request_method = 'OPTIONS') {
        return 204;
    }

    # User service routes
    location /api/users/ {
        proxy_pass http://user_service/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # Job service routes
    location /api/jobs/ {
        proxy_pass http://job_service/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # Application service routes
    location /api/applications/ {
        proxy_pass http://application_service/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # Health check endpoint
    location /health {
        return 200 'OK';
        add_header Content-Type text/plain;
    }
}

============================================================
FILE: infrastructure/scripts/setup.sh
============================================================
#!/bin/bash

echo "Setting up Job Platform development environment..."

# Create virtual environments for each service
services=("user-service" "job-service" "application-service" "search-service" "notification-service" "analytics-service")

for service in "${services[@]}"; do
    echo "Setting up $service..."
    cd backend/$service
    
    # Create virtual environment
    python -m venv venv
    source venv/bin/activate
    
    # Install dependencies
    pip install --upgrade pip
    pip install -r requirements.txt
    
    # Create Django project if it doesn't exist
    if [ ! -f manage.py ]; then
        django-admin startproject $service .
    fi
    
    cd ../..
done

echo "Creating Docker network..."
docker network create job-platform-network 2>/dev/null || true

echo "Building Docker images..."
docker-compose build

echo "Starting services..."
docker-compose up -d postgres-users postgres-jobs postgres-applications redis

echo "Waiting for databases to be ready..."
sleep 10

echo "Running migrations..."
docker-compose run --rm user-service python manage.py migrate
docker-compose run --rm job-service python manage.py migrate
docker-compose run --rm application-service python manage.py migrate

echo "Setup complete! You can now start development."
echo "Run 'docker-compose up' to start all services."

============================================================
FILE: scripts/setup.sh
============================================================
#!/bin/bash

# Job Platform Flutter App Setup Script
# This script helps set up the development environment

set -e

echo "🚀 Setting up Job Platform Flutter App..."

# Check if Flutter is installed
if ! command -v flutter &> /dev/null; then
    echo "❌ Flutter is not installed. Please install Flutter first:"
    echo "   https://flutter.dev/docs/get-started/install"
    exit 1
fi

# Check Flutter version
FLUTTER_VERSION=$(flutter --version | grep -o "Flutter [0-9]\+\.[0-9]\+\.[0-9]\+" | cut -d' ' -f2)
REQUIRED_VERSION="3.10.0"

if [ "$(printf '%s\n' "$REQUIRED_VERSION" "$FLUTTER_VERSION" | sort -V | head -n1)" != "$REQUIRED_VERSION" ]; then
    echo "❌ Flutter version $FLUTTER_VERSION is too old. Required: $REQUIRED_VERSION or higher"
    exit 1
fi

echo "✅ Flutter version $FLUTTER_VERSION detected"

# Get dependencies
echo "📦 Getting Flutter dependencies..."
flutter pub get

# Create necessary directories
echo "📁 Creating project structure..."
mkdir -p lib/features/auth/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/features/jobs/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/features/search/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/features/applications/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/features/profile/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/features/notifications/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/features/home/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/features/splash/{data/{api,repositories},domain/{entities,repositories,usecases},presentation/{screens,widgets,providers}}
mkdir -p lib/shared/{widgets,models,constants}
mkdir -p assets/{images,icons,config,fonts}
mkdir -p test/{unit,integration,widget}
mkdir -p integration_test

# Create placeholder files to maintain structure
echo "📝 Creating placeholder files..."
touch lib/features/auth/data/api/.gitkeep
touch lib/features/auth/data/repositories/.gitkeep
touch lib/features/auth/domain/entities/.gitkeep
touch lib/features/auth/domain/repositories/.gitkeep
touch lib/features/auth/domain/usecases/.gitkeep
touch lib/features/auth/presentation/screens/.gitkeep
touch lib/features/auth/presentation/widgets/.gitkeep
touch lib/features/auth/presentation/providers/.gitkeep

touch lib/features/jobs/data/api/.gitkeep
touch lib/features/jobs/data/repositories/.gitkeep
touch lib/features/jobs/domain/entities/.gitkeep
touch lib/features/jobs/domain/repositories/.gitkeep
touch lib/features/jobs/domain/usecases/.gitkeep
touch lib/features/jobs/presentation/screens/.gitkeep
touch lib/features/jobs/presentation/widgets/.gitkeep
touch lib/features/jobs/presentation/providers/.gitkeep

touch lib/features/search/data/api/.gitkeep
touch lib/features/search/data/repositories/.gitkeep
touch lib/features/search/domain/entities/.gitkeep
touch lib/features/search/domain/repositories/.gitkeep
touch lib/features/search/domain/usecases/.gitkeep
touch lib/features/search/presentation/screens/.gitkeep
touch lib/features/search/presentation/widgets/.gitkeep
touch lib/features/search/presentation/providers/.gitkeep

touch lib/features/applications/data/api/.gitkeep
touch lib/features/applications/data/repositories/.gitkeep
touch lib/features/applications/domain/entities/.gitkeep
touch lib/features/applications/domain/repositories/.gitkeep
touch lib/features/applications/domain/usecases/.gitkeep
touch lib/features/applications/presentation/screens/.gitkeep
touch lib/features/applications/presentation/widgets/.gitkeep
touch lib/features/applications/presentation/providers/.gitkeep

touch lib/features/profile/data/api/.gitkeep
touch lib/features/profile/data/repositories/.gitkeep
touch lib/features/profile/domain/entities/.gitkeep
touch lib/features/profile/domain/repositories/.gitkeep
touch lib/features/profile/domain/usecases/.gitkeep
touch lib/features/profile/presentation/screens/.gitkeep
touch lib/features/profile/presentation/widgets/.gitkeep
touch lib/features/profile/presentation/providers/.gitkeep

touch lib/features/notifications/data/api/.gitkeep
touch lib/features/notifications/data/repositories/.gitkeep
touch lib/features/notifications/domain/entities/.gitkeep
touch lib/features/notifications/domain/repositories/.gitkeep
touch lib/features/notifications/domain/usecases/.gitkeep
touch lib/features/notifications/presentation/screens/.gitkeep
touch lib/features/notifications/presentation/widgets/.gitkeep
touch lib/features/notifications/presentation/providers/.gitkeep

touch lib/features/home/data/api/.gitkeep
touch lib/features/home/data/repositories/.gitkeep
touch lib/features/home/domain/entities/.gitkeep
touch lib/features/home/domain/repositories/.gitkeep
touch lib/features/home/domain/usecases/.gitkeep
touch lib/features/home/presentation/screens/.gitkeep
touch lib/features/home/presentation/widgets/.gitkeep
touch lib/features/home/presentation/providers/.gitkeep

touch lib/features/splash/data/api/.gitkeep
touch lib/features/splash/data/repositories/.gitkeep
touch lib/features/splash/domain/entities/.gitkeep
touch lib/features/splash/domain/repositories/.gitkeep
touch lib/features/splash/domain/usecases/.gitkeep
touch lib/features/splash/presentation/screens/.gitkeep
touch lib/features/splash/presentation/widgets/.gitkeep
touch lib/features/splash/presentation/providers/.gitkeep

touch lib/shared/widgets/.gitkeep
touch lib/shared/models/.gitkeep
touch lib/shared/constants/.gitkeep

touch assets/images/.gitkeep
touch assets/icons/.gitkeep
touch assets/config/.gitkeep
touch assets/fonts/.gitkeep

touch test/unit/.gitkeep
touch test/integration/.gitkeep
touch test/widget/.gitkeep

# Generate code
echo "🔨 Generating code..."
flutter packages pub run build_runner build --delete-conflicting-outputs

# Run tests to ensure everything is working
echo "🧪 Running tests..."
flutter test

echo "✅ Setup completed successfully!"
echo ""
echo "🎯 Next steps:"
echo "1. Review the project structure in lib/"
echo "2. Check the README.md for development guidelines"
echo "3. Start implementing your features"
echo "4. Run 'flutter run' to start the app"
echo ""
echo "📚 Useful commands:"
echo "  flutter run                    # Run the app"
echo "  flutter test                   # Run tests"
echo "  flutter packages pub run build_runner build --delete-conflicting-outputs  # Generate code"
echo "  flutter packages pub run build_runner watch  # Watch for changes"
echo ""
echo "🚀 Happy coding!" 

============================================================
FILE: build.yaml
============================================================
targets:
  $default:
    builders:
      json_serializable:
        options:
          # Options for json_serializable
          explicit_to_json: true
          include_if_null: false
          field_rename: snake
          create_to_json: true
      
      retrofit_generator:
        options:
          # Options for retrofit
          generate_http_override: true
          generate_provider: true
      
      riverpod_generator:
        options:
          # Options for riverpod
          provider_name_suffix: Provider
          provider_parameters: true
          generate_provider_parameters: true
      
      build_web_compilers:
        options:
          compiler: dart2js
          dart2js_args:
            - --fast-startup
            - --minify
            - --trust-primitives
            - --trust-type-annotations 

============================================================
FILE: pubspec.yaml
============================================================
name: job_platform_app
description: A Flutter app for the Job Platform microservices backend
publish_to: 'none'
version: 1.0.0+1

environment:
  sdk: '>=3.0.0 <4.0.0'
  flutter: ">=3.10.0"

dependencies:
  flutter:
    sdk: flutter
  
  # State Management
  flutter_riverpod: ^2.4.9
  
  # HTTP & API
  dio: ^5.4.0
  
  # Local Storage
  shared_preferences: ^2.2.2
  
  # UI Components
  cupertino_icons: ^1.0.6
  
  # Navigation
  go_router: ^12.1.3
  
  # Localization
  flutter_localizations:
    sdk: flutter

dev_dependencies:
  flutter_test:
    sdk: flutter
  
  # Code Generation
  build_runner: ^2.4.7
  
  # Linting
  flutter_lints: ^3.0.1

flutter:
  uses-material-design: true
  
  assets:
    - assets/images/
    - assets/icons/
    - assets/config/ 

============================================================
FILE: README.md
============================================================
# Job Platform Flutter App

A comprehensive Flutter application built with Clean Architecture that integrates seamlessly with the Job Platform microservices backend.

## 🏗️ Architecture

This app follows **Clean Architecture** principles with the following layers:

- **Presentation Layer**: UI widgets, screens, and state management (Riverpod)
- **Domain Layer**: Business logic, entities, and use cases
- **Data Layer**: API clients, repositories, and local storage

### Project Structure

```
lib/
├── core/                           # Core app functionality
│   ├── config/                     # App configuration
│   ├── di/                         # Dependency injection
│   ├── network/                    # HTTP client and interceptors
│   ├── router/                     # Navigation and routing
│   ├── storage/                    # Local and secure storage
│   ├── theme/                      # App theming
│   └── utils/                      # Utility classes
├── features/                       # Feature modules
│   ├── auth/                       # Authentication
│   │   ├── data/                   # Data layer
│   │   ├── domain/                 # Domain layer
│   │   └── presentation/           # UI layer
│   ├── jobs/                       # Job management
│   ├── search/                     # Job search
│   ├── applications/               # Job applications
│   ├── profile/                    # User profile
│   ├── notifications/              # Notifications
│   └── home/                       # Home screen
└── shared/                         # Shared components
    ├── widgets/                    # Reusable widgets
    ├── models/                     # Shared models
    └── constants/                  # App constants
```

## 🚀 Getting Started

### Prerequisites

- Flutter SDK (3.10.0 or higher)
- Dart SDK (3.0.0 or higher)
- Android Studio / VS Code
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd job-platform-app
   ```

2. **Install dependencies**
   ```bash
   flutter pub get
   ```

3. **Generate code**
   ```bash
   flutter packages pub run build_runner build
   ```

4. **Run the app**
   ```bash
   flutter run
   ```

## 🔧 Configuration

### Environment Setup

The app automatically loads configuration from the backend config API. You can override default values by setting environment variables:

```bash
export USER_SERVICE_URL=http://localhost:8001
export JOB_SERVICE_URL=http://localhost:8002
export APPLICATION_SERVICE_URL=http://localhost:8003
export ANALYTICS_SERVICE_URL=http://localhost:8004
export NOTIFICATION_SERVICE_URL=http://localhost:8005
export SEARCH_SERVICE_URL=http://localhost:8006
```

### Feature Flags

The app supports dynamic feature flags loaded from the backend:

- `real_time_notifications`: Enable WebSocket notifications
- `advanced_search`: Enable advanced search filters
- `analytics`: Enable analytics tracking

## 📱 Features

### Authentication
- User registration and login
- JWT token management
- Secure token storage
- Automatic token refresh

### Job Management
- Browse job listings
- Job search and filtering
- Job details and application
- Company information

### User Profile
- Profile management
- Application history
- Saved jobs
- Preferences

### Real-time Features
- Push notifications
- WebSocket support
- Live updates

## 🛠️ Development

### Code Generation

This project uses several code generation tools:

- **Retrofit**: Generate API service classes
- **JSON Serializable**: Generate JSON serialization code
- **Riverpod Generator**: Generate provider code

To regenerate code after changes:

```bash
# Clean and rebuild
flutter packages pub run build_runner clean
flutter packages pub run build_runner build --delete-conflicting-outputs

# Watch for changes (development)
flutter packages pub run build_runner watch
```

### Adding New Microservices

1. **Create API service interface** in `lib/features/[feature]/data/api/`
2. **Add service URL** to `lib/core/config/app_config.dart`
3. **Generate API client** using build_runner
4. **Create repository** in `lib/features/[feature]/data/repositories/`
5. **Add to dependency injection** in `lib/core/di/providers.dart`

Example:
```dart
// 1. Create API interface
@RestApi()
abstract class NewServiceApi {
  factory NewServiceApi(Dio dio, {String baseUrl}) = _NewServiceApi;
  
  @GET('/api/endpoint')
  Future<List<DataModel>> getData();
}

// 2. Add to config
static String _newServiceUrl = 'http://localhost:8007';

// 3. Generate code
flutter packages pub run build_runner build

// 4. Create repository
class NewServiceRepository {
  final NewServiceApi _api;
  
  NewServiceRepository(this._api);
  
  Future<List<DataModel>> getData() => _api.getData();
}

// 5. Add to providers
@riverpod
NewServiceRepository newServiceRepository(NewServiceRepositoryRef ref) {
  final api = NewServiceApi(ref.watch(dioClientProvider).getDioForService('new'));
  return NewServiceRepository(api);
}
```

### State Management

The app uses **Riverpod** for state management. Key concepts:

- **Providers**: Define dependencies and state
- **Notifiers**: Manage state changes
- **ConsumerWidget**: Access providers in UI

Example:
```dart
class JobsNotifier extends StateNotifier<AsyncValue<List<Job>>> {
  final JobsRepository _repository;
  
  JobsNotifier(this._repository) : super(const AsyncValue.loading());
  
  Future<void> fetchJobs() async {
    state = const AsyncValue.loading();
    try {
      final jobs = await _repository.getJobs();
      state = AsyncValue.data(jobs);
    } catch (error, stackTrace) {
      state = AsyncValue.error(error, stackTrace);
    }
  }
}

@riverpod
class Jobs extends _$Jobs {
  @override
  Future<List<Job>> build() async {
    return ref.watch(jobsRepositoryProvider).getJobs();
  }
  
  Future<void> refresh() async {
    ref.invalidateSelf();
  }
}
```

### Testing

The project includes comprehensive testing setup:

```bash
# Unit tests
flutter test

# Integration tests
flutter test integration_test/

# Coverage report
flutter test --coverage
genhtml coverage/lcov.info -o coverage/html
```

## 📦 Dependencies

### Core Dependencies
- **flutter_riverpod**: State management
- **dio**: HTTP client
- **retrofit**: API client generation
- **json_annotation**: JSON serialization
- **go_router**: Navigation
- **flutter_secure_storage**: Secure storage
- **shared_preferences**: Local storage

### Development Dependencies
- **build_runner**: Code generation
- **retrofit_generator**: Retrofit code generation
- **json_serializable**: JSON code generation
- **riverpod_generator**: Riverpod code generation
- **mockito**: Testing mocks

## 🔐 Security

- JWT tokens stored in secure storage
- HTTPS enforced in production
- Input validation and sanitization
- Secure API communication

## 📊 Performance

- Lazy loading of data
- Efficient state management
- Optimized image loading
- Minimal network requests

## 🚀 Deployment

### Android
```bash
flutter build apk --release
flutter build appbundle --release
```

### iOS
```bash
flutter build ios --release
```

### Web
```bash
flutter build web --release
```

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## 📄 License

This project is licensed under the MIT License - see the LICENSE file for details.

## 🆘 Support

For support and questions:

- Create an issue in the repository
- Check the documentation
- Review the code examples

## 🔄 Updates

To update dependencies:

```bash
flutter pub upgrade
flutter packages pub run build_runner build --delete-conflicting-outputs
```

## 📝 TODO

- [ ] Implement actual API integration
- [ ] Add comprehensive error handling
- [ ] Implement offline support
- [ ] Add analytics tracking
- [ ] Implement push notifications
- [ ] Add comprehensive testing
- [ ] Performance optimization
- [ ] Accessibility improvements
- [ ] Internationalization
- [ ] Dark mode support

## 🎯 Roadmap

### Phase 1: Core Features ✅
- [x] Project structure setup
- [x] Authentication system
- [x] Basic navigation
- [x] Theme system

### Phase 2: Job Management 🚧
- [ ] Job listing
- [ ] Job search
- [ ] Job details
- [ ] Application system

### Phase 3: Advanced Features 📋
- [ ] Real-time notifications
- [ ] Advanced search
- [ ] Analytics dashboard
- [ ] Offline support

### Phase 4: Polish & Optimization 🎨
- [ ] Performance optimization
- [ ] UI/UX improvements
- [ ] Comprehensive testing
- [ ] Documentation